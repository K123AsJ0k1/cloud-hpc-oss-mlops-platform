{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fb5429-e144-4b31-85d7-8b64696c17f0",
   "metadata": {},
   "source": [
    "```\n",
    "docker compose -f backend.yaml up\n",
    "\n",
    "docker compose -f frontend.yaml up\n",
    "\n",
    "conda env list\n",
    "conda activate py3.11\n",
    "source pipeline_venv/bin/activate\n",
    "./start.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a37db-0a05-4324-b91c-8c31ec62d4ce",
   "metadata": {},
   "source": [
    "## Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe50e40-125e-4509-846b-920174f40d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient as mc\n",
    "\n",
    "def mongo_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, mc.Connection)\n",
    "\n",
    "def mongo_setup_client(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_check_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database_exists = database_name in mongo_client.list_database_names()\n",
    "        return database_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_list_databases(\n",
    "    mongo_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        databases = mongo_client.list_database_names()\n",
    "        return databases\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        mongo_client.drop_database(database_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_get_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_check_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        collection_exists = collection_name in database.list_collection_names()\n",
    "        return collection_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_update_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_many(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_collections(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collections = database.list_collection_names()\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try: \n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        database.drop_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_create_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    document: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.insert_one(document)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "    \n",
    "def mongo_collection_number(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str \n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        amount_of_documents = collection.count_documents({})\n",
    "        return amount_of_documents\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_documents(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any,\n",
    "    sorting_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        documents = list(collection.find(filter_query).sort(sorting_query))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_update_document(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_one(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_remove_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    ") -> bool:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.delete_one(filter_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0faced0-8947-403c-b9f3-60d93a42b1f1",
   "metadata": {},
   "source": [
    "## Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2030cee-1e5a-414f-afbe-a51dcc31ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient as qc\n",
    "\n",
    "def qdrant_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, qc.Connection)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_setup_client(\n",
    "    api_key: str,\n",
    "    address: str, \n",
    "    port: str\n",
    ") -> any:\n",
    "    try:\n",
    "        qdrant_client = qc(\n",
    "            host = address,\n",
    "            port = int(port),\n",
    "            api_key = api_key,\n",
    "            https = False\n",
    "        ) \n",
    "        return qdrant_client\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_create_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str,\n",
    "    configuration: any\n",
    ") -> any:\n",
    "    try:\n",
    "        result = qdrant_client.create_collection(\n",
    "            collection_name = collection_name,\n",
    "            vectors_config = configuration\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_get_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = qdrant_client.get_collection(\n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_collection_number(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str,\n",
    "    count_filter: any\n",
    ") -> any:\n",
    "    try:\n",
    "        result = qdrant_client.count(\n",
    "            collection_name = collection_name,\n",
    "            count_filter = count_filter,\n",
    "            exact =  True\n",
    "        )\n",
    "        return result.count\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_list_collections(\n",
    "    qdrant_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collections = qdrant_client.get_collections()\n",
    "        collection_list = []\n",
    "        for description in collections.collections:\n",
    "            collection_list.append(description.name)\n",
    "        return collection_list\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    \n",
    "def qdrant_remove_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        qdrant_client.delete_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_upsert_points(\n",
    "    qdrant_client: qc, \n",
    "    collection_name: str,\n",
    "    points: any\n",
    ") -> any:\n",
    "    try:\n",
    "        results = qdrant_client.upsert(\n",
    "            collection_name = collection_name, \n",
    "            points = points\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_search_data(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    scroll_filter: any,\n",
    "    limit: int,\n",
    "    offset: any\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.scroll(\n",
    "            collection_name = collection_name,\n",
    "            scroll_filter = scroll_filter,\n",
    "            limit = limit,\n",
    "            with_payload = True,\n",
    "            offset = offset\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def qdrant_search_vectors(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    query_vector: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.search(\n",
    "            collection_name = collection_name,\n",
    "            query_vector = query_vector,\n",
    "            limit = limit,\n",
    "            with_payload = True\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_remove_points(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str, \n",
    "    points_selector: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        results = qdrant_client.delete(\n",
    "            collection_name = collection_name,\n",
    "            points_selector = points_selector\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing document: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2d253-34ae-4b48-892b-8de7efc63e2d",
   "metadata": {},
   "source": [
    "## Meili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e7c7fc-5a18-45b4-a768-890528e02e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meilisearch as ms\n",
    "\n",
    "def meili_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, ms.Connection)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def meili_setup_client(\n",
    "    api_key: str,\n",
    "    host: str\n",
    ") -> any:\n",
    "    try:\n",
    "        meili_client = ms.Client(\n",
    "            url = host, \n",
    "            api_key = api_key\n",
    "        )\n",
    "        return meili_client \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_get_index( \n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_check_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        meili_client.get_index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def meili_remove_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        response = meili_client.index(\n",
    "            index_name = index_name\n",
    "        ).delete()\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_list_indexes(\n",
    "    meili_client: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        names = []\n",
    "        indexes = meili_client.get_indexes()\n",
    "        for index in indexes['results']:\n",
    "            names.append(index.uid)\n",
    "        return names\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_add_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    documents: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.add_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_set_filterable(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    attributes: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_filterable_attributes(attributes)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_search_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    query: any, \n",
    "    options: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.search(\n",
    "            query,\n",
    "            options\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_update_documents(\n",
    "    meili_client, \n",
    "    index_name, \n",
    "    documents\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_delete_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    ids: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.delete_documents(\n",
    "            document_ids = ids\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89470a8-57eb-4517-a61c-df4fdb7c5031",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd883ae-db11-43c1-b033-ed0761f9c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "def langchain_chunk_prompt(\n",
    "    configuration: any,\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = configuration['chunk-size'], \n",
    "        chunk_overlap = configuration['chunk-overlap'],\n",
    "        length_function = len,\n",
    "        is_separator_regex = False\n",
    "    )\n",
    "\n",
    "    prompt_chunks = splitter.create_documents([prompt])\n",
    "    prompt_chunks = [prompt.page_content for prompt in prompt_chunks]\n",
    "    return prompt_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9b08f-c5dc-4826-af2c-4071993e46e6",
   "metadata": {},
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab746465-58a8-4320-b4e4-47c64ec11ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_search_keywords(\n",
    "    language_model: any,\n",
    "    text: str\n",
    "):\n",
    "    lowered = text.lower()\n",
    "    formatted = language_model(lowered)\n",
    "    \n",
    "    keywords = [\n",
    "        token.lemma_ for token in formatted\n",
    "        if not token.is_stop               \n",
    "        and not token.is_punct              \n",
    "        and not token.is_space              \n",
    "        and len(token) > 1                  \n",
    "    ]\n",
    "    \n",
    "    keywords = list(set(keywords))\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc14aa8-c2c8-49f6-bd32-826805587534",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48ee3ec7-0c55-45ce-a74c-118d54fb24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_prompt(\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    prompt = prompt.lower()\n",
    "    prompt = re.sub(r'\\s+', ' ', prompt)\n",
    "    prompt = re.sub(r'[^\\w\\s]', '', prompt)\n",
    "    return prompt.strip()\n",
    "\n",
    "def create_chunk_keywords(\n",
    "    language_model: any,\n",
    "    chunks: any\n",
    ") -> any:\n",
    "    keyword_queries = []\n",
    "    for chunk in chunks:\n",
    "        keywords = spacy_search_keywords(\n",
    "            language_model = language_model,\n",
    "            text = chunk\n",
    "        )\n",
    "        keyword_query = ' OR '.join([f'keywords = \"{keyword}\"' for keyword in keywords])\n",
    "        keyword_queries.append(keyword_query)\n",
    "    return keyword_queries\n",
    "\n",
    "def generate_prompt_queries(\n",
    "    configuration: any,\n",
    "    embedding_model: any,\n",
    "    language_model: any,\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    cleaned_prompt = clean_prompt(\n",
    "        prompt = prompt\n",
    "    )\n",
    "    \n",
    "    prompt_chunks = langchain_chunk_prompt(\n",
    "        configuration = configuration,\n",
    "        prompt = cleaned_prompt\n",
    "    ) \n",
    "\n",
    "    embedding_queries = embedding_model.embed_documents(\n",
    "        texts = prompt_chunks\n",
    "    )\n",
    "\n",
    "    keyword_queries = create_chunk_keywords(\n",
    "        language_model = language_model,\n",
    "        chunks = prompt_chunks\n",
    "    )\n",
    "\n",
    "    formatted_queries = {\n",
    "        'embeddings': embedding_queries,\n",
    "        'keywords': keyword_queries\n",
    "    }\n",
    "\n",
    "    return formatted_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31fbd42-f55b-4877-9328-50dae80aa981",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = 'What is python?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425034a3-2cd7-4e65-8605-acf2c0c7d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_configuration = {\n",
    "    'chunk-size': 50,\n",
    "    'chunk-overlap': 0,\n",
    "    'top-k': 10,\n",
    "    'alpha': 0.5,\n",
    "    'context-amount': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c7e542-c4d6-438c-9747-efcd93a9fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/llm_venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/llm_venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ")\n",
    "\n",
    "language_model = spacy.load(\n",
    "    name = 'en_core_web_sm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06e4ea26-c0f7-4f94-a87d-4d8a0430a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/llm_venv/lib/python3.10/site-packages/qdrant_client/qdrant_remote.py:130: UserWarning: Api key is used with an insecure connection.\n",
      "  warnings.warn(\"Api key is used with an insecure connection.\")\n"
     ]
    }
   ],
   "source": [
    "mongo_client = mongo_setup_client(\n",
    "    username = 'mongo123',\n",
    "    password = 'mongo456',\n",
    "    address = '127.0.0.1',\n",
    "    port = '27017'\n",
    ")\n",
    "\n",
    "qdrant_client = qdrant_setup_client(\n",
    "    api_key = 'qdrant_key',\n",
    "    address = '127.0.0.1', \n",
    "    port = '7201'\n",
    ")\n",
    "\n",
    "meili_client = meili_setup_client(\n",
    "    host = 'http://127.0.0.1:7202', \n",
    "    api_key = 'meili_key'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4dc08bb-a7b9-4454-b6f1-29046960e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_queries = generate_prompt_queries(\n",
    "    configuration = pipeline_configuration,\n",
    "    embedding_model = embedding_model, \n",
    "    language_model = language_model,\n",
    "    prompt = test_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13fa2b5-ecb1-4cff-aa79-2ca0e8a3f25b",
   "metadata": {},
   "source": [
    "## Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ac6d823-9d6f-4c32-be45-092b87b61f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keyword_score(\n",
    "    keyword_query: str,\n",
    "    keyword_list: any\n",
    ") -> any:\n",
    "    match = 0\n",
    "    asked_keywords = keyword_query.split('OR')\n",
    "    for asked_keyword in asked_keywords:\n",
    "        formatted = asked_keyword.replace('keywords =', '')\n",
    "        formatted = formatted.replace('\"', '')\n",
    "        formatted = formatted.replace(' ', '')\n",
    "        \n",
    "        if formatted in keyword_list:\n",
    "            match += 1\n",
    "            \n",
    "    query_length = len(asked_keywords)\n",
    "    keyword_length = len(keyword_list)\n",
    "\n",
    "    if match == 0:\n",
    "        return 0.0\n",
    "\n",
    "    normalized = match / ((query_length * keyword_length) ** 0.5)\n",
    "    return normalized\n",
    "\n",
    "def get_vector_hits(\n",
    "    vector_client: any,\n",
    "    configuration: any,\n",
    "    embedding_queries: any\n",
    ") -> any:\n",
    "    vector_hits = []\n",
    "    \n",
    "    collections = qdrant_list_collections(\n",
    "        qdrant_client = vector_client\n",
    "    )\n",
    "    for collection in collections:\n",
    "        for embedding in embedding_queries:\n",
    "            results = qdrant_search_vectors(\n",
    "                qdrant_client = vector_client,  \n",
    "                collection_name = collection,\n",
    "                query_vector = embedding,\n",
    "                limit = configuration['top-k']\n",
    "            ) \n",
    "            \n",
    "            for result in results:\n",
    "                #result_tuple = (\n",
    "                #    'vector',\n",
    "                #    result.payload['database'],\n",
    "                #    result.payload['collection'],\n",
    "                #    result.payload['document'],\n",
    "                #    result.payload['type'],\n",
    "                #    result.score\n",
    "                #)\n",
    "                result_dict = {\n",
    "                    'source': 'vector',\n",
    "                    'database': result.payload['database'],\n",
    "                    'collection': result.payload['collection'],\n",
    "                    'document': result.payload['document'],\n",
    "                    'type': result.payload['type'],\n",
    "                    'score': result.score\n",
    "                }\n",
    "                \n",
    "                vector_hits.append(result_dict)\n",
    "    return vector_hits\n",
    "\n",
    "def get_search_hits(\n",
    "    search_client: any,\n",
    "    configuration: any,\n",
    "    keyword_queries: any\n",
    ") -> any:\n",
    "    search_hits = []\n",
    "    \n",
    "    collections = meili_list_indexes(\n",
    "        meili_client = search_client\n",
    "    )\n",
    "    \n",
    "    for collection in collections:        \n",
    "        for keywords in keyword_queries:\n",
    "            results = meili_search_documents(\n",
    "                meili_client = search_client, \n",
    "                index_name = collection, \n",
    "                query = \"\", \n",
    "                options = {\n",
    "                    'filter': keywords,\n",
    "                    'attributesToRetrieve': ['database','collection','document', 'type', 'keywords'],\n",
    "                    'limit': configuration['top-k']\n",
    "                }\n",
    "            )\n",
    "    \n",
    "            for result in results['hits']:\n",
    "                score = calculate_keyword_score(\n",
    "                    keyword_query = keywords,\n",
    "                    keyword_list = result['keywords']\n",
    "                )\n",
    "            \n",
    "                #result_tuples = (\n",
    "                #    'search',\n",
    "                #    result['database'],\n",
    "                #    result['collection'],\n",
    "                #    result['document'],\n",
    "                #    result['type'],\n",
    "                #    score\n",
    "                #)\n",
    "\n",
    "                result_dict = {\n",
    "                    'source': 'search',\n",
    "                    'database': result['database'],\n",
    "                    'collection': result['collection'],\n",
    "                    'document': result['document'],\n",
    "                    'type': result['type'],\n",
    "                    'score': score\n",
    "                }\n",
    "                \n",
    "                search_hits.append(result_dict)\n",
    "    return search_hits\n",
    "    \n",
    "def get_hits(\n",
    "    vector_client: any,\n",
    "    search_client: any,\n",
    "    configuration: any,\n",
    "    queries: any\n",
    ") -> any:\n",
    "    vector_hits = get_vector_hits(\n",
    "        vector_client = vector_client,\n",
    "        configuration = configuration,\n",
    "        embedding_queries = queries['embeddings']\n",
    "    )\n",
    "    \n",
    "    search_hits = get_search_hits(\n",
    "        search_client = search_client,\n",
    "        configuration = configuration,\n",
    "        keyword_queries = queries['keywords']\n",
    "    )\n",
    "\n",
    "    found_hits = vector_hits + search_hits\n",
    "    # sorted(found_hits, key = lambda x: x[-1], reverse = True)\n",
    "    return found_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c8be4e9-7aec-4487-9af2-680a3a9f4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hits = get_hits(\n",
    "    vector_client = qdrant_client,\n",
    "    search_client = meili_client,\n",
    "    configuration = pipeline_configuration,\n",
    "    queries = example_queries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e949f5-afc8-4053-a032-7ec56feadc90",
   "metadata": {},
   "source": [
    "## Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61b1e426-3066-42b2-9cf4-71608745e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def match_hit_documents(\n",
    "    configuration: any,\n",
    "    filtered_df: any\n",
    ") -> any:\n",
    "    alpha = configuration['alpha']\n",
    "    matched_documents = []\n",
    "    for index_i, row_i in filtered_df[filtered_df['source'] == 'vector'].iterrows():\n",
    "        vector_source = row_i['source']\n",
    "        vector_database = row_i['database']\n",
    "        vector_collection = row_i['collection']\n",
    "        vector_id = row_i['document']\n",
    "        vector_type = row_i['type']\n",
    "        vector_score = row_i['score']\n",
    "        \n",
    "        for index_j, row_j in filtered_df[filtered_df['source'] == 'search'].iterrows():\n",
    "            search_source = row_j['source']\n",
    "            search_database = row_j['database']\n",
    "            search_collection = row_j['collection']\n",
    "            search_id = row_j['document']\n",
    "            search_type = row_j['type']\n",
    "            search_score = row_j['score']\n",
    "            \n",
    "            if vector_database == search_database:\n",
    "                if vector_collection == search_collection:\n",
    "                    if vector_type == search_type:\n",
    "                        if vector_id == search_id:\n",
    "                            hybrid_score = vector_score * alpha + search_score * (1-alpha)\n",
    "    \n",
    "                            matched_documents.append({\n",
    "                                'source': 'hybrid',\n",
    "                                'database': search_database,\n",
    "                                'collection': search_collection,\n",
    "                                'document': search_id,\n",
    "                                'score': hybrid_score\n",
    "                            })\n",
    "    match_df = pd.DataFrame(matched_documents)\n",
    "    return match_df\n",
    "\n",
    "def select_context_documents(\n",
    "    configuration: any,\n",
    "    matched_df: any\n",
    ") -> any:\n",
    "    sorted_df = matched_df.sort_values('score', ascending = False)\n",
    "    seen_documents = []\n",
    "    context_documents = []\n",
    "    for row in sorted_df.values.tolist():\n",
    "        row_id = row[3]\n",
    "        if not row_id in seen_documents and len(context_documents) <= configuration['context-amount']:\n",
    "            seen_documents.append(row_id)\n",
    "            context_documents.append(row)\n",
    "    return context_documents\n",
    "\n",
    "#def filter_hits(\n",
    "#    hits: any\n",
    "#) -> any:\n",
    "    \n",
    "\n",
    "def get_top_documents(\n",
    "    hits: str,\n",
    "    configuration: any\n",
    ") -> any:\n",
    "    df = pd.DataFrame(hits)\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    #ids_with_both = df.groupby('document')['source'].nunique()\n",
    "    \n",
    "    #print(ids_with_both)\n",
    "    \n",
    "    #ids_with_both = ids_with_both[ids_with_both > 1].index\n",
    "\n",
    "    \n",
    "    \n",
    "    #filtered_df = df[df['document'].isin(ids_with_both)]\n",
    "\n",
    "    #print(filtered_df)\n",
    "    \n",
    "    #df = filter_hits(\n",
    "    #    hits = hits\n",
    "    #)\n",
    "\n",
    "    return None\n",
    "\n",
    "    #matched_df = match_hit_documents(\n",
    "    #    configuration = configuration,\n",
    "    #    filtered_df = filtered_df\n",
    "    #) \n",
    "\n",
    "    #context_documents = select_context_documents(\n",
    "    #    configuration = configuration,\n",
    "    #    matched_df = matched_df\n",
    "    #)\n",
    "    \n",
    "    #return context_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e67c55be-f23c-4df7-b260-0d97f803b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(example_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dbfe9e15-9e22-4153-8c83-90ac89e0c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('document')['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32d28862-e115-4d06-8dd4-99096b487aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7c081e9b8a60>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f24b67d1-87ab-4f07-a62d-f5b9fdbb7000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>database</th>\n",
       "      <th>collection</th>\n",
       "      <th>document</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vector</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|md</td>\n",
       "      <td>de|ku|ma|co|ks|README</td>\n",
       "      <td>673b0e5b6ddead426e62ca83</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vector</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|md</td>\n",
       "      <td>de|ku|ma|co|ks|README</td>\n",
       "      <td>673b0e5b6ddead426e62ca83</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vector</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|md</td>\n",
       "      <td>de|ku|ma|co|ks|README</td>\n",
       "      <td>673b0e5b6ddead426e62ca83</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vector</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|md</td>\n",
       "      <td>de|ku|ma|co|ks|README</td>\n",
       "      <td>673b0e5b6ddead426e62ca83</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vector</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|md</td>\n",
       "      <td>de|ku|ma|co|ks|README</td>\n",
       "      <td>673b0e5b6ddead426e62ca83</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>search</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml</td>\n",
       "      <td>te|re|kf|pipeline</td>\n",
       "      <td>673b0e9a76c6682abb11ddba</td>\n",
       "      <td>yaml</td>\n",
       "      <td>0.147442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>search</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml</td>\n",
       "      <td>de|ku|ma|ap|kf|up|v1|th|ar|up|ma|qu|ba|ov|work...</td>\n",
       "      <td>673b0f5edf3ef8d0a63ff2ab</td>\n",
       "      <td>yaml</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>search</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml</td>\n",
       "      <td>de|ku|ma|ap|ju|ju|up|ba|co|spawner_ui_config</td>\n",
       "      <td>673b0ef0755c0da6c9c6dfbd</td>\n",
       "      <td>yaml</td>\n",
       "      <td>0.129099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>search</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml</td>\n",
       "      <td>de|ku|ma|ap|kf|up|th|ar|up|ma|qu|ba|ov|workflo...</td>\n",
       "      <td>673b0f3f755c0da6c9c6e233</td>\n",
       "      <td>yaml</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>search</td>\n",
       "      <td>K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml</td>\n",
       "      <td>de|ku|ma|ap|pi|up|th|ar|up|ma|qu|ba|ov|workflo...</td>\n",
       "      <td>673b0f4c755c0da6c9c6e27b</td>\n",
       "      <td>yaml</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source                                      database  \\\n",
       "0   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
       "1   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
       "2   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
       "3   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
       "4   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
       "..     ...                                           ...   \n",
       "70  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
       "71  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
       "72  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
       "73  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
       "74  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
       "\n",
       "                                           collection  \\\n",
       "0                               de|ku|ma|co|ks|README   \n",
       "1                               de|ku|ma|co|ks|README   \n",
       "2                               de|ku|ma|co|ks|README   \n",
       "3                               de|ku|ma|co|ks|README   \n",
       "4                               de|ku|ma|co|ks|README   \n",
       "..                                                ...   \n",
       "70                                  te|re|kf|pipeline   \n",
       "71  de|ku|ma|ap|kf|up|v1|th|ar|up|ma|qu|ba|ov|work...   \n",
       "72       de|ku|ma|ap|ju|ju|up|ba|co|spawner_ui_config   \n",
       "73  de|ku|ma|ap|kf|up|th|ar|up|ma|qu|ba|ov|workflo...   \n",
       "74  de|ku|ma|ap|pi|up|th|ar|up|ma|qu|ba|ov|workflo...   \n",
       "\n",
       "                    document      type     score  \n",
       "0   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
       "1   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
       "2   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
       "3   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
       "4   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
       "..                       ...       ...       ...  \n",
       "70  673b0e9a76c6682abb11ddba      yaml  0.147442  \n",
       "71  673b0f5edf3ef8d0a63ff2ab      yaml  0.125000  \n",
       "72  673b0ef0755c0da6c9c6dfbd      yaml  0.129099  \n",
       "73  673b0f3f755c0da6c9c6e233      yaml  0.125000  \n",
       "74  673b0f4c755c0da6c9c6e27b      yaml  0.125000  \n",
       "\n",
       "[75 rows x 6 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26d15e08-7ef1-4709-8ef2-5fe61a1487e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    source                                      database  \\\n",
      "0   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
      "1   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
      "2   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
      "3   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
      "4   vector    K123AsJ0k1|cloud-hpc-oss-mlops-platform|md   \n",
      "..     ...                                           ...   \n",
      "70  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
      "71  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
      "72  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
      "73  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
      "74  search  K123AsJ0k1|cloud-hpc-oss-mlops-platform|yaml   \n",
      "\n",
      "                                           collection  \\\n",
      "0                               de|ku|ma|co|ks|README   \n",
      "1                               de|ku|ma|co|ks|README   \n",
      "2                               de|ku|ma|co|ks|README   \n",
      "3                               de|ku|ma|co|ks|README   \n",
      "4                               de|ku|ma|co|ks|README   \n",
      "..                                                ...   \n",
      "70                                  te|re|kf|pipeline   \n",
      "71  de|ku|ma|ap|kf|up|v1|th|ar|up|ma|qu|ba|ov|work...   \n",
      "72       de|ku|ma|ap|ju|ju|up|ba|co|spawner_ui_config   \n",
      "73  de|ku|ma|ap|kf|up|th|ar|up|ma|qu|ba|ov|workflo...   \n",
      "74  de|ku|ma|ap|pi|up|th|ar|up|ma|qu|ba|ov|workflo...   \n",
      "\n",
      "                    document      type     score  \n",
      "0   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
      "1   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
      "2   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
      "3   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
      "4   673b0e5b6ddead426e62ca83  markdown  0.500455  \n",
      "..                       ...       ...       ...  \n",
      "70  673b0e9a76c6682abb11ddba      yaml  0.147442  \n",
      "71  673b0f5edf3ef8d0a63ff2ab      yaml  0.125000  \n",
      "72  673b0ef0755c0da6c9c6dfbd      yaml  0.129099  \n",
      "73  673b0f3f755c0da6c9c6e233      yaml  0.125000  \n",
      "74  673b0f4c755c0da6c9c6e27b      yaml  0.125000  \n",
      "\n",
      "[75 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "example_documents = get_top_documents(\n",
    "    hits = example_hits,\n",
    "    configuration = pipeline_configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d520391f-28b0-4497-ac24-35ff36028fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>database</th>\n",
       "      <th>collection</th>\n",
       "      <th>document</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, database, collection, document, type, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1b985-734a-4f28-abbc-dc54f28a3618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76ee51-019f-4d3a-9c56-1e229c73c8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f7f0a-ab1d-4392-850e-7a9aaf4f3e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60ee6d-e721-47bd-93a7-e50a71ee8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(\n",
    "    self,\n",
    "    prompt: str\n",
    ") -> str:\n",
    "    \n",
    "    print('Creating clients')\n",
    "    mongo_client = self.mongo_setup_client(\n",
    "        username = self.valves.MONGO_USER,\n",
    "        password = self.valves.MONGO_PASSWORD,\n",
    "        address = self.valves.MONGO_ADDRESS,\n",
    "        port = self.valves.MONGO_PORT\n",
    "    )\n",
    "\n",
    "    qdrant_client = self.qdrant_setup_client(\n",
    "        api_key = self.valves.QDRANT_KEY,\n",
    "        address = self.valves.QDRANT_ADDRESS, \n",
    "        port = self.valves.QDRANT_PORT\n",
    "    )\n",
    "\n",
    "    meili_client = self.meili_setup_client(\n",
    "        host = self.valves.MEILI_HOST, \n",
    "        api_key = self.valves.MEILI_KEY\n",
    "    )\n",
    "    print('Clients setup')\n",
    "\n",
    "    pipeline_configuration = {\n",
    "        'chunk-size': 50,\n",
    "        'chunk-overlap': 0,\n",
    "        'model-name': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "        'top-k': 10,\n",
    "        'alpha': 0.5,\n",
    "        'context-amount': 5\n",
    "    }\n",
    "\n",
    "    print('Running context pipeline')\n",
    "    created_context = self.context_pipeline(\n",
    "        document_client = mongo_client,\n",
    "        vector_client = qdrant_client,\n",
    "        search_client = meili_client,\n",
    "        configuration = pipeline_configuration ,\n",
    "        prompt = prompt\n",
    "    )\n",
    "    print('Context pipeline run')\n",
    "\n",
    "    return created_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f169f0-155a-47ad-a1cc-90f85da11c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cd7a5-48ee-4273-a225-b6a2b51dd422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0d214-0f11-4d62-816b-4b3e24967624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059230ca-fbd1-4681-9911-8bb49a13a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_setup_client(\n",
    "    self,\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    self,\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_collection(\n",
    "    self,\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = self.mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_get_document(\n",
    "    self,\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = self.mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "\n",
    "def qdrant_setup_client(\n",
    "    self,\n",
    "    api_key: str,\n",
    "    address: str, \n",
    "    port: str\n",
    ") -> any:\n",
    "    try:\n",
    "        qdrant_client = qc(\n",
    "            host = address,\n",
    "            port = int(port),\n",
    "            api_key = api_key,\n",
    "            https = False\n",
    "        ) \n",
    "        return qdrant_client\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_list_collections(\n",
    "    self,\n",
    "    qdrant_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collections = qdrant_client.get_collections()\n",
    "        collection_list = []\n",
    "        for description in collections.collections:\n",
    "            collection_list.append(description.name)\n",
    "        return collection_list\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_search_vectors(\n",
    "    self,\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    query_vector: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.search(\n",
    "            collection_name = collection_name,\n",
    "            query_vector = query_vector,\n",
    "            limit = limit\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def meili_setup_client(\n",
    "    self,\n",
    "    host: str, \n",
    "    api_key: str\n",
    ") -> any:\n",
    "    try:\n",
    "        meili_client = ms.Client(\n",
    "            url = host, \n",
    "            api_key = api_key\n",
    "        )\n",
    "        return meili_client \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_get_index( \n",
    "    self,\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_list_indexes(\n",
    "    self,\n",
    "    meili_client: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        names = []\n",
    "        indexes = meili_client.get_indexes()\n",
    "        for index in indexes['results']:\n",
    "            names.append(index.uid)\n",
    "        return names\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_search_documents(\n",
    "    self,\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    query: any, \n",
    "    options: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = self.meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.search(\n",
    "            query,\n",
    "            options\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def langchain_chunk_prompt(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = configuration['chunk-size'], \n",
    "        chunk_overlap = configuration['chunk-overlap'],\n",
    "        length_function = len\n",
    "    )\n",
    "\n",
    "    prompt_chunks = splitter.create_documents([prompt])\n",
    "    prompt_chunks = [prompt.page_content for prompt in prompt_chunks]\n",
    "    return prompt_chunks\n",
    "    \n",
    "def langchain_chunk_embeddings(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    chunks: any\n",
    ") -> any:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name = configuration['model-name']\n",
    "    )    \n",
    "    embeddings = embedding_model.embed_documents(\n",
    "        texts = chunks\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "def spacy_find_keywords(\n",
    "    self,\n",
    "    text: str\n",
    "):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    formatted = nlp(text.lower())\n",
    "    \n",
    "    keywords = [\n",
    "        token.lemma_ for token in formatted\n",
    "        if not token.is_stop               \n",
    "        and not token.is_punct              \n",
    "        and not token.is_space              \n",
    "        and len(token) > 1                  \n",
    "    ]\n",
    "    \n",
    "    keywords = list(set(keywords))\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def spacy_create_chunk_keywords(\n",
    "    self, \n",
    "    chunks: any\n",
    ") -> any:\n",
    "    keyword_queries = []\n",
    "    for chunk in chunks:\n",
    "        keywords = self.spacy_find_keywords(\n",
    "            text = chunk\n",
    "        )\n",
    "        keyword_query = ' OR '.join([f'keywords = \"{keyword}\"' for keyword in keywords])\n",
    "        keyword_queries.append(keyword_query)\n",
    "    return keyword_queries\n",
    "\n",
    "def clean_prompt(\n",
    "    self,\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    prompt = prompt.lower()\n",
    "    prompt = re.sub(r'\\s+', ' ', prompt)\n",
    "    prompt = re.sub(r'[^\\w\\s]', '', prompt)\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_prompt_queries(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    cleaned_prompt = self.clean_prompt(\n",
    "        prompt = prompt\n",
    "    )\n",
    "    \n",
    "    prompt_chunks = self.langchain_chunk_prompt(\n",
    "        configuration = configuration,\n",
    "        prompt = cleaned_prompt\n",
    "    ) \n",
    "\n",
    "    embedding_queries = self.langchain_chunk_embeddings(\n",
    "        configuration = configuration,\n",
    "        chunks = prompt_chunks\n",
    "    )\n",
    "\n",
    "    keyword_queries = self.spacy_create_chunk_keywords(\n",
    "        chunks = prompt_chunks\n",
    "    )\n",
    "\n",
    "    formatted_queries = {\n",
    "        'embeddings': embedding_queries,\n",
    "        'keywords': keyword_queries\n",
    "    }\n",
    "\n",
    "    return formatted_queries\n",
    "\n",
    "def calculate_keyword_score(\n",
    "    self,\n",
    "    keyword_query: str,\n",
    "    keyword_list: any\n",
    ") -> any:\n",
    "    match = 0\n",
    "    asked_keywords = keyword_query.split('OR')\n",
    "    for asked_keyword in asked_keywords:\n",
    "        formatted = asked_keyword.replace('keywords =', '')\n",
    "        formatted = formatted.replace('\"', '')\n",
    "        formatted = formatted.replace(' ', '')\n",
    "        \n",
    "        if formatted in keyword_list:\n",
    "            match += 1\n",
    "            \n",
    "    query_length = len(asked_keywords)\n",
    "    keyword_length = len(keyword_list)\n",
    "\n",
    "    if match == 0:\n",
    "        return 0.0\n",
    "\n",
    "    normalized = match / ((query_length * keyword_length) ** 0.5)\n",
    "    return normalized\n",
    "\n",
    "def get_vector_hits(\n",
    "    self,\n",
    "    vector_client: any,\n",
    "    configuration: any,\n",
    "    embedding_queries: any\n",
    ") -> any:\n",
    "    recommeded_cases = []\n",
    "\n",
    "    collections = self.qdrant_list_collections(\n",
    "        qdrant_client = vector_client\n",
    "    )\n",
    "    for collection in collections:\n",
    "        for embedding in embedding_queries:\n",
    "            results = self.qdrant_search_vectors(\n",
    "                qdrant_client = vector_client,  \n",
    "                collection_name = collection,\n",
    "                query_vector = embedding,\n",
    "                limit = configuration['top-k']\n",
    "            ) \n",
    "            \n",
    "            for result in results:\n",
    "                res_database = result.payload['database']\n",
    "                res_collection = result.payload['collection']\n",
    "                res_document = result.payload['document']\n",
    "                res_type = result.payload['type']\n",
    "                res_score = result.score\n",
    "                \n",
    "                res_case = {\n",
    "                    'source': 'vector',\n",
    "                    'database': res_database,\n",
    "                    'collection': res_collection,\n",
    "                    'document': res_document,\n",
    "                    'type': res_type,\n",
    "                    'score': res_score\n",
    "                }\n",
    "                \n",
    "                recommeded_cases.append(res_case)\n",
    "    return recommeded_cases\n",
    "\n",
    "def get_search_hits(\n",
    "    self,\n",
    "    search_client: any,\n",
    "    configuration: any,\n",
    "    keyword_queries: any\n",
    ") -> any:\n",
    "    recommeded_cases = []\n",
    "    collections = self.meili_list_indexes(\n",
    "        meili_client = search_client\n",
    "    )\n",
    "    \n",
    "    for collection in collections:        \n",
    "        for keywords in keyword_queries:\n",
    "            results = self.meili_search_documents(\n",
    "                meili_client = search_client, \n",
    "                index_name = collection, \n",
    "                query = \"\", \n",
    "                options = {\n",
    "                    'filter': keywords,\n",
    "                    'attributesToRetrieve': ['database','collection','document', 'type', 'keywords'],\n",
    "                    'limit': configuration['top-k']\n",
    "                }\n",
    "            )\n",
    "    \n",
    "            for result in results['hits']:\n",
    "                res_database = result['database']\n",
    "                res_collection = result['collection']\n",
    "                res_document = result['document']\n",
    "                res_type = result['type']\n",
    "                res_keywords = result['keywords']\n",
    "                \n",
    "                \n",
    "                res_score = self.calculate_keyword_score(\n",
    "                    keyword_query = keywords,\n",
    "                    keyword_list = res_keywords\n",
    "                )\n",
    "    \n",
    "                res_case = {\n",
    "                    'source': 'search',\n",
    "                    'database': res_database,\n",
    "                    'collection': res_collection,\n",
    "                    'document': res_document,\n",
    "                    'type': res_type,\n",
    "                    'score': res_score\n",
    "                }\n",
    "    \n",
    "                recommeded_cases.append(res_case)\n",
    "    return recommeded_cases\n",
    "    \n",
    "def get_vector_search_hits(\n",
    "    self,\n",
    "    vector_client: any,\n",
    "    search_client: any,\n",
    "    configuration: any,\n",
    "    queries: any\n",
    ") -> any:\n",
    "    vector_hits = self.get_vector_hits(\n",
    "        vector_client = vector_client,\n",
    "        configuration = configuration,\n",
    "        embedding_queries = queries['embeddings']\n",
    "    )\n",
    "    \n",
    "    search_hits = self.get_search_hits(\n",
    "        search_client = search_client,\n",
    "        configuration = configuration,\n",
    "        keyword_queries = queries['keywords']\n",
    "    )\n",
    "\n",
    "    found_hits = vector_hits + search_hits\n",
    "\n",
    "    return found_hits\n",
    "\n",
    "def filter_hit_documents(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    hits: any\n",
    ") -> any:\n",
    "    df = pd.DataFrame(hits)\n",
    "    ids_with_both = df.groupby('document')['source'].nunique()\n",
    "    ids_with_both = ids_with_both[ids_with_both > 1].index\n",
    "    filtered_df = df[df['document'].isin(ids_with_both)]\n",
    "    return filtered_df\n",
    "\n",
    "def match_hit_documents(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    filtered_df: any\n",
    ") -> any:\n",
    "    alpha = configuration['alpha']\n",
    "    matched_documents = []\n",
    "    for index_i, row_i in filtered_df[filtered_df['source'] == 'vector'].iterrows():\n",
    "        vector_source = row_i['source']\n",
    "        vector_database = row_i['database']\n",
    "        vector_collection = row_i['collection']\n",
    "        vector_id = row_i['document']\n",
    "        vector_type = row_i['type']\n",
    "        vector_score = row_i['score']\n",
    "        \n",
    "        for index_j, row_j in filtered_df[filtered_df['source'] == 'search'].iterrows():\n",
    "            search_source = row_j['source']\n",
    "            search_database = row_j['database']\n",
    "            search_collection = row_j['collection']\n",
    "            search_id = row_j['document']\n",
    "            search_type = row_j['type']\n",
    "            search_score = row_j['score']\n",
    "            \n",
    "            if vector_database == search_database:\n",
    "                if vector_collection == search_collection:\n",
    "                    if vector_type == search_type:\n",
    "                        if vector_id == search_id:\n",
    "                            hybrid_score = vector_score * alpha + search_score * (1-alpha)\n",
    "    \n",
    "                            matched_documents.append({\n",
    "                                'source': 'hybrid',\n",
    "                                'database': search_database,\n",
    "                                'collection': search_collection,\n",
    "                                'document': search_id,\n",
    "                                'score': hybrid_score\n",
    "                            })\n",
    "    match_df = pd.DataFrame(matched_documents)\n",
    "    return match_df\n",
    "\n",
    "def select_context_documents(\n",
    "    self,\n",
    "    configuration: any,\n",
    "    matched_df: any\n",
    ") -> any:\n",
    "    sorted_df = matched_df.sort_values('score', ascending = False)\n",
    "    seen_documents = []\n",
    "    context_documents = []\n",
    "    for row in sorted_df.values.tolist():\n",
    "        row_id = row[3]\n",
    "        if not row_id in seen_documents and len(context_documents) <= configuration['context-amount']:\n",
    "            seen_documents.append(row_id)\n",
    "            context_documents.append(row)\n",
    "    return context_documents\n",
    "\n",
    "def get_top_documents(\n",
    "    self,\n",
    "    hits: str,\n",
    "    configuration: any\n",
    ") -> any:\n",
    "    filtered_df = self.filter_hit_documents(\n",
    "        configuration = configuration,\n",
    "        hits = hits\n",
    "    )\n",
    "\n",
    "    matched_df = self.match_hit_documents(\n",
    "        configuration = configuration,\n",
    "        filtered_df = filtered_df\n",
    "    ) \n",
    "\n",
    "    context_documents = self.select_context_documents(\n",
    "        configuration = configuration,\n",
    "        matched_df = matched_df\n",
    "    )\n",
    "    \n",
    "    return context_documents\n",
    "\n",
    "def create_context(\n",
    "    self,\n",
    "    mongo_client: any,\n",
    "    documents: any\n",
    ") -> any:\n",
    "    context = ''\n",
    "    for metadata in documents:\n",
    "        database = metadata[1]\n",
    "        collection = metadata[2]\n",
    "        document = metadata[3]\n",
    "        data = self.mongo_get_document(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database, \n",
    "            collection_name = collection, \n",
    "            filter_query = {\n",
    "                '_id': ObjectId(document)\n",
    "            }\n",
    "        )\n",
    "        context += data['data']\n",
    "    return context\n",
    "\n",
    "def context_pipeline(\n",
    "    self,\n",
    "    document_client: any,\n",
    "    vector_client: any,\n",
    "    search_client: any,\n",
    "    configuration: any,\n",
    "    prompt: any\n",
    ") -> any:\n",
    "\n",
    "    print('Creating queries')\n",
    "\n",
    "    prompt_query = self.generate_prompt_queries(\n",
    "        configuration = configuration,\n",
    "        prompt = prompt\n",
    "    )\n",
    "\n",
    "    print('Getting hits')\n",
    "\n",
    "    prompt_hits = self.get_vector_search_hits(\n",
    "        vector_client = vector_client,\n",
    "        search_client = search_client,\n",
    "        configuration = configuration,\n",
    "        queries = prompt_query\n",
    "    )\n",
    "    \n",
    "    print('Getting top documents')\n",
    "\n",
    "    prompt_documents = self.get_top_documents(\n",
    "        hits = prompt_hits,\n",
    "        configuration = configuration\n",
    "    ) \n",
    "\n",
    "    print('Creating context')\n",
    "\n",
    "    prompt_context = self.create_context(\n",
    "        mongo_client = document_client,\n",
    "        documents = prompt_documents\n",
    "    )\n",
    "\n",
    "    return prompt_context\n",
    "\n",
    "def get_context(\n",
    "    self,\n",
    "    prompt: str\n",
    ") -> str:\n",
    "    \n",
    "    print('Creating clients')\n",
    "    mongo_client = self.mongo_setup_client(\n",
    "        username = self.valves.MONGO_USER,\n",
    "        password = self.valves.MONGO_PASSWORD,\n",
    "        address = self.valves.MONGO_ADDRESS,\n",
    "        port = self.valves.MONGO_PORT\n",
    "    )\n",
    "\n",
    "    qdrant_client = self.qdrant_setup_client(\n",
    "        api_key = self.valves.QDRANT_KEY,\n",
    "        address = self.valves.QDRANT_ADDRESS, \n",
    "        port = self.valves.QDRANT_PORT\n",
    "    )\n",
    "\n",
    "    meili_client = self.meili_setup_client(\n",
    "        host = self.valves.MEILI_HOST, \n",
    "        api_key = self.valves.MEILI_KEY\n",
    "    )\n",
    "    print('Clients setup')\n",
    "\n",
    "    pipeline_configuration = {\n",
    "        'chunk-size': 50,\n",
    "        'chunk-overlap': 0,\n",
    "        'model-name': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "        'top-k': 10,\n",
    "        'alpha': 0.5,\n",
    "        'context-amount': 5\n",
    "    }\n",
    "\n",
    "    print('Running context pipeline')\n",
    "    created_context = self.context_pipeline(\n",
    "        document_client = mongo_client,\n",
    "        vector_client = qdrant_client,\n",
    "        search_client = meili_client,\n",
    "        configuration = pipeline_configuration ,\n",
    "        prompt = prompt\n",
    "    )\n",
    "    print('Context pipeline run')\n",
    "\n",
    "    return created_context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
