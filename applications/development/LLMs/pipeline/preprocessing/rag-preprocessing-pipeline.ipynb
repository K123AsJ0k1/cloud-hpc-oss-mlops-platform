{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c60297-972e-4dab-bc4c-7852198fbd18",
   "metadata": {},
   "source": [
    "# Demonstration RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77dd7dd-5daa-4b84-a256-93a588e8db06",
   "metadata": {},
   "source": [
    "## Istio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfc7136-3404-4358-bf05-38cc88883ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "def get_istio_auth_session(url: str, username: str, password: str) -> dict:\n",
    "    \"\"\"\n",
    "    Determine if the specified URL is secured by Dex and try to obtain a session cookie.\n",
    "    WARNING: only Dex `staticPasswords` and `LDAP` authentication are currently supported\n",
    "             (we default default to using `staticPasswords` if both are enabled)\n",
    "\n",
    "    :param url: Kubeflow server URL, including protocol\n",
    "    :param username: Dex `staticPasswords` or `LDAP` username\n",
    "    :param password: Dex `staticPasswords` or `LDAP` password\n",
    "    :return: auth session information\n",
    "    \"\"\"\n",
    "    # define the default return object\n",
    "    auth_session = {\n",
    "        \"endpoint_url\": url,    # KF endpoint URL\n",
    "        \"redirect_url\": None,   # KF redirect URL, if applicable\n",
    "        \"dex_login_url\": None,  # Dex login URL (for POST of credentials)\n",
    "        \"is_secured\": None,     # True if KF endpoint is secured\n",
    "        \"session_cookie\": None  # Resulting session cookies in the form \"key1=value1; key2=value2\"\n",
    "    }\n",
    "\n",
    "    # use a persistent session (for cookies)\n",
    "    with requests.Session() as s:\n",
    "\n",
    "        ################\n",
    "        # Determine if Endpoint is Secured\n",
    "        ################\n",
    "        resp = s.get(url, allow_redirects=True)\n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(\n",
    "                f\"HTTP status code '{resp.status_code}' for GET against: {url}\"\n",
    "            )\n",
    "\n",
    "        auth_session[\"redirect_url\"] = resp.url\n",
    "\n",
    "        # if we were NOT redirected, then the endpoint is UNSECURED\n",
    "        if len(resp.history) == 0:\n",
    "            auth_session[\"is_secured\"] = False\n",
    "            return auth_session\n",
    "        else:\n",
    "            auth_session[\"is_secured\"] = True\n",
    "\n",
    "        ################\n",
    "        # Get Dex Login URL\n",
    "        ################\n",
    "        redirect_url_obj = urlsplit(auth_session[\"redirect_url\"])\n",
    "\n",
    "        # if we are at `/auth?=xxxx` path, we need to select an auth type\n",
    "        if re.search(r\"/auth$\", redirect_url_obj.path):\n",
    "\n",
    "            #######\n",
    "            # TIP: choose the default auth type by including ONE of the following\n",
    "            #######\n",
    "\n",
    "            # OPTION 1: set \"staticPasswords\" as default auth type\n",
    "            redirect_url_obj = redirect_url_obj._replace(\n",
    "                path=re.sub(r\"/auth$\", \"/auth/local\", redirect_url_obj.path)\n",
    "            )\n",
    "            # OPTION 2: set \"ldap\" as default auth type\n",
    "            # redirect_url_obj = redirect_url_obj._replace(\n",
    "            #     path=re.sub(r\"/auth$\", \"/auth/ldap\", redirect_url_obj.path)\n",
    "            # )\n",
    "\n",
    "        # if we are at `/auth/xxxx/login` path, then no further action is needed (we can use it for login POST)\n",
    "        if re.search(r\"/auth/.*/login$\", redirect_url_obj.path):\n",
    "            auth_session[\"dex_login_url\"] = redirect_url_obj.geturl()\n",
    "\n",
    "        # else, we need to be redirected to the actual login page\n",
    "        else:\n",
    "            # this GET should redirect us to the `/auth/xxxx/login` path\n",
    "            resp = s.get(redirect_url_obj.geturl(), allow_redirects=True)\n",
    "            if resp.status_code != 200:\n",
    "                raise RuntimeError(\n",
    "                    f\"HTTP status code '{resp.status_code}' for GET against: {redirect_url_obj.geturl()}\"\n",
    "                )\n",
    "\n",
    "            # set the login url\n",
    "            auth_session[\"dex_login_url\"] = resp.url\n",
    "\n",
    "        ################\n",
    "        # Attempt Dex Login\n",
    "        ################\n",
    "        resp = s.post(\n",
    "            auth_session[\"dex_login_url\"],\n",
    "            data={\"login\": username, \"password\": password},\n",
    "            allow_redirects=True\n",
    "        )\n",
    "        if len(resp.history) == 0:\n",
    "            raise RuntimeError(\n",
    "                f\"Login credentials were probably invalid - \"\n",
    "                f\"No redirect after POST to: {auth_session['dex_login_url']}\"\n",
    "            )\n",
    "\n",
    "        # store the session cookies in a \"key1=value1; key2=value2\" string\n",
    "        auth_session[\"session_cookie\"] = \"; \".join([f\"{c.name}={c.value}\" for c in s.cookies])\n",
    "\n",
    "    return auth_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b565a2b-32aa-4662-9be5-c5a55d098a2a",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378b1067-8226-4af2-a924-18af14db33ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created and works\n",
    "def set_formatted_user(\n",
    "    user: str   \n",
    ") -> any:\n",
    "    return re.sub(r'[^a-z0-9]+', '-', user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd09df-d3ae-437f-b849-7d89380c4e14",
   "metadata": {},
   "source": [
    "## SWIFT Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e7f56e-06e1-4802-b7d6-de3a3be2c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config,RepositoryEnv\n",
    "\n",
    "from keystoneauth1 import loading, session\n",
    "from keystoneauth1.identity import v3\n",
    "from keystoneclient.v3 import client as keystone_client\n",
    "\n",
    "import swiftclient as sc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06221118-bc13-45e2-8e67-d30af5eba5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works\n",
    "def is_swift_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, sc.Connection)\n",
    "# Works\n",
    "def swift_setup_client(\n",
    "    pre_auth_url: str,\n",
    "    pre_auth_token: str,\n",
    "    user_domain_name: str,\n",
    "    project_domain_name: str,\n",
    "    project_name: str,\n",
    "    auth_version: str\n",
    ") -> any:\n",
    "    swift_client = sc.Connection(\n",
    "        preauthurl = pre_auth_url,\n",
    "        preauthtoken = pre_auth_token,\n",
    "        os_options = {\n",
    "            'user_domain_name': user_domain_name,\n",
    "            'project_domain_name': project_domain_name,\n",
    "            'project_name': project_name\n",
    "        },\n",
    "        auth_version = auth_version\n",
    "    )\n",
    "    return swift_client\n",
    "# Works\n",
    "def swift_create_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.put_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "# Works\n",
    "def swift_check_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name:str\n",
    ") -> any:\n",
    "    try:\n",
    "        bucket_info = swift_client.get_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        bucket_metadata = bucket_info[0]\n",
    "        list_of_objects = bucket_info[1]\n",
    "        return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "# Refactored\n",
    "def swift_delete_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.delete_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "# Created\n",
    "def swift_list_buckets(\n",
    "    swift_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        account_buckets = swift_client.get_account()[1]\n",
    "        buckets = {}\n",
    "        for bucket in account_buckets:\n",
    "            bucket_name = bucket['name']\n",
    "            bucket_count = bucket['count']\n",
    "            bucket_size = bucket['bytes']\n",
    "            buckets[bucket_name] = {\n",
    "                'amount': bucket_count,\n",
    "                'size': bucket_size\n",
    "            }\n",
    "        return buckets\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "# Works\n",
    "def swift_create_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool: \n",
    "    # This should be updated to handle 5 GB objects\n",
    "    # It also should handle metadata\n",
    "    try:\n",
    "        swift_client.put_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path,\n",
    "            contents = object_data,\n",
    "            headers = object_metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "# Works\n",
    "def swift_check_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_metadata = swift_client.head_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path\n",
    "        )       \n",
    "        return object_metadata\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "# Refactored\n",
    "def swift_get_object(\n",
    "    swift_client:any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    # This should handle metadata\n",
    "    try:\n",
    "        response = swift_client.get_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path \n",
    "        )\n",
    "        object_info = response[0]\n",
    "        object_data = response[1]\n",
    "        return {'data': object_data, 'info': object_info}\n",
    "    except Exception as e:\n",
    "        return {}     \n",
    "# Refactored   \n",
    "def swift_remove_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        swift_client.delete_object(\n",
    "            container = bucket_name, \n",
    "            obj = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "# Works\n",
    "def swift_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool:  \n",
    "    remove = swift_remove_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not remove:\n",
    "        return False\n",
    "    create = swift_create_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path, \n",
    "        object_data = object_data,\n",
    "        object_metadata = object_metadata\n",
    "    )\n",
    "    return create\n",
    "# Works\n",
    "def swift_create_or_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    bucket_info = swift_check_bucket(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    \n",
    "    if len(bucket_info) == 0:\n",
    "        creation_status = swift_create_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    \n",
    "    object_info = swift_check_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    \n",
    "    if len(object_info) == 0:\n",
    "        return swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "    else:\n",
    "        return swift_update_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176951f-a1f1-48b2-8dc3-e52f318662bd",
   "metadata": {},
   "source": [
    "## Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7564dc0e-94f2-42d6-85f8-afcd2498015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-2-2\n",
    "\n",
    "# Refactored and Works\n",
    "def set_encoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    encoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            encoded_key = key_initial + '-' + key\n",
    "            if isinstance(value, list):\n",
    "                encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                continue\n",
    "            encoded_metadata[encoded_key] = str(value)\n",
    "    return encoded_metadata\n",
    "# Refactored and works\n",
    "def get_general_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    general_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if not key_initial == key[:len(key_initial)]:\n",
    "                general_metadata[key] = value\n",
    "    return general_metadata\n",
    "# Refactored and works\n",
    "def get_decoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any: \n",
    "    decoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if key_initial == key[:len(key_initial)]:\n",
    "                decoded_key = key[len(key_initial) + 1:]\n",
    "                if 'list=' in value:\n",
    "                    string_integers = value.split('=')[1]\n",
    "                    values = string_integers.split(',')\n",
    "                    if len(values) == 1 and values[0] == '':\n",
    "                        decoded_metadata[decoded_key] = []\n",
    "                    else:\n",
    "                        try:\n",
    "                            decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                        except:\n",
    "                            decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                    continue\n",
    "                if value.isnumeric():\n",
    "                    decoded_metadata[decoded_key] = int(value)\n",
    "                    continue\n",
    "                decoded_metadata[decoded_key] = value\n",
    "    return decoded_metadata\n",
    "# Refactored and works\n",
    "def set_bucket_names(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_names = []\n",
    "    bucket_prefix = storage_parameters['bucket-prefix']\n",
    "    ice_id = storage_parameters['ice-id']\n",
    "    user = storage_parameters['user']\n",
    "    storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "    storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    return storage_names\n",
    "# Refactored and works\n",
    "def setup_storage_client(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = None\n",
    "    if storage_parameters['used-client'] == 'swift':\n",
    "        storage_client = swift_setup_client(\n",
    "            pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "            pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "            user_domain_name = storage_parameters['user-domain-name'],\n",
    "            project_domain_name = storage_parameters['project-domain-name'],\n",
    "            project_name = storage_parameters['project-name'],\n",
    "            auth_version = storage_parameters['auth-version']\n",
    "        )\n",
    "    return storage_client\n",
    "# Refactored and works\n",
    "def check_object_metadata(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    object_metadata = {\n",
    "        'general-meta': {},\n",
    "        'custom-meta': {}\n",
    "    }\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        all_metadata = swift_check_object(\n",
    "           swift_client = storage_client,\n",
    "           bucket_name = bucket_name,\n",
    "           object_path = object_path\n",
    "        ) \n",
    "\n",
    "        general_metadata = {}\n",
    "        custom_metadata = {}\n",
    "        if not len(all_metadata) == 0:\n",
    "            general_metadata = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "            custom_metadata = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "\n",
    "        object_metadata['general-meta'] = general_metadata\n",
    "        object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "    return object_metadata\n",
    "# Refactored and works\n",
    "def get_object_content(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    object_content = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        fetched_object = swift_get_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "        object_content['general-meta'] = get_general_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "        object_content['custom-meta'] = get_decoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "    return object_content\n",
    "# Refactored    \n",
    "def remove_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    removed = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        removed = swift_remove_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "    return removed\n",
    "# Refactored and works\n",
    "def create_or_update_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    success = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        formatted_data = pickle.dumps(object_data)\n",
    "        formatted_metadata = set_encoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "        success = swift_create_or_update_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path,\n",
    "            object_data = formatted_data,\n",
    "            object_metadata = formatted_metadata\n",
    "        )\n",
    "    return success\n",
    "# Created and works\n",
    "def format_bucket_metadata(\n",
    "    used_client: str,\n",
    "    bucket_metadata: any\n",
    ") -> any:\n",
    "    formatted_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        relevant_values = {\n",
    "            'x-container-object-count': 'object-count',\n",
    "            'x-container-bytes-used-actual': 'used-bytes',\n",
    "            'last-modified': 'date',\n",
    "            'content-type': 'type'\n",
    "        }\n",
    "        formatted_metadata = {}\n",
    "        for key,value in bucket_metadata.items():\n",
    "            if key in relevant_values:\n",
    "                formatted_key = relevant_values[key]\n",
    "                formatted_metadata[formatted_key] = value\n",
    "    return formatted_metadata\n",
    "# Created and works\n",
    "def format_bucket_objects(\n",
    "    used_client: str,\n",
    "    bucket_objects: any\n",
    ") -> any:\n",
    "    formatted_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket_object in bucket_objects:\n",
    "            formatted_object_metadata = {\n",
    "                'hash': 'id',\n",
    "                'bytes': 'used-bytes',\n",
    "                'last_modified': 'date'\n",
    "            }\n",
    "            object_key = None\n",
    "            object_metadata = {}\n",
    "            for key, value in bucket_object.items():\n",
    "                if key == 'name':\n",
    "                    object_key = value\n",
    "                if key in formatted_object_metadata:\n",
    "                    formatted_key = formatted_object_metadata[key]\n",
    "                    object_metadata[formatted_key] = value\n",
    "            formatted_objects[object_key] = object_metadata\n",
    "    return formatted_objects\n",
    "# Created and works\n",
    "def format_bucket_info(\n",
    "    used_client: str,\n",
    "    bucket_info: any\n",
    ") -> any:\n",
    "    bucket_metadata = {}\n",
    "    bucket_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        bucket_metadata = format_bucket_metadata(\n",
    "            used_client = used_client,\n",
    "            bucket_metadata = bucket_info['metadata']\n",
    "        )\n",
    "        bucket_objects = format_bucket_objects(\n",
    "            used_client = used_client,\n",
    "            bucket_objects = bucket_info['objects']\n",
    "        )\n",
    "    return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "# Created and works\n",
    "def get_bucket_info(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    bucket_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_bucket_info = swift_check_bucket(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        bucket_info = format_bucket_info(\n",
    "            used_client = 'swift',\n",
    "            bucket_info = unformatted_bucket_info\n",
    "        )\n",
    "    return bucket_info\n",
    "# Created and works\n",
    "def format_container_info(\n",
    "    used_client: str,\n",
    "    container_info: any\n",
    ") -> any:\n",
    "    formatted_container_info = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket in container_info:\n",
    "            bucket_name = bucket['name']\n",
    "            bucket_count = bucket['count']\n",
    "            bucket_size = bucket['bytes']\n",
    "            formatted_container_info[bucket_name] = {\n",
    "                'amount': bucket_count,\n",
    "                'size': bucket_size\n",
    "            }\n",
    "    return formatted_container_info\n",
    "# Created and works\n",
    "def get_container_info( \n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    container_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_container_info = swift_list_buckets(\n",
    "            swift_client = storage_client \n",
    "        )\n",
    "        container_info = format_container_info(\n",
    "            used_client = 'swift',\n",
    "            container_info = unformatted_container_info\n",
    "        )\n",
    "    return container_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120dd7c-01e4-4b9a-b6d9-88a045b074b4",
   "metadata": {},
   "source": [
    "## Object functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c109f5-f46c-4498-8b4f-6e254c07680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2-3\n",
    "\n",
    "# Created and works\n",
    "def set_object_path(\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    "):\n",
    "    object_paths = {\n",
    "        'root': 'name',\n",
    "        'code': 'CODE/name',\n",
    "        'slurm': 'CODE/SLURM/name',\n",
    "        'ray': 'CODE/RAY/name',\n",
    "        'data': 'DATA/name',\n",
    "        'artifacts': 'ARTIFACTS/name',\n",
    "        'time': 'TIMES/name'\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    path_split = object_paths[object_name].split('/')\n",
    "    for name in path_split:\n",
    "        if name in path_replacers:\n",
    "            replacer = path_replacers[name]\n",
    "            if 0 < len(replacer):\n",
    "                path_split[i] = replacer\n",
    "        i = i + 1\n",
    "    \n",
    "    if not len(path_names) == 0:\n",
    "        path_split.extend(path_names)\n",
    "\n",
    "    object_path = '/'.join(path_split)\n",
    "    print('Used object path:' + str(object_path))\n",
    "    return object_path\n",
    "# created and works\n",
    "def setup_storage(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = setup_storage_client(\n",
    "        storage_parameters = storage_parameters\n",
    "    ) \n",
    "    \n",
    "    storage_name = set_bucket_names(\n",
    "       storage_parameters = storage_parameters\n",
    "    )\n",
    "    \n",
    "    return storage_client, storage_name\n",
    "# Created and works\n",
    "def check_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> bool:\n",
    "    object_path = set_object_path(\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    # Consider making these functions object storage agnostic\n",
    "    object_metadata = check_object_metadata(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    object_metadata['path'] = object_path\n",
    "    return object_metadata\n",
    "# Created and works\n",
    "def get_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> any:\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "\n",
    "    object_data = None\n",
    "    if not len(checked_object['general-meta']) == 0:\n",
    "        # Consider making these functions object storage agnostic\n",
    "        object_data = get_object_content(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path']\n",
    "        )\n",
    "\n",
    "    return object_data\n",
    "# Created and Works\n",
    "def set_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any,\n",
    "    overwrite: bool,\n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    "):\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    \n",
    "    perform = True\n",
    "    if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "        perform = False\n",
    "    \n",
    "    if perform:\n",
    "        create_or_update_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path'],\n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "# Created and works\n",
    "def check_bucket(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    return get_bucket_info(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "# Created and works\n",
    "def check_buckets(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return get_container_info( \n",
    "        storage_client = storage_client\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c0da1-98e5-4dd7-bc95-3a1b37bdae7d",
   "metadata": {},
   "source": [
    "## Metadata Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705d1b2c-ab54-4036-a260-216116705248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created and works\n",
    "def general_object_metadata():\n",
    "    general_object_metadata = {\n",
    "        'version': 1\n",
    "    }\n",
    "    return general_object_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a77045-e806-4c4e-91fb-35ba564a97db",
   "metadata": {},
   "source": [
    "## Access Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12104ef1-ae44-433d-8683-a3b3668e0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storage_parameters(\n",
    "    env_path: str,\n",
    "    auth_url: str,\n",
    "    pre_auth_url: str,\n",
    "    auth_version: str,\n",
    "    bucket_prefix: str,\n",
    "    ice_id: str,\n",
    "    user: str\n",
    "):\n",
    "    env_config = Config(RepositoryEnv(env_path))\n",
    "    swift_auth_url = auth_url\n",
    "    swift_user = env_config.get('CSC_USERNAME')\n",
    "    swift_key = env_config.get('CSC_PASSWORD')\n",
    "    swift_project_name = env_config.get('CSC_PROJECT_NAME')\n",
    "    swift_user_domain_name = env_config.get('CSC_USER_DOMAIN_NAME')\n",
    "    swift_project_domain_name = env_config.get('CSC_USER_DOMAIN_NAME')\n",
    "\n",
    "    loader = loading.get_plugin_loader('password')\n",
    "    auth = loader.load_from_options(\n",
    "        auth_url = swift_auth_url,\n",
    "        username = swift_user,\n",
    "        password = swift_key,\n",
    "        project_name = swift_project_name,\n",
    "        user_domain_name = swift_user_domain_name,\n",
    "        project_domain_name = swift_project_domain_name\n",
    "    )\n",
    "\n",
    "    keystone_session = session.Session(\n",
    "        auth = auth\n",
    "    )\n",
    "    swift_token = keystone_session.get_token()\n",
    "\n",
    "    swift_pre_auth_url = pre_auth_url\n",
    "    swift_auth_version = auth_version\n",
    "\n",
    "    storage_parameters = {\n",
    "        'bucket-prefix': bucket_prefix,\n",
    "        'ice-id': ice_id,\n",
    "        'user': user,\n",
    "        'used-client': 'swift',\n",
    "        'pre-auth-url': str(swift_pre_auth_url),\n",
    "        'pre-auth-token': str(swift_token),\n",
    "        'user-domain-name': str(swift_user_domain_name),\n",
    "        'project-domain-name': str(swift_project_domain_name),\n",
    "        'project-name': str(swift_project_name),\n",
    "        'auth-version': str(swift_auth_version)\n",
    "    }\n",
    "\n",
    "    return storage_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac6498e-c272-40f1-9e87-5b89e985ff97",
   "metadata": {},
   "source": [
    "## Code Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24255089-c126-4c52-947d-9c214727c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactored\n",
    "def set_code(\n",
    "    storage_client: any,\n",
    "    storage_name: str,\n",
    "    file_path: str,\n",
    "    overwrite: bool\n",
    "):\n",
    "    file_data = None\n",
    "    print('User code storage:' + str(storage_name))\n",
    "    print('Used code path:' + str(file_path))\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_data = f.read()\n",
    "\n",
    "    path_split = file_path.split('/')\n",
    "    directory_name = path_split[-2]\n",
    "    file_name = path_split[-1]\n",
    "    \n",
    "    set_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = directory_name,\n",
    "        path_replacers = {\n",
    "            'name': file_name\n",
    "        },\n",
    "        path_names = [],\n",
    "        overwrite = overwrite,\n",
    "        object_data = file_data,\n",
    "        object_metadata = general_object_metadata()\n",
    "    )\n",
    "# Refactored\n",
    "def get_code(\n",
    "    storage_client: any,\n",
    "    storage_name: str,\n",
    "    code_type: str,\n",
    "    code_file: str\n",
    ") -> any:\n",
    "    print('User code storage:' + str(storage_name))\n",
    "    fetched_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = code_type,\n",
    "        path_replacers = {\n",
    "            'name': code_file\n",
    "        },\n",
    "        path_names = []\n",
    "    )\n",
    "    code_object = {\n",
    "        'data': fetched_object['data'],\n",
    "        'metadata': fetched_object['custom-meta']\n",
    "    }\n",
    "    return code_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b47bb6-4ffb-45d9-b84b-5ab2d9955a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_absolute_path = '/home/sfniila/.ssh/.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5964acbb-62e4-4c78-95ca-02fd39e4a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_parameters = get_storage_parameters(\n",
    "    env_path = env_absolute_path,\n",
    "    auth_url = 'https://pouta.csc.fi:5001/v3',\n",
    "    pre_auth_url = 'https://a3s.fi:443/swift/v1/AUTH_6698ff90e6704a74930c33d6b66f1b5b',\n",
    "    auth_version = '3',\n",
    "    bucket_prefix = 'llm',\n",
    "    ice_id = 's0-c0-u1',\n",
    "    user = 'user@example.com'\n",
    ")\n",
    "\n",
    "storage_client, storage_names = setup_storage(\n",
    "    storage_parameters = storage_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6070f557-160a-43e4-833b-ae23fcb0d7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llm-forwarder-s0-c0-u1',\n",
       " 'llm-submitter-s0-c0-u1-user-example-com',\n",
       " 'llm-pipeline-s0-c0-u1-user-example-com',\n",
       " 'llm-experiment-s0-c0-u1-user-example-com']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f622dd-ef42-4481-adac-b6480ba755fd",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b87834b-cf15-4513-9564-20230eda6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/llm_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-08 12:04:28,830\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from ray.job_submission import JobSubmissionClient\n",
    "from ray.job_submission import JobStatus\n",
    "import time as t\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def test_url(\n",
    "    target_url: str,\n",
    "    timeout: int\n",
    ") -> bool:\n",
    "    try:\n",
    "        response = requests.head(\n",
    "            url = target_url, \n",
    "            timeout = timeout\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        return False\n",
    "    except requests.ConnectionError:\n",
    "        return False\n",
    "\n",
    "def setup_ray(\n",
    "    services: any,\n",
    "    timeout: int\n",
    "):\n",
    "    start = t.time()\n",
    "    ray_client = None\n",
    "    if 0 < len(services):\n",
    "        ray_dashboard_url = 'http://' + services['ray-dashboard']\n",
    "        ray_exists = None\n",
    "        while t.time() - start <= timeout:\n",
    "            ray_exists = test_url(\n",
    "                target_url = ray_dashboard_url,\n",
    "                timeout = 5\n",
    "            )\n",
    "            if ray_exists:\n",
    "                break\n",
    "            t.sleep(5)\n",
    "        if ray_exists:\n",
    "            ray_client = JobSubmissionClient(\n",
    "                address = ray_dashboard_url\n",
    "            )\n",
    "    return ray_client\n",
    "\n",
    "def submit_ray_job(\n",
    "    ray_client: any,\n",
    "    ray_parameters: any,\n",
    "    ray_job_file: any,\n",
    "    working_directory: str,\n",
    "    ray_job_envs: any,\n",
    "    ray_job_packages: any\n",
    ") -> any:\n",
    "    command = \"python \" + str(ray_job_file)\n",
    "    if 0 < len(ray_parameters):\n",
    "        command = command + \" '\" + json.dumps(ray_parameters) + \"'\"\n",
    "    job_id = ray_client.submit_job(\n",
    "        entrypoint = command,\n",
    "        runtime_env = {\n",
    "            'working_dir': str(working_directory),\n",
    "            'env_vars': ray_job_envs,\n",
    "            'pip': ray_job_packages\n",
    "        }\n",
    "    )\n",
    "    return job_id\n",
    "\n",
    "def wait_ray_job(\n",
    "    ray_client: any,\n",
    "    ray_job_id: int, \n",
    "    waited_status: any,\n",
    "    timeout: int\n",
    ") -> any:\n",
    "    start = t.time()\n",
    "    job_status = None\n",
    "    while t.time() - start <= timeout:\n",
    "        status = ray_client.get_job_status(ray_job_id)\n",
    "        print(f\"status: {status}\")\n",
    "        if status in waited_status:\n",
    "            job_status = status\n",
    "            break\n",
    "        t.sleep(5)\n",
    "    job_logs = ray_client.get_job_logs(ray_job_id)\n",
    "    return job_status, job_logs\n",
    "\n",
    "def ray_job_handler(\n",
    "    ray_client: any,\n",
    "    ray_parameters: any,\n",
    "    ray_job_file: str,\n",
    "    ray_directory: str,\n",
    "    ray_job_envs: any,\n",
    "    ray_job_packages: any,\n",
    "    timeout: int\n",
    ") -> bool:\n",
    "    ray_job_id = submit_ray_job(\n",
    "        ray_client = ray_client,\n",
    "        ray_parameters = ray_parameters,\n",
    "        ray_job_file = ray_job_file,\n",
    "        working_directory = ray_directory,\n",
    "        ray_job_envs = ray_job_envs,\n",
    "        ray_job_packages = ray_job_packages\n",
    "    )\n",
    "\n",
    "    print('Ray batch job id: ' + str(ray_job_id))\n",
    "    \n",
    "    ray_job_status, ray_job_logs = wait_ray_job(\n",
    "        ray_client = ray_client,\n",
    "        ray_job_id = ray_job_id,\n",
    "        waited_status = {\n",
    "            JobStatus.SUCCEEDED, \n",
    "            JobStatus.STOPPED, \n",
    "            JobStatus.FAILED\n",
    "        }, \n",
    "        timeout = timeout\n",
    "    )\n",
    "    print('Ray batch job ended:')\n",
    "    success = True\n",
    "    if not ray_job_status == JobStatus.SUCCEEDED:\n",
    "        print('Ray batch job failed')\n",
    "        success = False\n",
    "    else:\n",
    "        print('Ray batch job succeeded')\n",
    "    print(ray_job_logs)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c204d-af93-4647-abab-bf3cd6936294",
   "metadata": {},
   "source": [
    "## Job Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed9f9235-d14a-465e-afac-a916379f5a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/pygithub.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/pygithub.py\n",
    "\n",
    "from github import Github\n",
    "\n",
    "def pygithub_get_repo_paths(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    contents = repo.get_contents(\"\")\n",
    "    paths = []\n",
    "    while len(contents) > 0:\n",
    "      file_content = contents.pop(0)\n",
    "      if file_content.type == 'dir':\n",
    "        contents.extend(repo.get_contents(file_content.path))\n",
    "      else:\n",
    "        paths.append(file_content.path)\n",
    "    g.close()\n",
    "    return paths\n",
    "\n",
    "def pygithub_get_path_content(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str, \n",
    "    path: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    file_content = repo.get_contents(path)\n",
    "    content = file_content.decoded_content.decode('utf-8')\n",
    "    g.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "742342bb-dba7-4fef-bc24-5c8c24f31f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/mongo_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/mongo_db.py\n",
    "\n",
    "from pymongo import MongoClient as mc\n",
    "\n",
    "def mongo_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, mc.Connection)\n",
    "\n",
    "def mongo_setup_client(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_check_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database_exists = database_name in mongo_client.list_database_names()\n",
    "        return database_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_list_databases(\n",
    "    mongo_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        databases = mongo_client.list_database_names()\n",
    "        return databases\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        mongo_client.drop_database(database_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_get_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_check_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        collection_exists = collection_name in database.list_collection_names()\n",
    "        return collection_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_update_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_many(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_collections(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collections = database.list_collection_names()\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try: \n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        database.drop_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_create_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    document: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.insert_one(document)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "\n",
    "def mongo_list_documents(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any,\n",
    "    sorting_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        documents = list(collection.find(filter_query).sort(sorting_query))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_update_document(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_one(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_remove_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    ") -> bool:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.delete_one(filter_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c433c31f-bca8-4683-9261-b53db20eed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/minio_os.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/minio_os.py\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "from minio import Minio\n",
    "\n",
    "def is_minio_client(\n",
    "    storage_client: any\n",
    ") -> bool:\n",
    "    return isinstance(storage_client, Minio)\n",
    "\n",
    "def minio_setup_client(\n",
    "    endpoint: str,\n",
    "    username: str,\n",
    "    password: str\n",
    ") -> any:\n",
    "    minio_client = Minio(\n",
    "        endpoint = endpoint, \n",
    "        access_key = username, \n",
    "        secret_key = password,\n",
    "        secure = False\n",
    "    )\n",
    "    return minio_client\n",
    "\n",
    "def minio_pickle_data(\n",
    "    data: any\n",
    ") -> any:\n",
    "    pickled_data = pickle.dumps(data)\n",
    "    length = len(pickled_data)\n",
    "    buffer = io.BytesIO()\n",
    "    buffer.write(pickled_data)\n",
    "    buffer.seek(0)\n",
    "    return buffer, length\n",
    "\n",
    "def minio_unpickle_data(\n",
    "    pickled: any\n",
    ") -> any:\n",
    "    return pickle.loads(pickled)\n",
    "\n",
    "def minio_create_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.make_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def minio_check_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        status = minio_client.bucket_exists(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket checking error')\n",
    "        print(e)\n",
    "        return False \n",
    "       \n",
    "def minio_delete_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        minio_client.remove_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def minio_create_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool: \n",
    "    # Be aware that MinIO objects have a size limit of 1GB, \n",
    "    # which might result to large header error    \n",
    "    \n",
    "    try:\n",
    "        buffer, length = minio_pickle_data(\n",
    "            data = data\n",
    "        )\n",
    "\n",
    "        minio_client.put_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path,\n",
    "            data = buffer,\n",
    "            length = length,\n",
    "            metadata = metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def minio_check_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path\n",
    "        )      \n",
    "        return object_info\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def minio_delete_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.remove_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def minio_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool:  \n",
    "    remove = minio_delete_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    if remove:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data,\n",
    "            metadata = metadata\n",
    "        )\n",
    "    return False\n",
    "\n",
    "def minio_create_or_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any, \n",
    "    metadata: dict\n",
    ") -> bool:\n",
    "    bucket_status = minio_check_bucket(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    if not bucket_status:\n",
    "        creation_status = minio_create_bucket(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    object_status = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not object_status:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "    else:\n",
    "        return minio_update_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "\n",
    "def minio_get_object_list(\n",
    "    minio_client: any,\n",
    "    bucket_name: str,\n",
    "    path_prefix: str\n",
    ") -> any:\n",
    "    try:\n",
    "        objects = minio_client.list_objects(\n",
    "            bucket_name = bucket_name, \n",
    "            prefix = path_prefix, \n",
    "            recursive = True\n",
    "        )\n",
    "        return objects\n",
    "    except Exception as e:\n",
    "        return None  \n",
    "    \n",
    "def minio_get_object_data_and_metadata(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any:\n",
    "    try:\n",
    "        given_object_data = minio_client.get_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        given_data = minio_unpickle_data(\n",
    "            pickled = given_object_data.data\n",
    "        )\n",
    "        \n",
    "        given_object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        given_metadata = given_object_info.metadata\n",
    "        \n",
    "        return {'data': given_data, 'metadata': given_metadata}\n",
    "    except Exception as e:\n",
    "        print('MinIO object fetching error')\n",
    "        print(e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "732d4724-0f15-4b67-9816-0465756e892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/get_documents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/get_documents.py\n",
    "\n",
    "from functions.minio_os import minio_check_object, minio_create_or_update_object, minio_get_object_data_and_metadata\n",
    "from functions.pygithub import pygithub_get_repo_paths\n",
    "\n",
    "def get_github_repo_documents(\n",
    "    object_client: any,\n",
    "    github_token: str,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    object_bucket: str,\n",
    "    repo_paths_object: str,\n",
    "    relevant_files: any,\n",
    "    replace: bool\n",
    ") -> any:\n",
    "    print('Fetching paths')\n",
    "\n",
    "    object_exists = minio_check_object(\n",
    "        minio_client = object_client,\n",
    "        bucket_name = object_bucket, \n",
    "        object_path = repo_paths_object\n",
    "    )\n",
    " \n",
    "    repo_paths = []\n",
    "    if replace == 'true' or not object_exists:\n",
    "        print('Getting github paths')\n",
    "\n",
    "        repo_paths = pygithub_get_repo_paths(\n",
    "            token = github_token,\n",
    "            owner = repository_owner, \n",
    "            name = repository_name\n",
    "        )\n",
    "\n",
    "        print('Storing paths')\n",
    "\n",
    "        minio_create_or_update_object(\n",
    "            minio_client = object_client,\n",
    "            bucket_name = object_bucket, \n",
    "            object_path = repo_paths_object,\n",
    "            data = repo_paths, \n",
    "            metadata = {}\n",
    "        )\n",
    "\n",
    "        print('Paths stored')\n",
    "    else:\n",
    "        print('Getting stored paths')\n",
    "        repo_paths = minio_get_object_data_and_metadata(\n",
    "            minio_client = object_client,\n",
    "            bucket_name = object_bucket, \n",
    "            object_path = repo_paths_object\n",
    "        )['data']\n",
    "\n",
    "    print('Filtering paths')\n",
    "    relevant_paths = []\n",
    "    for path in repo_paths:\n",
    "        path_split = path.split('/')\n",
    "        file_end = path_split[-1].split('.')[-1].rstrip()\n",
    "        if file_end in relevant_files:\n",
    "            relevant_paths.append(path.rstrip())\n",
    "    print('Paths filtered')\n",
    "\n",
    "    formatted_paths = {\n",
    "        'paths': relevant_paths\n",
    "    }\n",
    "\n",
    "    return formatted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d58c655d-ac39-4f18-bb71-47b3dfbf8a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/create_documents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/create_documents.py\n",
    "\n",
    "import re\n",
    "import yaml \n",
    "\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from functions.formatting_documents import extract_yaml_values, extract_jupyter_notebook_markdown_and_code, parse_jupyter_notebook_markdown_into_text\n",
    "from functions.tree_sitter import tree_create_python_code_and_function_documents\n",
    "\n",
    "def create_markdown_documents(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    \n",
    "    documents = []\n",
    "    document = ''\n",
    "    index = 1\n",
    "    for element in soup.descendants:\n",
    "        if element.name in ['h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            text = element.get_text(strip = True)\n",
    "            if not document == '':\n",
    "                document = document.replace('\\n', '')\n",
    "                if not len(document.split()) == 1:\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'markdown',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    index += 1\n",
    "                document = ''\n",
    "            document += text\n",
    "        elif element.name == 'p':\n",
    "            text = element.get_text(strip = True)\n",
    "            text = re.sub(code_block_pattern, '', text)\n",
    "            text = text.rstrip('\\n')\n",
    "            text = text.replace('\\nsh', '')\n",
    "            text = text.replace('\\nbash', '')\n",
    "            document += ' ' + text\n",
    "        elif element.name in ['ul', 'ol']:\n",
    "            text = ''\n",
    "            for li in element.find_all('li'):\n",
    "                item = li.get_text(strip=True)\n",
    "                if not '-' in item:\n",
    "                    text += '-' + item\n",
    "                    continue\n",
    "                text += item\n",
    "            document += ' ' + text\n",
    "            \n",
    "    documents.append({\n",
    "        'index': index,\n",
    "        'sub-index': 0,\n",
    "        'type': 'markdown',\n",
    "        'data': document\n",
    "    })\n",
    "    \n",
    "    formatted_documents = {\n",
    "        'text': documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents\n",
    "\n",
    "def create_yaml_documents(\n",
    "    yaml_text: any\n",
    ") -> any:\n",
    "    yaml_data = list(yaml.safe_load_all(yaml_text))\n",
    "\n",
    "    documents = []\n",
    "    index = 1\n",
    "    for data in yaml_data:\n",
    "        yaml_values = extract_yaml_values(\n",
    "            section = data,\n",
    "            path = '',\n",
    "            values = []\n",
    "        )\n",
    "\n",
    "        previous_root = ''\n",
    "        document = ''\n",
    "        sub_index = 1\n",
    "        for value in yaml_values:\n",
    "            equal_split = value.split('=')\n",
    "            path_split = equal_split[0].split('/')\n",
    "            root = path_split[0]\n",
    "            if not root == previous_root:\n",
    "                if 0 < len(document):\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': sub_index,\n",
    "                        'type': 'yaml',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    sub_index += 1\n",
    "                    \n",
    "                previous_root = root\n",
    "                document = value\n",
    "            else:\n",
    "                document += value\n",
    "                \n",
    "        documents.append({\n",
    "            'index': index,\n",
    "            'sub-index': sub_index,\n",
    "            'type': 'yaml',\n",
    "            'data': document\n",
    "        })\n",
    "        index += 1\n",
    "\n",
    "    formatted_documents = {\n",
    "        'text': documents\n",
    "    }\n",
    "            \n",
    "    return formatted_documents\n",
    "\n",
    "def create_python_documents(\n",
    "    python_text: any\n",
    "): \n",
    "    joined_code = ''.join(python_text)\n",
    "    block_code_documents = tree_create_python_code_and_function_documents(\n",
    "        code_document = joined_code\n",
    "    )\n",
    "    \n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    code_doc_index = 0\n",
    "    for code_doc in block_code_documents:\n",
    "        row_split = code_doc.split('\\n')\n",
    "        for row in row_split:\n",
    "            if 'function' in row and 'code' in row:\n",
    "                # This causes problems with some documents\n",
    "                # list index out of range\n",
    "                function_name = row.split(' ')[1]\n",
    "                if not function_name in seen_function_names:\n",
    "                    seen_function_names.append(function_name)\n",
    "                else:\n",
    "                    del block_code_documents[code_doc_index]\n",
    "        code_doc_index += 1\n",
    "    \n",
    "    if 0 < len(block_code_documents):\n",
    "        index = 1\n",
    "        for code_doc in block_code_documents:\n",
    "            code_documents.append({\n",
    "                'index': index,\n",
    "                'sub-index': 0,\n",
    "                'type': 'python',\n",
    "                'data': code_doc\n",
    "            })\n",
    "            index += 1\n",
    "   \n",
    "    formatted_documents = {\n",
    "        'code': code_documents\n",
    "    }\n",
    "    return formatted_documents\n",
    "\n",
    "def create_notebook_documents(\n",
    "    notebook_text: any\n",
    "):\n",
    "    notebook_documents = extract_jupyter_notebook_markdown_and_code(\n",
    "        notebook_text = notebook_text\n",
    "    )\n",
    "    \n",
    "    markdown_documents = []\n",
    "    for block in notebook_documents['markdown']:\n",
    "        joined_text = ''.join(block['data'])\n",
    "        markdown_text = parse_jupyter_notebook_markdown_into_text(\n",
    "            markdown_text = joined_text\n",
    "        )\n",
    "        markdown_documents.append({\n",
    "            'index': block['id'],\n",
    "            'sub-index': 0,\n",
    "            'type': 'markdown',\n",
    "            'data': markdown_text\n",
    "        })\n",
    "    \n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    for block in notebook_documents['code']:\n",
    "        joined_code = ''.join(block['data'])\n",
    "        block_code_documents = tree_create_python_code_and_function_documents(\n",
    "            code_document = joined_code\n",
    "        )\n",
    "\n",
    "        code_doc_index = 0\n",
    "        for code_doc in block_code_documents:\n",
    "            row_split = code_doc.split('\\n')\n",
    "            for row in row_split:\n",
    "                if 'function' in row and 'code' in row:\n",
    "                    # This causes problems with some documents\n",
    "                    # list index out of range\n",
    "                    function_name = row.split(' ')[1]\n",
    "                    if not function_name in seen_function_names:\n",
    "                        seen_function_names.append(function_name)\n",
    "                    else:\n",
    "                        del block_code_documents[code_doc_index]\n",
    "            code_doc_index += 1\n",
    "        \n",
    "        if 0 < len(block_code_documents):\n",
    "            sub_indexes = False\n",
    "            if 1 < len(block_code_documents):\n",
    "                sub_indexes = True\n",
    "            index = 1\n",
    "            for code_doc in block_code_documents:\n",
    "                if sub_indexes:\n",
    "                    code_documents.append({\n",
    "                        'index': block['id'],\n",
    "                        'sub-index': index, \n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                else:\n",
    "                    code_documents.append({ \n",
    "                        'index': block['id'],\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                index += 1\n",
    "    \n",
    "    formatted_documents = {\n",
    "        'text': markdown_documents,\n",
    "        'code': code_documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a748ccab-655a-4b81-bb1b-f4418eaef2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/formatting_documents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/formatting_documents.py\n",
    "\n",
    "import re\n",
    "import markdown\n",
    "import nbformat\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_yaml_values(\n",
    "    section: any,\n",
    "    path: str,\n",
    "    values: any\n",
    ") -> any:\n",
    "    for key, value in section.items():\n",
    "        if path == '':\n",
    "            current_path = key\n",
    "        else:\n",
    "            current_path = path + '/' + key\n",
    "        if isinstance(value, dict):\n",
    "            extract_yaml_values(\n",
    "                section = value,\n",
    "                path = current_path,\n",
    "                values = values\n",
    "            )\n",
    "        if isinstance(value, list):\n",
    "            number = 1\n",
    "            \n",
    "            for case in value:\n",
    "                base_path = current_path\n",
    "                if isinstance(case, dict):\n",
    "                   extract_yaml_values(\n",
    "                       section = case,\n",
    "                       path = current_path,\n",
    "                       values = values\n",
    "                   ) \n",
    "                   continue\n",
    "                base_path += '/' + str(number)\n",
    "                number += 1\n",
    "                values.append(base_path + '=' + str(case))\n",
    "        else:\n",
    "            if isinstance(value, dict):\n",
    "                continue\n",
    "            if isinstance(value, list):\n",
    "                continue\n",
    "            values.append(current_path + '=' + str(value))\n",
    "            \n",
    "    return values\n",
    "\n",
    "def parse_jupyter_notebook_markdown_into_text(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    text = soup.get_text()\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    text = re.sub(code_block_pattern, '', text)\n",
    "    text = text.rstrip('\\n')\n",
    "    text = text.replace('\\nsh', '\\n')\n",
    "    text = text.replace('\\nbash', '\\n')\n",
    "    return text\n",
    "\n",
    "def extract_jupyter_notebook_markdown_and_code(\n",
    "    notebook_text: any\n",
    "): \n",
    "    notebook_documents = {\n",
    "        'markdown': [],\n",
    "        'code': []\n",
    "    }\n",
    "\n",
    "    notebook = nbformat.reads(notebook_text, as_version=2)\n",
    "    index = 1\n",
    "    for cell in notebook.worksheets[0].cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            notebook_documents['markdown'].append({\n",
    "                'id': index,\n",
    "                'data': cell.source\n",
    "            })\n",
    "            index += 1\n",
    "        if cell.cell_type == 'code':\n",
    "            notebook_documents['code'].append({\n",
    "                'id': index,\n",
    "                'data': cell.input\n",
    "            })\n",
    "            index += 1\n",
    "    \n",
    "    return notebook_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e5aa76b-7d31-448f-bef2-1745a36136ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/tree_sitter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/tree_sitter.py\n",
    "\n",
    "import re\n",
    "\n",
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "def tree_extract_imports(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    imports = []\n",
    "    if node.type == 'import_statement' or node.type == 'import_from_statement':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        imports.append(code_text[start_byte:end_byte].decode('utf8'))\n",
    "    for child in node.children:\n",
    "        imports.extend(tree_extract_imports(child, code_text))\n",
    "    return imports\n",
    "\n",
    "def tree_extract_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    dependencies = []\n",
    "    for child in node.children:\n",
    "        if child.type == 'call':\n",
    "            dependency_name = child.child_by_field_name('function').text.decode('utf8')\n",
    "            dependencies.append(dependency_name)\n",
    "        dependencies.extend(tree_extract_dependencies(child, code_text))\n",
    "    return dependencies\n",
    "\n",
    "def tree_extract_code_and_dependencies(\n",
    "    node: any,\n",
    "    code_text: str\n",
    ") -> any:\n",
    "    codes = []\n",
    "    if not node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name')\n",
    "        if name is None:\n",
    "            code = code_text[start_byte:end_byte].decode('utf8')\n",
    "            if not 'def' in code:\n",
    "                dependencies = tree_extract_dependencies(node, code_text)\n",
    "                codes.append({\n",
    "                    'name': 'global',\n",
    "                    'code': code,\n",
    "                    'dependencies': dependencies\n",
    "                })\n",
    "    return codes\n",
    "\n",
    "def tree_extract_functions_and_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    functions = []\n",
    "    if node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name').text.decode('utf8')\n",
    "        code = code_text[start_byte:end_byte].decode('utf8')\n",
    "        dependencies = tree_extract_dependencies(node, code_text)\n",
    "        functions.append({\n",
    "            'name': name,\n",
    "            'code': code,\n",
    "            'dependencies': dependencies\n",
    "        })\n",
    "    for child in node.children:\n",
    "        functions.extend(tree_extract_functions_and_dependencies(child, code_text))\n",
    "    return functions\n",
    "\n",
    "def tree_get_used_imports(\n",
    "    general_imports: any,\n",
    "    function_dependencies: any\n",
    ") -> any:\n",
    "    parsed_imports = {}\n",
    "    for code_import in general_imports:\n",
    "        import_factors = code_import.split('import')[-1].replace(' ', '')\n",
    "        import_factors = import_factors.split(',')\n",
    "    \n",
    "        for factor in import_factors:\n",
    "            if not factor in parsed_imports:\n",
    "                parsed_imports[factor] = code_import.split('import')[0] + 'import ' + factor\n",
    "            \n",
    "    relevant_imports = {}\n",
    "    for dependency in function_dependencies:\n",
    "        initial_term = dependency.split('.')[0]\n",
    "    \n",
    "        if not initial_term in relevant_imports:\n",
    "            if initial_term in parsed_imports:\n",
    "                relevant_imports[initial_term] = parsed_imports[initial_term]\n",
    "    \n",
    "    used_imports = []\n",
    "    for name, code in relevant_imports.items():\n",
    "        used_imports.append(code)\n",
    "\n",
    "    return used_imports\n",
    "\n",
    "def tree_get_used_functions(\n",
    "    general_functions: any,\n",
    "    function_dependencies: any\n",
    "): \n",
    "    used_functions = []\n",
    "    for related_function_name in function_dependencies:\n",
    "        for function in general_functions:\n",
    "            if function['name'] == related_function_name:\n",
    "                used_functions.append('from ice import ' + function['name'])\n",
    "    return used_functions\n",
    "\n",
    "def tree_create_code_document(\n",
    "    code_imports: any,\n",
    "    code_functions: any,\n",
    "    function_item: any\n",
    ") -> any:\n",
    "    used_imports = tree_get_used_imports(\n",
    "        general_imports = code_imports,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "\n",
    "    used_functions = tree_get_used_functions(\n",
    "        general_functions = code_functions,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "    \n",
    "    document = {\n",
    "        'imports': used_imports,\n",
    "        'functions': used_functions,\n",
    "        'name': function_item['name'],\n",
    "        'dependencies': function_item['dependencies'],\n",
    "        'code': function_item['code']\n",
    "    }\n",
    "    \n",
    "    return document\n",
    "     \n",
    "def tree_format_code_document(\n",
    "    code_document: any\n",
    ") -> any:\n",
    "    formatted_document = ''\n",
    "    for doc_import in code_document['imports']:\n",
    "        formatted_document += doc_import + '\\n'\n",
    "\n",
    "    for doc_functions in code_document['functions']:\n",
    "        formatted_document += doc_functions + '\\n'\n",
    "\n",
    "    if 0 < len(code_document['dependencies']):\n",
    "        formatted_document += 'code dependencies\\n'\n",
    "\n",
    "        for doc_dependency in code_document['dependencies']:\n",
    "            formatted_document += doc_dependency + '\\n'\n",
    "\n",
    "    if code_document['name'] == 'global':\n",
    "        formatted_document += code_document['name'] + ' code\\n'\n",
    "    else:\n",
    "        formatted_document += 'function ' + code_document['name'] + ' code\\n'\n",
    "    \n",
    "    for line in code_document['code'].splitlines():\n",
    "        if not bool(line.strip()):\n",
    "            continue\n",
    "        doc_code = re.sub(r'#.*','', line)\n",
    "        if not bool(doc_code.strip()):\n",
    "            continue\n",
    "        formatted_document += doc_code + '\\n'    \n",
    "    return formatted_document\n",
    "\n",
    "def tree_create_python_code_and_function_documents(\n",
    "    code_document: any\n",
    "):\n",
    "    PY_LANGUAGE = Language(tspython.language())\n",
    "    parser = Parser(PY_LANGUAGE)\n",
    "\n",
    "    tree = parser.parse(\n",
    "        bytes(\n",
    "            code_document,\n",
    "            \"utf8\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    root_node = tree.root_node\n",
    "    code_imports = tree_extract_imports(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_global = tree_extract_code_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_functions = tree_extract_functions_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    initial_documents = []\n",
    "    for item in code_global:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    for item in code_functions:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    formatted_documents = []\n",
    "    seen_functions = []\n",
    "    for document in initial_documents:\n",
    "        if not document['name'] == 'global':\n",
    "            if document['name'] in seen_functions:\n",
    "                continue\n",
    "        \n",
    "        formatted_document = tree_format_code_document(\n",
    "            code_document = document\n",
    "        )\n",
    "\n",
    "        formatted_documents.append(formatted_document)\n",
    "        seen_functions.append(document['name'])\n",
    "\n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "314ed789-c717-4813-8050-027b5a261a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/functions/store_documents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/functions/store_documents.py\n",
    "\n",
    "from functions.pygithub import pygithub_get_path_content\n",
    "from functions.mongo_db import mongo_check_collection, mongo_create_document\n",
    "from functions.create_documents import create_markdown_documents, create_python_documents, create_notebook_documents, create_yaml_documents\n",
    "\n",
    "def store_repository_path_documents(\n",
    "    mongo_client: any,\n",
    "    github_token: any,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    repository_path: str,\n",
    "    database_name: str,\n",
    "    collection_name: str\n",
    "):\n",
    "    collection_exists = mongo_check_collection(\n",
    "        mongo_client = mongo_client, \n",
    "        database_name = database_name, \n",
    "        collection_name = collection_name\n",
    "    )\n",
    "\n",
    "    if collection_exists:\n",
    "        return False\n",
    "\n",
    "    target_content = ''\n",
    "    try:\n",
    "        target_content = pygithub_get_path_content(\n",
    "            token = github_token,\n",
    "            owner = repository_owner, \n",
    "            name = repository_name, \n",
    "            path = repository_path\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(repository_path)\n",
    "        print('Get content error')\n",
    "        print(e)\n",
    "\n",
    "    if target_content == '':\n",
    "        return False\n",
    "\n",
    "    path_split = repository_path.split('/')\n",
    "    target_type = path_split[-1].split('.')[-1]\n",
    "    \n",
    "    target_documents = {}\n",
    "    if target_type == 'md':\n",
    "        try:\n",
    "            target_documents = create_markdown_documents(\n",
    "                markdown_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print('Create markdown document error')\n",
    "            print(e)\n",
    "    if target_type == 'yaml':\n",
    "        try:\n",
    "            target_documents = create_yaml_documents(\n",
    "                yaml_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print('Create yaml document error')\n",
    "            print(e)\n",
    "    if target_type == 'py':\n",
    "        try:\n",
    "            target_documents = create_python_documents(\n",
    "                python_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print('Create python document error')\n",
    "            print(e)\n",
    "    if target_type == 'ipynb':\n",
    "        try:\n",
    "            target_documents = create_notebook_documents(\n",
    "                notebook_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print('Create notebook document error')\n",
    "            print(e)\n",
    "    if 0 < len(target_documents):\n",
    "        for doc_type, docs in target_documents.items():\n",
    "            for document in docs:\n",
    "                result = mongo_create_document(\n",
    "                    mongo_client = mongo_client,\n",
    "                    database_name = database_name,\n",
    "                    collection_name = collection_name,\n",
    "                    document = document\n",
    "                )\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_github_storage_prefix(\n",
    "    repository_owner: str,\n",
    "    repository_name: str\n",
    ") -> str:\n",
    "    return repository_owner + '|' + repository_name + '|'\n",
    "\n",
    "def store_github_repository_documents(\n",
    "    mongo_client: any,\n",
    "    github_token: str,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    repository_paths: any\n",
    ") -> any:\n",
    "    paths = repository_paths['paths']\n",
    "    for path in paths:\n",
    "        path_split = path.split('/')\n",
    "        document_database_name = get_github_storage_prefix(repository_owner, repository_name) + path_split[-1].split('.')[-1]\n",
    "        \n",
    "        document_collection_name = ''\n",
    "        for word in path_split[:-1]:\n",
    "            document_collection_name += word[:2] + '|'\n",
    "        document_collection_name += path_split[-1].split('.')[0]\n",
    "\n",
    "        stored = store_repository_path_documents(\n",
    "            mongo_client = mongo_client,\n",
    "            github_token = github_token,\n",
    "            repository_owner = repository_owner,\n",
    "            repository_name = repository_name,\n",
    "            repository_path = path,\n",
    "            database_name = document_database_name,\n",
    "            collection_name = document_collection_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de434c4-81b3-47dc-a3aa-3d3d1b75a7c5",
   "metadata": {},
   "source": [
    "## Fetching and Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d816d919-fb2f-439c-9fef-d75f1047ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ray/fetch-store-rag-data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ray/fetch-store-rag-data.py\n",
    "import sys\n",
    "import ray\n",
    "import json\n",
    "\n",
    "from functions.mongo_db import mongo_setup_client\n",
    "from functions.minio_os import minio_setup_client\n",
    "from functions.get_documents import get_github_repo_documents\n",
    "from functions.store_documents import store_github_repository_documents\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "@ray.remote\n",
    "def fetch_and_store_data(\n",
    "    storage_parameters: any,\n",
    "    data_parameters: any\n",
    "):\n",
    "    try:\n",
    "        print('Creating mongo client')\n",
    "        document_client = mongo_setup_client(\n",
    "            username = storage_parameters['mongo-username'],\n",
    "            password = storage_parameters['mongo-password'],\n",
    "            address = storage_parameters['mongo-address'],\n",
    "            port = storage_parameters['mongo-port']\n",
    "        )\n",
    "        print('Mongo client created')\n",
    "\n",
    "        print('Creating minio client')\n",
    "        object_client = minio_setup_client(\n",
    "            endpoint = storage_parameters['minio-endpoint'],\n",
    "            username = storage_parameters['minio-username'],\n",
    "            password = storage_parameters['minio-password']\n",
    "        )\n",
    "        print('Minio client created')\n",
    "        \n",
    "        github_token = data_parameters['github-token']\n",
    "        repository_owner = data_parameters['repository-owner']\n",
    "        repository_name = data_parameters['repository-name']\n",
    "        object_bucket = data_parameters['object-bucket']\n",
    "        repo_paths_object = data_parameters['repo-paths-object']\n",
    "        relevant_files = data_parameters['relevant-files']\n",
    "        replace = data_parameters['replace']\n",
    "\n",
    "        print('Getting repository paths')\n",
    "        \n",
    "        repository_paths = get_github_repo_documents(\n",
    "            object_client = object_client,\n",
    "            github_token = github_token,\n",
    "            repository_owner = repository_owner,\n",
    "            repository_name = repository_name,\n",
    "            object_bucket = object_bucket,\n",
    "            repo_paths_object = repo_paths_object,\n",
    "            relevant_files = relevant_files,\n",
    "            replace = replace\n",
    "        )\n",
    "\n",
    "        print('Storing repository documents')\n",
    "\n",
    "        store_github_repository_documents(\n",
    "            mongo_client = document_client,\n",
    "            github_token = github_token,\n",
    "            repository_owner = repository_owner, \n",
    "            repository_name = repository_name, \n",
    "            repository_paths = repository_paths\n",
    "        )\n",
    "\n",
    "        print('Documents stored')\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Fetch and store error')\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Starting ray job')\n",
    "    print('Python version is:' + str(sys.version))\n",
    "    print('Ray version is:' + version('Ray'))\n",
    "    print('PyGithub version is:' + version('PyGithub'))\n",
    "    print('PyMongo version is:' + version('PyMongo'))\n",
    "    print('Markdown version is:' + version('Markdown'))\n",
    "    print('Tree-sitter version is:' + version('tree-sitter'))\n",
    "    print('Tree-sitter-python version is:' + version('tree-sitter-python'))\n",
    "    print('BeautifulSoup version is:' + version('beautifulsoup4'))\n",
    "    print('NBformat version is:' + version('nbformat'))\n",
    "    \n",
    "    input = json.loads(sys.argv[1])\n",
    "\n",
    "    storage_parameters = input['storage-parameters']\n",
    "    data_parameters = input['data-parameters']\n",
    "\n",
    "    print('Running fetch and store')\n",
    "    \n",
    "    fetch_store_status = ray.get(fetch_and_store_data.remote(\n",
    "        storage_parameters = storage_parameters,\n",
    "        data_parameters = data_parameters\n",
    "    ))\n",
    "\n",
    "    print('Fetch and store success:' + str(fetch_store_status))\n",
    "\n",
    "    print('Ray job Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2415b6f0-38ed-4337-9d0d-e84e63388882",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_client = setup_ray(\n",
    "    services = {\n",
    "        'ray-dashboard': '127.0.0.1:8265'\n",
    "    },\n",
    "    timeout = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbc16652-774f-44ec-8126-7f3a1dbabafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_parameters = {\n",
    "    'mongo-username': 'mongo123',\n",
    "    'mongo-password': 'mongo456',\n",
    "    'mongo-address': 'mongodb-service.llm.svc.cluster.local',\n",
    "    'mongo-port': '27017',\n",
    "    'minio-endpoint': 'mlflow-minio-service.mlflow.svc.cluster.local:9000',\n",
    "    'minio-username': 'minioadmin',\n",
    "    'minio-password': 'minioadmin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e504326-4d87-4cbb-b1ef-3f1dbcba1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config,RepositoryEnv\n",
    "env_path = '/home/sfniila/.ssh/.env'\n",
    "env_config = Config(RepositoryEnv(env_path))\n",
    "github_token = env_config.get('GITHUB_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "310ef2df-1493-4786-8a6c-1fa62f6fb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_owner = 'K123AsJ0k1'\n",
    "repository_name = 'cloud-hpc-oss-mlops-platform'\n",
    "object_bucket = 'llm-rag'\n",
    "repo_paths_object = repository_name + '-paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7a5f1ef-b450-4267-9012-535a47bb35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = {\n",
    "    'github-token': github_token,\n",
    "    'repository-owner': repository_owner,\n",
    "    'repository-name': repository_name,\n",
    "    'object-bucket': object_bucket,\n",
    "    'repo-paths-object': repo_paths_object,\n",
    "    'relevant-files': [\n",
    "        'md',\n",
    "        'yaml',\n",
    "        'py',\n",
    "        'ipynb'\n",
    "    ],\n",
    "    'replace': 'false'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "777d4eeb-7450-42fb-87cb-165eb6bd2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_store_parameters = {\n",
    "    'storage-parameters': storage_parameters,\n",
    "    'data-parameters': data_parameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aee5e145-4441-4bd3-9b10-458cde88a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:09:27,789\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_de37e93f8a241cd3.zip.\n",
      "2024-11-08 12:09:27,792\tINFO packaging.py:530 -- Creating a file package for local directory '/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/preprocessing/ray'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray batch job id: raysubmit_JQRmyEAcV9VZBh1J\n",
      "status: PENDING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: RUNNING\n",
      "status: SUCCEEDED\n",
      "Ray batch job ended:\n",
      "Ray batch job succeeded\n",
      "2024-11-08 02:09:27,897\tINFO job_manager.py:529 -- Runtime env is setting up.\n",
      "Starting ray job\n",
      "Python version is:3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0]\n",
      "Ray version is:2.38.0\n",
      "PyGithub version is:2.5.0\n",
      "PyMongo version is:4.10.1\n",
      "Markdown version is:3.7\n",
      "Tree-sitter version is:0.23.0\n",
      "Tree-sitter-python version is:0.23.0\n",
      "BeautifulSoup version is:4.12.3\n",
      "NBformat version is:5.10.4\n",
      "Running fetch and store\n",
      "2024-11-08 02:09:31,332\tINFO worker.py:1491 -- Using address 10.244.0.40:6379 set in the environment variable RAY_ADDRESS\n",
      "2024-11-08 02:09:31,332\tINFO worker.py:1631 -- Connecting to existing Ray cluster at address: 10.244.0.40:6379...\n",
      "2024-11-08 02:09:31,360\tINFO worker.py:1807 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://10.244.0.40:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Creating mongo client\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Mongo client created\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Creating minio client\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Minio client created\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Getting repository paths\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Fetching paths\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Getting stored paths\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Filtering paths\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Paths filtered\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Storing repository documents\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/RAG-Development.ipynb\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create notebook document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/RAG-pipeline.ipynb\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create notebook document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/RAG_Preprocessing.ipynb\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create notebook document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/scripts/documents.py\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create python document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/scripts/python_parsing.py\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create python document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m applications/development/LLMs/pipeline/preprocessing/scripts/platforms/tree.py\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create python document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m list index out of range\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/contrib/ray/kuberay-operator/base/resources.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Get content error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m unsupported encoding: none\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/eventing-core.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/in-memory-channel.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/mt-channel-broker.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/common/knative/knative-serving/base/upstream/net-istio.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/common/knative/knative-serving/base/upstream/serving-core.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-openshift/patches/service-serving-cert.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-openshift/patches/webhook-inject-cabundle.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-with-kubeflow/patches/enable-ui-authz-checks.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-with-kubeflow/patches/ui-rbac.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/openshift-pipelines-custom-task/pipelineloop-controller-patch.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/openshift-pipelines-custom-task/pipelineloop-webhook-patch.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/contrib/kserve/models-web-app/overlays/kubeflow/patches/web-app-vsvc.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/base/metadata/overlays/db/kustomization.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m could not determine a constructor for the tag 'tag:yaml.org,2002:value'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m   in \"<unicode string>\", line 41, column 18:\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m           delimiter: =\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m                      ^\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-dashboard/tekton-dashboard-release.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-controller.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-release.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/pipeline/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/pipeline/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-dashboard/tekton-dashboard-release.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-controller.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'list' object has no attribute 'items'\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-release.yaml\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Create yaml document error\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m 'NoneType' object has no attribute 'items'\n",
      "Fetch and store success:True\n",
      "Ray job Complete\n",
      "\u001b[36m(fetch_and_store_data pid=988)\u001b[0m Documents stored\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_status = ray_job_handler(\n",
    "    ray_client = ray_client,\n",
    "    ray_parameters = fetch_store_parameters,\n",
    "    ray_job_file = 'fetch-store-rag-data.py',\n",
    "    ray_directory = '/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/preprocessing/ray',\n",
    "    ray_job_envs = {},\n",
    "    ray_job_packages = [\n",
    "        'pymongo',\n",
    "        'minio',\n",
    "        'PyGithub',\n",
    "        'Markdown',\n",
    "        'tree-sitter==0.23.0',\n",
    "        'tree-sitter-python==0.23.0',\n",
    "        'beautifulsoup4',\n",
    "        'nbformat'\n",
    "    ],\n",
    "    timeout = 8000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cb4ca-f7c0-4435-92cc-58c70d22c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ray/preprocess-rag-data.py\n",
    "import sys\n",
    "import ray\n",
    "import json\n",
    "\n",
    "from pymongo import MongoClient as mc\n",
    "\n",
    "import re\n",
    "\n",
    "from pymongo import ASCENDING\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import hashlib\n",
    "import uuid\n",
    "import re\n",
    "from qdrant_client import QdrantClient as qc\n",
    "from qdrant_client import models\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from qdrant_client.models import PointStruct\n",
    "import spacy\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "from minio import Minio\n",
    "import meilisearch as ms\n",
    "\n",
    "def get_github_storage_prefix(\n",
    "    repository_owner: str,\n",
    "    repository_name: str\n",
    ") -> str:\n",
    "    return repository_owner + '|' + repository_name + '|'\n",
    "\n",
    "def mongo_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, mc.Connection)\n",
    "\n",
    "def mongo_setup_client(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_check_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database_exists = database_name in mongo_client.list_database_names()\n",
    "        return database_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_list_databases(\n",
    "    mongo_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        databases = mongo_client.list_database_names()\n",
    "        return databases\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        mongo_client.drop_database(database_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_get_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_check_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        collection_exists = collection_name in database.list_collection_names()\n",
    "        return collection_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_update_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_many(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_collections(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collections = database.list_collection_names()\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try: \n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        database.drop_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_create_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    document: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.insert_one(document)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "\n",
    "def mongo_list_documents(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any,\n",
    "    sorting_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        documents = list(collection.find(filter_query).sort(sorting_query))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_update_document(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_one(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_remove_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    ") -> bool:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.delete_one(filter_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def get_stored_documents(\n",
    "    mongo_client: any,\n",
    "    database_prefix: str\n",
    ") -> any:\n",
    "    storage_structure = {}\n",
    "    database_list = mongo_list_databases(\n",
    "        mongo_client = mongo_client\n",
    "    )\n",
    "    for database_name in database_list:\n",
    "        if database_prefix in database_name:\n",
    "            collection_list = mongo_list_collections(\n",
    "                mongo_client = mongo_client,\n",
    "                database_name = database_name\n",
    "            )\n",
    "            storage_structure[database_name] = collection_list\n",
    "    \n",
    "    storage_documents = {}\n",
    "    for database_name, collections in storage_structure.items():\n",
    "        if not database_name in storage_documents:\n",
    "            storage_documents[database_name] = {}\n",
    "        for collection_name in collections:\n",
    "            collection_documents = mongo_list_documents(\n",
    "                mongo_client = mongo_client,\n",
    "                database_name = database_name,\n",
    "                collection_name = collection_name,\n",
    "                filter_query = {},\n",
    "                sorting_query = [\n",
    "                    ('index', ASCENDING),\n",
    "                    ('sub-index', ASCENDING)\n",
    "                ]\n",
    "            )\n",
    "            storage_documents[database_name][collection_name] = collection_documents\n",
    "            \n",
    "    return storage_documents\n",
    "\n",
    "def is_minio_client(\n",
    "    storage_client: any\n",
    ") -> bool:\n",
    "    return isinstance(storage_client, Minio)\n",
    "\n",
    "def setup_minio(\n",
    "    endpoint: str,\n",
    "    username: str,\n",
    "    password: str\n",
    ") -> any:\n",
    "    minio_client = Minio(\n",
    "        endpoint = endpoint, \n",
    "        access_key = username, \n",
    "        secret_key = password,\n",
    "        secure = False\n",
    "    )\n",
    "    return minio_client\n",
    "\n",
    "def pickle_data(\n",
    "    data: any\n",
    ") -> any:\n",
    "    pickled_data = pickle.dumps(data)\n",
    "    length = len(pickled_data)\n",
    "    buffer = io.BytesIO()\n",
    "    buffer.write(pickled_data)\n",
    "    buffer.seek(0)\n",
    "    return buffer, length\n",
    "\n",
    "def unpickle_data(\n",
    "    pickled: any\n",
    ") -> any:\n",
    "    return pickle.loads(pickled)\n",
    "\n",
    "def minio_create_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.make_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def minio_check_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        status = minio_client.bucket_exists(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket checking error')\n",
    "        print(e)\n",
    "        return False \n",
    "       \n",
    "def minio_delete_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        minio_client.remove_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_create_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool: \n",
    "    # Be aware that MinIO objects have a size limit of 1GB, \n",
    "    # which might result to large header error    \n",
    "    \n",
    "    try:\n",
    "        buffer, length = pickle_data(\n",
    "            data = data\n",
    "        )\n",
    "\n",
    "        minio_client.put_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path,\n",
    "            data = buffer,\n",
    "            length = length,\n",
    "            metadata = metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_check_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path\n",
    "        )      \n",
    "        return object_info\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "# Works\n",
    "def minio_delete_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.remove_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool:  \n",
    "    remove = minio_delete_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    if remove:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data,\n",
    "            metadata = metadata\n",
    "        )\n",
    "    return False\n",
    "# works\n",
    "def minio_create_or_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any, \n",
    "    metadata: dict\n",
    ") -> bool:\n",
    "    bucket_status = minio_check_bucket(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    if not bucket_status:\n",
    "        creation_status = minio_create_bucket(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    object_status = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not object_status:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "    else:\n",
    "        return minio_update_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "# Works\n",
    "def minio_get_object_list(\n",
    "    minio_client: any,\n",
    "    bucket_name: str,\n",
    "    path_prefix: str\n",
    ") -> any:\n",
    "    try:\n",
    "        objects = minio_client.list_objects(\n",
    "            bucket_name = bucket_name, \n",
    "            prefix = path_prefix, \n",
    "            recursive = True\n",
    "        )\n",
    "        return objects\n",
    "    except Exception as e:\n",
    "        return None  \n",
    "    \n",
    "def minio_get_object_data_and_metadata(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any:\n",
    "    try:\n",
    "        given_object_data = minio_client.get_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        # There seems to be some kind of a limit\n",
    "        # with the amount of request a client \n",
    "        # can make, which is why this variable\n",
    "        # is set here to give more time got the client\n",
    "        # to complete the request\n",
    "\n",
    "        given_data = unpickle_data(\n",
    "            pickled = given_object_data.data\n",
    "        )\n",
    "        \n",
    "        given_object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        given_metadata = given_object_info.metadata\n",
    "        \n",
    "        return {'data': given_data, 'metadata': given_metadata}\n",
    "    except Exception as e:\n",
    "        print('MinIO object fetching error')\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def langchain_create_code_chunks(\n",
    "    language: any,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    document: any\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language = language,\n",
    "        chunk_size = chunk_size, \n",
    "        chunk_overlap = chunk_overlap\n",
    "    )\n",
    "\n",
    "    code_chunks = splitter.create_documents([document])\n",
    "    code_chunks = [doc.page_content for doc in code_chunks]\n",
    "    return code_chunks\n",
    "\n",
    "def langchain_create_text_chunks(\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    document: any\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size, \n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False\n",
    "    )\n",
    "\n",
    "    text_chunks = splitter.create_documents([document])\n",
    "    text_chunks = [doc.page_content for doc in text_chunks]\n",
    "    return text_chunks\n",
    "\n",
    "def langchain_create_chunk_embeddings(\n",
    "    model_name: str,\n",
    "    chunks: any\n",
    ") -> any:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name = model_name\n",
    "    )\n",
    "    chunk_embeddings = embedding_model.embed_documents(\n",
    "        texts = chunks\n",
    "    )\n",
    "    return chunk_embeddings\n",
    "\n",
    "def qdrant_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, qc.Connection)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_setup_client(\n",
    "    api_key: str,\n",
    "    address: str, \n",
    "    port: str\n",
    ") -> any:\n",
    "    try:\n",
    "        qdrant_client = qc(\n",
    "            host = address,\n",
    "            port = int(port),\n",
    "            api_key = api_key,\n",
    "            https = False\n",
    "        ) \n",
    "        return qdrant_client\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_create_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str,\n",
    "    configuration: any\n",
    ") -> any:\n",
    "    try:\n",
    "        result = qdrant_client.create_collection(\n",
    "            collection_name = collection_name,\n",
    "            vectors_config = configuration\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_get_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = qdrant_client.get_collection(\n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_list_collections(\n",
    "    qdrant_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collections = qdrant_client.get_collections()\n",
    "        collection_list = []\n",
    "        for description in collections.collections:\n",
    "            collection_list.append(description.name)\n",
    "        return collection_list\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_remove_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        qdrant_client.delete_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_upsert_points(\n",
    "    qdrant_client: qc, \n",
    "    collection_name: str,\n",
    "    points: any\n",
    ") -> any:\n",
    "    try:\n",
    "        results = qdrant_client.upsert(\n",
    "            collection_name = collection_name, \n",
    "            points = points\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_search_data(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    scroll_filter: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.scroll(\n",
    "            collection_name = collection_name,\n",
    "            scroll_filter = scroll_filter,\n",
    "            limit = limit\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def qdrant_search_vectors(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    query_vector: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.search(\n",
    "            collection_name = collection_name,\n",
    "            query_vector = query_vector,\n",
    "            limit = limit\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_remove_vectors(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str, \n",
    "    vectors: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        results = qdrant_client.delete_vectors(\n",
    "            collection_name = collection_name,\n",
    "            vectors = vectors\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing document: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_document_packet(\n",
    "    document: any,\n",
    "    configuration: any,\n",
    ") -> any:\n",
    "    document_type = document['type']\n",
    "    used_configuration = configuration[document_type]\n",
    "    \n",
    "    document_chunks = []\n",
    "    if document_type == 'python':\n",
    "        document_chunks = langchain_create_code_chunks(\n",
    "            language = used_configuration['language'],\n",
    "            chunk_size = used_configuration['chunk-size'],\n",
    "            chunk_overlap = used_configuration['chunk-overlap'],\n",
    "            document = document['data']\n",
    "        )\n",
    "    if document_type == 'text' or document_type == 'yaml' or document_type == 'markdown':\n",
    "        document_chunks = langchain_create_text_chunks(\n",
    "            chunk_size = used_configuration['chunk-size'],\n",
    "            chunk_overlap = used_configuration['chunk-overlap'],\n",
    "            document = document['data']\n",
    "        )\n",
    "    # This needs to remove empty chunks\n",
    "    filtered_chunks = []\n",
    "    for chunk in document_chunks:\n",
    "        if chunk.strip():\n",
    "            filtered_chunks.append(chunk)\n",
    "        \n",
    "    vector_embedding = langchain_create_chunk_embeddings(\n",
    "        model_name = used_configuration['model-name'],\n",
    "        chunks = filtered_chunks\n",
    "    )\n",
    "\n",
    "    packet = {\n",
    "        'chunks': filtered_chunks,\n",
    "        'embeddings': vector_embedding\n",
    "    }\n",
    "    \n",
    "    return packet\n",
    "\n",
    "def format_chunk(\n",
    "    document_chunk: any\n",
    ") -> any:\n",
    "    chunk = re.sub(r'[^\\w\\s]', '', document_chunk)\n",
    "    chunk = re.sub(r'\\s+', ' ', chunk) \n",
    "    chunk = chunk.strip()\n",
    "    chunk = chunk.lower()\n",
    "    # This helps to remove unique hashes for duplicates such as:\n",
    "    # task_id = task_id )\n",
    "    # task_id = task_id \n",
    "    # task_id = task_id )\n",
    "    return chunk\n",
    "\n",
    "def generate_chunk_hash(\n",
    "    document_chunk: any\n",
    ") -> any:\n",
    "    cleaned_chunk = format_chunk(\n",
    "        document_chunk = document_chunk\n",
    "    )\n",
    "    return hashlib.md5(cleaned_chunk.encode('utf-8')).hexdigest()\n",
    "\n",
    "def generate_document_vectors(\n",
    "    qdrant_client: any,\n",
    "    document_database: any,\n",
    "    document_collection: any,\n",
    "    document_type: any,\n",
    "    document_id: str, \n",
    "    document_chunks: any,\n",
    "    document_embeddings: any,\n",
    "    vector_collection: any\n",
    "):\n",
    "    vector_points = []\n",
    "    vector_index = 0\n",
    "    added_hashes = []\n",
    "    for chunk in document_chunks:\n",
    "        vector_id = document_id + '-' + str(vector_index + 1)\n",
    "        vector_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, vector_id))\n",
    "\n",
    "        chunk_hash = generate_chunk_hash(\n",
    "            document_chunk = chunk\n",
    "        )\n",
    "        \n",
    "        existing_chunks = qdrant_search_data(\n",
    "            qdrant_client = qdrant_client,\n",
    "            collection_name = vector_collection,\n",
    "            scroll_filter = models.Filter(\n",
    "                must = [\n",
    "                    models.FieldCondition(\n",
    "                        key = 'chunk_hash',\n",
    "                        match = models.MatchValue(\n",
    "                            value = chunk_hash\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit = 1\n",
    "        )\n",
    "        # Removes duplicates\n",
    "        if len(existing_chunks[0]) == 0:\n",
    "            if not chunk_hash in added_hashes:\n",
    "                given_vector = document_embeddings[vector_index]\n",
    "\n",
    "                chunk_point = PointStruct(\n",
    "                    id = vector_uuid, \n",
    "                    vector = given_vector,\n",
    "                    payload = {\n",
    "                        'database': document_database,\n",
    "                        'collection': document_collection,\n",
    "                        'document': document_id,\n",
    "                        'type': document_type,\n",
    "                        'chunk': chunk,\n",
    "                        'chunk_hash': chunk_hash\n",
    "                    }\n",
    "                )\n",
    "                added_hashes.append(chunk_hash)\n",
    "                vector_points.append(chunk_point)\n",
    "        vector_index += 1\n",
    "    return vector_points\n",
    "\n",
    "def create_document_vectors(\n",
    "    qdrant_client: any,\n",
    "    document_database,\n",
    "    document_collection,\n",
    "    document: any,\n",
    "    configuration: any,\n",
    "    vector_collection: str\n",
    ") -> bool:\n",
    "    document_id = str(document['_id'])\n",
    "    document_type = document['type']\n",
    "\n",
    "    document_packet = {}\n",
    "    try:\n",
    "        document_packet = create_document_packet(\n",
    "            document = document,\n",
    "            configuration = configuration\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(document_database,document_collection,document_id)\n",
    "        print(e)\n",
    "\n",
    "    if 0 == len(document_packet):\n",
    "        return []\n",
    "        \n",
    "    document_chunks = document_packet['chunks']\n",
    "    document_embeddings = document_packet['embeddings']\n",
    "    \n",
    "    if 0 == len(document_embeddings):\n",
    "        return []\n",
    "    \n",
    "    vector_collections = qdrant_list_collections(\n",
    "        qdrant_client = qdrant_client\n",
    "    )\n",
    "    \n",
    "    collection_created = None\n",
    "    if not vector_collection in vector_collections:\n",
    "        collection_configuration = VectorParams(\n",
    "            size = len(document_embeddings[0]), \n",
    "            distance = Distance.COSINE\n",
    "        )\n",
    "        collection_created = qdrant_create_collection(\n",
    "            qdrant_client = qdrant_client,\n",
    "            collection_name = vector_collection,\n",
    "            configuration = collection_configuration\n",
    "        )\n",
    "\n",
    "    vector_points = generate_document_vectors(\n",
    "        qdrant_client = qdrant_client,\n",
    "        document_database = document_database,\n",
    "        document_collection = document_collection,\n",
    "        document_type = document_type,\n",
    "        document_id = document_id,\n",
    "        document_chunks = document_chunks,\n",
    "        document_embeddings = document_embeddings,\n",
    "        vector_collection = vector_collection\n",
    "    )\n",
    "\n",
    "    return vector_points\n",
    "\n",
    "def store_vectors(\n",
    "    minio_client: any,\n",
    "    qdrant_client: any,\n",
    "    configuration: any,\n",
    "    storage_documents: any\n",
    "):\n",
    "    print('Storing vectors')\n",
    "    \n",
    "    used_object_bucket = configuration['object-bucket']\n",
    "    used_object_path = configuration['object-path']\n",
    "    \n",
    "    identities_exists = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path\n",
    "    )\n",
    "\n",
    "    document_identities = []\n",
    "    # doesn't work\n",
    "    if not len(identities_exists) == 0:\n",
    "        document_identities = minio_get_object_data_and_metadata(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = used_object_bucket, \n",
    "            object_path = used_object_path\n",
    "        )['data']\n",
    "    \n",
    "    amount_of_databases = len(storage_documents)\n",
    "    database_index = 1\n",
    "    for document_database, document_collections in storage_documents.items():\n",
    "        vector_collection = document_database.replace('|','-') + '-embeddings'\n",
    "        amount_of_collections = len(document_collections)\n",
    "        collection_index = 1\n",
    "        database_vectors = []\n",
    "        for document_collection, documents in document_collections.items():\n",
    "            #amount_of_documents = len(documents)\n",
    "            for document in documents:\n",
    "                document_identity = document_database + '-' + document_collection + '-' + str(document['_id'])\n",
    "\n",
    "                if document_identity in document_identities:\n",
    "                    continue\n",
    "                    \n",
    "                document_vectors = create_document_vectors(\n",
    "                    qdrant_client = qdrant_client,\n",
    "                    document_database = document_database,\n",
    "                    document_collection = document_collection,\n",
    "                    document = document,\n",
    "                    configuration = configuration,\n",
    "                    vector_collection = vector_collection\n",
    "                )\n",
    "\n",
    "                if 0 < len(document_vectors):\n",
    "                    database_vectors.extend(document_vectors)\n",
    "                    document_identities.append(document_identity)\n",
    "            print('Collections: ' + str(collection_index) + '|' + str(amount_of_collections))\n",
    "            collection_index += 1\n",
    "\n",
    "        points_stored = qdrant_upsert_points(\n",
    "            qdrant_client = qdrant_client, \n",
    "            collection_name = vector_collection,\n",
    "            points = database_vectors\n",
    "        )\n",
    "        print('Databases: ' + str(database_index) + '|' + str(amount_of_databases))\n",
    "        database_index += 1\n",
    "\n",
    "    minio_create_or_update_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path,\n",
    "        data = document_identities, \n",
    "        metadata = {}\n",
    "    )\n",
    "    \n",
    "    print('Vectors stored')\n",
    "\n",
    "def spacy_find_keywords(\n",
    "    text: str\n",
    "):   \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    formatted = nlp(text.lower())\n",
    "    \n",
    "    keywords = [\n",
    "        token.lemma_ for token in formatted\n",
    "        if not token.is_stop               \n",
    "        and not token.is_punct              \n",
    "        and not token.is_space              \n",
    "        and len(token) > 1                  \n",
    "    ]\n",
    "    \n",
    "    keywords = list(set(keywords))\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def meili_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, ms.Connection)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def meili_setup_client(\n",
    "    api_key: str,\n",
    "    host: str\n",
    ") -> any:\n",
    "    try:\n",
    "        meili_client = ms.Client(\n",
    "            url = host, \n",
    "            api_key = api_key\n",
    "        )\n",
    "        return meili_client \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_get_index( \n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_check_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        meili_client.get_index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def meili_remove_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        response = meili_client.index(\n",
    "            index_name = index_name\n",
    "        ).delete()\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_list_indexes(\n",
    "    meili_client: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        names = []\n",
    "        indexes = meili_client.get_indexes()\n",
    "        for index in indexes['results']:\n",
    "            names.append(index.uid)\n",
    "        return names\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_add_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    documents: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.add_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_set_filterable(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    attributes: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_filterable_attributes(attributes)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_search_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    query: any, \n",
    "    options: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.search(\n",
    "            query,\n",
    "            options\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_update_documents(\n",
    "    meili_client, \n",
    "    index_name, \n",
    "    documents\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_delete_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    ids: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.delete_documents(\n",
    "            document_ids = ids\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def generate_keyword_uuid(\n",
    "    document_id: str,\n",
    "    document_index: int\n",
    ") -> str:\n",
    "    keyword_id = document_id + '-' + str(document_index + 1)\n",
    "    keyword_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, keyword_id))\n",
    "    return keyword_uuid\n",
    "\n",
    "def create_document_keywords(\n",
    "    document_database: str,\n",
    "    document_collection: str,\n",
    "    document: any,\n",
    "    document_index: int\n",
    ") -> any:\n",
    "    document_id = str(document['_id'])\n",
    "    document_data = document['data']\n",
    "    document_type = document['type']\n",
    "\n",
    "    document_keywords = []\n",
    "    try:\n",
    "        document_keywords = spacy_find_keywords(\n",
    "            text = document_data\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if 0 == len(document_keywords):\n",
    "        return {}\n",
    "    \n",
    "    keyword_uuid = generate_keyword_uuid(\n",
    "        document_id = document_id,\n",
    "        document_index = document_index\n",
    "    ) \n",
    "\n",
    "    payload = {\n",
    "        'id': keyword_uuid,\n",
    "        'database': document_database,\n",
    "        'collection': document_collection,\n",
    "        'document': document_id,\n",
    "        'type': document_type,\n",
    "        'keywords': document_keywords\n",
    "    }\n",
    "\n",
    "    return payload\n",
    "    \n",
    "def store_keywords(\n",
    "    minio_client: any,\n",
    "    meili_client: any,\n",
    "    configuration: any,\n",
    "    storage_documents: any\n",
    "):\n",
    "    print('Storing keywords')\n",
    "\n",
    "    used_object_bucket = configuration['object-bucket']\n",
    "    used_object_path = configuration['object-path']\n",
    "    \n",
    "    identities_exists = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path\n",
    "    )\n",
    "\n",
    "    document_identities = []\n",
    "    # doesn't work\n",
    "    if not len(identities_exists) == 0:\n",
    "        document_identities = minio_get_object_data_and_metadata(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = used_object_bucket, \n",
    "            object_path = used_object_path\n",
    "        )['data']\n",
    "\n",
    "    amount_of_databases = len(storage_documents)\n",
    "    database_index = 1\n",
    "    for document_database, collections in storage_documents.items():\n",
    "        keyword_collection = document_database.replace('|','-') + '-keywords'\n",
    "        database_keywords = []\n",
    "        collection_index = 1\n",
    "        amount_of_collections = len(collections)\n",
    "        for document_collection, documents in collections.items():\n",
    "            document_index = 1\n",
    "            for document in documents:\n",
    "                document_identity = document_database + '-' + document_collection + '-' + str(document['_id'])\n",
    "\n",
    "                if document_identity in document_identities:\n",
    "                    continue\n",
    "\n",
    "                document_keywords = create_document_keywords(\n",
    "                    document_database = document_database,\n",
    "                    document_collection = document_collection,\n",
    "                    document = document,\n",
    "                    document_index = document_index\n",
    "                )\n",
    "\n",
    "                if 0 < len(document_keywords):\n",
    "                    database_keywords.append(document_keywords)\n",
    "                    document_identities.append(document_identity)\n",
    "            print('Collections: ' + str(collection_index) + '|' + str(amount_of_collections))\n",
    "            collection_index += 1\n",
    "        #print(database_keywords)\n",
    "        stored = meili_add_documents(\n",
    "            meili_client = meili_client,\n",
    "            index_name = keyword_collection,\n",
    "            documents = database_keywords\n",
    "        )\n",
    "\n",
    "        meili_set_filterable(\n",
    "            meili_client = meili_client, \n",
    "            index_name = keyword_collection, \n",
    "            attributes = ['keywords']\n",
    "        )\n",
    "        \n",
    "        print('Databases: ' + str(database_index) + '|' + str(amount_of_databases))\n",
    "        database_index += 1\n",
    "        \n",
    "    minio_create_or_update_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path,\n",
    "        data = document_identities, \n",
    "        metadata = {}\n",
    "    )\n",
    "\n",
    "@ray.remote\n",
    "def preprocess_data(\n",
    "    document_client: any,\n",
    "    object_client: any,\n",
    "    vector_client: any,\n",
    "    search_client: any,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    configuration: any\n",
    "):\n",
    "    try:\n",
    "        stored_documents = get_stored_documents(\n",
    "            mongo_client = document_client,\n",
    "            database_prefix = get_github_storage_prefix(\n",
    "                repository_owner = repository_owner,\n",
    "                repository_name = repository_name\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        store_vectors(\n",
    "            minio_client = object_client,\n",
    "            qdrant_client = vector_client,\n",
    "            configuration = configuration,\n",
    "            storage_documents = stored_documents\n",
    "        )\n",
    "\n",
    "        store_keywords(\n",
    "            minio_client = object_client,\n",
    "            meili_client = search_client,\n",
    "            configuration = configuration,\n",
    "            storage_documents = stored_documents\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Starting ray job')\n",
    "    print('Ray version is:' + str(ray.__version__))\n",
    "    \n",
    "    input = json.loads(sys.argv[1])\n",
    "\n",
    "    storage_parameters = input['storage-parameters']\n",
    "    data_parameters = input['data-parameters']\n",
    "\n",
    "    mongo_client = mongo_setup_client(\n",
    "        username = storage_parameters['mongo-username'],\n",
    "        password = storage_parameters['mongo-password'],\n",
    "        address = storage_parameters['mongo-address'],\n",
    "        port = storage_parameters['mongo-port']\n",
    "    )\n",
    "\n",
    "    minio_client = setup_minio(\n",
    "        endpoint = storage_parameters['minio-endpoint'],\n",
    "        username = storage_parameters['minio-username'],\n",
    "        password = storage_parameters['minio-password']\n",
    "    )\n",
    "\n",
    "    qdrant_client = qdrant_setup_client(\n",
    "        api_key = storage_parameters['qdrant-key'],\n",
    "        address = storage_parameters['qdrant-address'], \n",
    "        port = storage_parameters['qdrant-port']\n",
    "    )\n",
    "\n",
    "    meili_client = meili_setup_client(\n",
    "        api_key = storage_parameters['meili-key'],\n",
    "        host = storage_parameters['meili-host']\n",
    "    )\n",
    "\n",
    "    github_token = data_parameters['github-token']\n",
    "    repository_owner = data_parameters['repository-owner']\n",
    "    repository_name = data_parameters['repository-name']\n",
    "    relevant_files = data_parameters['relevant-files']\n",
    "    configuration = data_parameters['configuration']\n",
    "\n",
    "    fetch_store_status = ray.get(preprocess_data.remote(\n",
    "        document_client = mongo_client,\n",
    "        object_client = minio_client,\n",
    "        vector_client = qdrant_client,\n",
    "        search_client = meili_client,\n",
    "        repository_owner = repository_owner,\n",
    "        repository_name = repository_name,\n",
    "        configuration = configuration\n",
    "    ))\n",
    "\n",
    "    print('Preprocess success:' + str(fetch_store_status))\n",
    "\n",
    "    print('Ray job Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
