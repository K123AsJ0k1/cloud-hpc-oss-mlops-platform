{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76734520-9ec6-4cb9-bed5-477006377137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df5dcf8-2d82-40da-8914-9ce8aef3b84f",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7f7b3f-6c35-47f0-8ba4-f0853ab66d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config,RepositoryEnv\n",
    "env_path = '/home/sfniila/.ssh/.env'\n",
    "env_config = Config(RepositoryEnv(env_path))\n",
    "github_token = env_config.get('GITHUB_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4314a1-75b3-4a21-93ea-da45671295c9",
   "metadata": {},
   "source": [
    "## PyGitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07a4fb-3e77-4418-900a-00355b551a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "def pygithub_get_repo_paths(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    contents = repo.get_contents(\"\")\n",
    "    paths = []\n",
    "    while len(contents) > 0:\n",
    "      file_content = contents.pop(0)\n",
    "      if file_content.type == 'dir':\n",
    "        contents.extend(repo.get_contents(file_content.path))\n",
    "      else:\n",
    "        paths.append(file_content.path)\n",
    "    g.close()\n",
    "    return paths\n",
    "\n",
    "def pygithub_get_path_content(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str, \n",
    "    path: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    file_content = repo.get_contents(path)\n",
    "    content = file_content.decoded_content.decode('utf-8')\n",
    "    g.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d75007-8269-450f-a54b-c485a324949e",
   "metadata": {},
   "source": [
    "## Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b2f0cd3-106c-4b5d-9926-40dd191ee231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_github_repo_documents(\n",
    "    github_token: str,\n",
    "    repo_owner: str,\n",
    "    repo_name: str,\n",
    "    relevant_files: any,\n",
    "    store: bool\n",
    ") -> any:\n",
    "    storage_path = os.getcwd() + '/' + repo_owner + '-' + repo_name + '.txt' \n",
    "\n",
    "    repo_paths = []\n",
    "    if not os.path.exists(storage_path):\n",
    "        print('Getting github paths')\n",
    "        repo_paths = pygithub_get_repo_paths(\n",
    "            token = github_token,\n",
    "            owner = repo_owner, \n",
    "            name = repo_name\n",
    "        )\n",
    "        \n",
    "        if store:\n",
    "            print('Storing paths')\n",
    "            path_amount = len(repo_paths)\n",
    "            i = 0\n",
    "            with open(storage_path, 'w') as file:\n",
    "                for line in repo_paths:\n",
    "                    row = line \n",
    "                    if i < path_amount:\n",
    "                        row += '\\n'\n",
    "                    file.write(row)\n",
    "                    i += 1\n",
    "            print('Paths stored')\n",
    "    else:\n",
    "        print('Getting stored paths')\n",
    "        with open(storage_path, 'r') as file:\n",
    "            repo_paths = file.readlines()\n",
    "    print('Paths fetched')\n",
    "                \n",
    "    print('Filtering paths')\n",
    "    relevant_paths = []\n",
    "    for path in repo_paths:\n",
    "        path_split = path.split('/')\n",
    "        file_end = path_split[-1].split('.')[-1].rstrip()\n",
    "        if file_end in relevant_files:\n",
    "            relevant_paths.append(path.rstrip())\n",
    "    print('Paths filtered')\n",
    "\n",
    "    formatted_paths = {\n",
    "        'paths': relevant_paths\n",
    "    }\n",
    "\n",
    "    # consider how to store this to allas\n",
    "    return formatted_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4bb145-96d9-46ce-82dc-233bef130b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def get_document_data(\n",
    "    document_url: str,\n",
    "    document_type: str\n",
    ") -> any:\n",
    "    data = None\n",
    "    response = requests.get(\n",
    "        url = document_url\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        if document_type == 'text':\n",
    "            data = response.text\n",
    "        if document_type == 'json':\n",
    "            data = json.loads(response.text)\n",
    "        # handle html later\n",
    "    return data\n",
    "\n",
    "def scrape_documents(\n",
    "    url_list: any,\n",
    "    timeout: int\n",
    ") -> any:\n",
    "    documents = []\n",
    "\n",
    "    text_files = [\n",
    "        'py',\n",
    "        'md',\n",
    "        'yaml',\n",
    "        'sh'\n",
    "    ]\n",
    "\n",
    "    json_files = [\n",
    "        'ipynb'\n",
    "    ]\n",
    "    index = 0\n",
    "    for url in url_list:\n",
    "        document = {\n",
    "            'name': '',\n",
    "            'data': ''\n",
    "        }\n",
    "        url_split = url.split('/')\n",
    "        if 'github' in url_split[2]:\n",
    "            if 'raw' in url_split[2]:\n",
    "                file_end = url_split[-1].split('.')[-1]\n",
    "                document['name'] = url_split[-1]\n",
    "                if file_end in text_files:\n",
    "                    document['data'] = get_document_data(\n",
    "                        document_url = url,\n",
    "                        document_type = 'text' \n",
    "                    )\n",
    "                if file_end in json_files:\n",
    "                    document['data'] = get_document_data(\n",
    "                        document_url = url,\n",
    "                        document_type = 'json' \n",
    "                    )\n",
    "        documents.append(document)\n",
    "        index = index + 1\n",
    "        if index < len(url_list):\n",
    "            time.sleep(timeout)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee717787-4d21-4082-ad61-5b1973926cc9",
   "metadata": {},
   "source": [
    "Files of intrest\n",
    "- md = important to usesr\n",
    "- txt = isn't important to users\n",
    "- sh = isn't important to users\n",
    "- yaml = important to developers\n",
    "- py = important to users and developers\n",
    "- ipynb = important to users and developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9ccfa42-95dc-4c8a-9784-fa703937d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stored paths\n",
      "Paths fetched\n",
      "Filtering paths\n",
      "Paths filtered\n"
     ]
    }
   ],
   "source": [
    "repository_paths = get_github_repo_documents(\n",
    "    github_token = github_token,\n",
    "    repo_owner = 'K123AsJ0k1',\n",
    "    repo_name = 'cloud-hpc-oss-mlops-platform',\n",
    "    relevant_files = [\n",
    "        'md',\n",
    "        'yaml',\n",
    "        'py',\n",
    "        'ipynb'\n",
    "    ],\n",
    "    store = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70f6e8-ed91-45c9-afa5-cf598998ac17",
   "metadata": {},
   "source": [
    "# Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a37223-b44f-4237-9eb8-c5ccc9235758",
   "metadata": {},
   "source": [
    "## TreeSitter Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c5afb2-d4b9-43e0-8e57-39982b0d6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "import re\n",
    "\n",
    "def tree_extract_imports(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    imports = []\n",
    "    if node.type == 'import_statement' or node.type == 'import_from_statement':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        imports.append(code_text[start_byte:end_byte].decode('utf8'))\n",
    "    for child in node.children:\n",
    "        imports.extend(tree_extract_imports(child, code_text))\n",
    "    return imports\n",
    "\n",
    "def tree_extract_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    dependencies = []\n",
    "    for child in node.children:\n",
    "        if child.type == 'call':\n",
    "            dependency_name = child.child_by_field_name('function').text.decode('utf8')\n",
    "            dependencies.append(dependency_name)\n",
    "        dependencies.extend(tree_extract_dependencies(child, code_text))\n",
    "    return dependencies\n",
    "\n",
    "def tree_extract_code_and_dependencies(\n",
    "    node: any,\n",
    "    code_text: str\n",
    ") -> any:\n",
    "    codes = []\n",
    "    if not node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name')\n",
    "        if name is None:\n",
    "            code = code_text[start_byte:end_byte].decode('utf8')\n",
    "            if not 'def' in code:\n",
    "                dependencies = tree_extract_dependencies(node, code_text)\n",
    "                codes.append({\n",
    "                    'name': 'global',\n",
    "                    'code': code,\n",
    "                    'dependencies': dependencies\n",
    "                })\n",
    "    return codes\n",
    "\n",
    "def tree_extract_functions_and_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    functions = []\n",
    "    if node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name').text.decode('utf8')\n",
    "        code = code_text[start_byte:end_byte].decode('utf8')\n",
    "        dependencies = tree_extract_dependencies(node, code_text)\n",
    "        functions.append({\n",
    "            'name': name,\n",
    "            'code': code,\n",
    "            'dependencies': dependencies\n",
    "        })\n",
    "    for child in node.children:\n",
    "        functions.extend(tree_extract_functions_and_dependencies(child, code_text))\n",
    "    return functions\n",
    "\n",
    "def tree_get_used_imports(\n",
    "    general_imports: any,\n",
    "    function_dependencies: any\n",
    ") -> any:\n",
    "    parsed_imports = {}\n",
    "    for code_import in general_imports:\n",
    "        import_factors = code_import.split('import')[-1].replace(' ', '')\n",
    "        import_factors = import_factors.split(',')\n",
    "    \n",
    "        for factor in import_factors:\n",
    "            if not factor in parsed_imports:\n",
    "                parsed_imports[factor] = code_import.split('import')[0] + 'import ' + factor\n",
    "            \n",
    "    relevant_imports = {}\n",
    "    for dependency in function_dependencies:\n",
    "        initial_term = dependency.split('.')[0]\n",
    "    \n",
    "        if not initial_term in relevant_imports:\n",
    "            if initial_term in parsed_imports:\n",
    "                relevant_imports[initial_term] = parsed_imports[initial_term]\n",
    "    \n",
    "    used_imports = []\n",
    "    for name, code in relevant_imports.items():\n",
    "        used_imports.append(code)\n",
    "\n",
    "    return used_imports\n",
    "\n",
    "def tree_get_used_functions(\n",
    "    general_functions: any,\n",
    "    function_dependencies: any\n",
    "): \n",
    "    used_functions = []\n",
    "    for related_function_name in function_dependencies:\n",
    "        for function in general_functions:\n",
    "            if function['name'] == related_function_name:\n",
    "                used_functions.append('from ice import ' + function['name'])\n",
    "    return used_functions\n",
    "\n",
    "def tree_create_code_document(\n",
    "    code_imports: any,\n",
    "    code_functions: any,\n",
    "    function_item: any\n",
    ") -> any:\n",
    "    used_imports = tree_get_used_imports(\n",
    "        general_imports = code_imports,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "\n",
    "    used_functions = tree_get_used_functions(\n",
    "        general_functions = code_functions,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "    \n",
    "    document = {\n",
    "        'imports': used_imports,\n",
    "        'functions': used_functions,\n",
    "        'name': function_item['name'],\n",
    "        'dependencies': function_item['dependencies'],\n",
    "        'code': function_item['code']\n",
    "    }\n",
    "    \n",
    "    return document\n",
    "     \n",
    "def tree_format_code_document(\n",
    "    code_document: any\n",
    ") -> any:\n",
    "    formatted_document = ''\n",
    "    for doc_import in code_document['imports']:\n",
    "        formatted_document += doc_import + '\\n'\n",
    "\n",
    "    for doc_functions in code_document['functions']:\n",
    "        formatted_document += doc_functions + '\\n'\n",
    "\n",
    "    if 0 < len(code_document['dependencies']):\n",
    "        formatted_document += 'code dependencies\\n'\n",
    "\n",
    "        for doc_dependency in code_document['dependencies']:\n",
    "            formatted_document += doc_dependency + '\\n'\n",
    "\n",
    "    if code_document['name'] == 'global':\n",
    "        formatted_document += code_document['name'] + ' code\\n'\n",
    "    else:\n",
    "        formatted_document += 'function ' + code_document['name'] + ' code\\n'\n",
    "    \n",
    "    for line in code_document['code'].splitlines():\n",
    "        if not bool(line.strip()):\n",
    "            continue\n",
    "        doc_code = re.sub(r'#.*','', line)\n",
    "        if not bool(doc_code.strip()):\n",
    "            continue\n",
    "        formatted_document += doc_code + '\\n'    \n",
    "    return formatted_document\n",
    "\n",
    "def tree_create_python_code_and_function_documents(\n",
    "    code_document: any\n",
    "):\n",
    "    PY_LANGUAGE = Language(tspython.language())\n",
    "    parser = Parser(PY_LANGUAGE)\n",
    "   \n",
    "    tree = parser.parse(\n",
    "        bytes(\n",
    "            code_document,\n",
    "            \"utf8\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    root_node = tree.root_node\n",
    "    code_imports = tree_extract_imports(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_global = tree_extract_code_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_functions = tree_extract_functions_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    initial_documents = []\n",
    "    for item in code_global:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    for item in code_functions:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    formatted_documents = []\n",
    "    seen_functions = []\n",
    "    for document in initial_documents:\n",
    "        if not document['name'] == 'global':\n",
    "            if document['name'] in seen_functions:\n",
    "                continue\n",
    "        \n",
    "        formatted_document = tree_format_code_document(\n",
    "            code_document = document\n",
    "        )\n",
    "\n",
    "        formatted_documents.append(formatted_document)\n",
    "        seen_functions.append(document['name'])\n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839df405-d29b-44ed-a0f7-23287e8ea76c",
   "metadata": {},
   "source": [
    "## Document Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bd7d8a-04ca-428b-a6eb-b71e90018d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from bs4 import BeautifulSoup\n",
    "import markdown\n",
    "\n",
    "def extract_jupyter_notebook_markdown_and_code(\n",
    "    notebook_document: any\n",
    "): \n",
    "    notebook_documents = {\n",
    "        'markdown': [],\n",
    "        'code': []\n",
    "    }\n",
    "\n",
    "    notebook = nbformat.from_dict(notebook_document)\n",
    "\n",
    "    index = 1\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            notebook_documents['markdown'].append({\n",
    "                'id': index,\n",
    "                'data': cell.source\n",
    "            })\n",
    "            index += 1\n",
    "        if cell.cell_type == 'code':\n",
    "            notebook_documents['code'].append({\n",
    "                'id': index,\n",
    "                'data': cell.source\n",
    "            })\n",
    "            index += 1\n",
    "    \n",
    "    return notebook_documents\n",
    "    \n",
    "def parse_markdown_into_text(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    text = soup.get_text()\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    text = re.sub(code_block_pattern, '', text)\n",
    "    text = text.rstrip('\\n')\n",
    "    text = text.replace('\\nsh', '\\n')\n",
    "    text = text.replace('\\nbash', '\\n')\n",
    "    return text\n",
    "\n",
    "def create_python_documents(\n",
    "    python_document: any\n",
    "): \n",
    "    joined_code = ''.join(python_document)\n",
    "    block_code_documents = tree_create_python_code_and_function_documents(\n",
    "        code_document = joined_code\n",
    "    )\n",
    "\n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    code_doc_index = 0\n",
    "    for code_doc in block_code_documents:\n",
    "        row_split = code_doc.split('\\n')\n",
    "        for row in row_split:\n",
    "            if 'function' in row and 'code' in row:\n",
    "                function_name = row.split(' ')[1]\n",
    "                if not function_name in seen_function_names:\n",
    "                    seen_function_names.append(function_name)\n",
    "                else:\n",
    "                    del block_code_documents[code_doc_index]\n",
    "        code_doc_index += 1\n",
    "\n",
    "    if 0 < len(block_code_documents):\n",
    "        index = 1\n",
    "        for code_doc in block_code_documents:\n",
    "            code_documents.append({\n",
    "                'index': index,\n",
    "                'data': code_doc\n",
    "            })\n",
    "            index += 1\n",
    "        \n",
    "    formatted_documents = {\n",
    "        'code': code_documents\n",
    "    }\n",
    "    return formatted_documents\n",
    "\n",
    "def create_notebook_documents(\n",
    "    notebook_document: any\n",
    "):\n",
    "    notebook_documents = extract_jupyter_notebook_markdown_and_code(\n",
    "        notebook_document = notebook_document\n",
    "    )\n",
    "\n",
    "    markdown_documents = []\n",
    "    for block in notebook_documents['markdown']:\n",
    "        joined_text = ''.join(block['data'])\n",
    "        markdown_text = parse_markdown_into_text(\n",
    "            markdown_text = joined_text\n",
    "        )\n",
    "        markdown_documents.append({\n",
    "            'index': block['id'],\n",
    "            'data': markdown_text\n",
    "        })\n",
    "        \n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    for block in notebook_documents['code']:\n",
    "        joined_code = ''.join(block['data'])\n",
    "        block_code_documents = tree_create_python_code_and_function_documents(\n",
    "            code_document = joined_code\n",
    "        )\n",
    "\n",
    "        code_doc_index = 0\n",
    "        for code_doc in block_code_documents:\n",
    "            row_split = code_doc.split('\\n')\n",
    "            for row in row_split:\n",
    "                if 'function' in row and 'code' in row:\n",
    "                    function_name = row.split(' ')[1]\n",
    "                    if not function_name in seen_function_names:\n",
    "                        seen_function_names.append(function_name)\n",
    "                    else:\n",
    "                        del block_code_documents[code_doc_index]\n",
    "            code_doc_index += 1\n",
    "        \n",
    "        if 0 < len(block_code_documents):\n",
    "            sub_indexes = False\n",
    "            if 1 < len(block_code_documents):\n",
    "                sub_indexes = True\n",
    "            index = 1\n",
    "            for code_doc in block_code_documents:\n",
    "                if sub_indexes:\n",
    "                    code_documents.append({\n",
    "                        'sub-index': index, \n",
    "                        'index': block['id'],\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                else:\n",
    "                    code_documents.append({ \n",
    "                        'index': block['id'],\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                index += 1\n",
    "            \n",
    "    formatted_documents = {\n",
    "        'markdown': markdown_documents,\n",
    "        'code': code_documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfc42e-02e2-4d94-b7f9-9782228cc44d",
   "metadata": {},
   "source": [
    "## Mongo Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e4c444-5608-4dde-bf09-c0364a1b8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient as mc\n",
    "\n",
    "def mongo_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, mc.Connection)\n",
    "\n",
    "def mongo_setup_client(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_check_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database_exists = database_name in mongo_client.list_database_names()\n",
    "        return database_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_list_databases(\n",
    "    mongo_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        databases = mongo_client.list_database_names()\n",
    "        return databases\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        mongo_client.drop_database(database_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_get_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_check_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        collection_exists = collection_name in database.list_collection_names()\n",
    "        return collection_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_update_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_many(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_collections(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collections = database.list_collection_names()\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try: \n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        database.drop_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_create_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    document: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.insert_one(document)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "\n",
    "def mongo_list_documents(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any,\n",
    "    sorting_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        documents = list(collection.find(filter_query).sort(sorting_query))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_update_document(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_one(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_remove_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    ") -> bool:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.delete_one(filter_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5777e-24ea-4bc8-9d41-568e60677b0a",
   "metadata": {},
   "source": [
    "## Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0901bd6-ecb5-49b1-b9eb-750baf417afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = mongo_setup_client(\n",
    "    username = 'mongo123',\n",
    "    password = 'mongo456',\n",
    "    address = '127.0.0.1',\n",
    "    port = '27017'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116c18c-53f1-4222-986f-6e3fa00e65b2",
   "metadata": {},
   "source": [
    "## Markdown documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec230be-1fbe-4b25-90da-078055b830af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def create_markdown_documents(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    \n",
    "    documents = []\n",
    "    document = ''\n",
    "    index = 1\n",
    "    for element in soup.descendants:\n",
    "        if element.name in ['h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            text = element.get_text(strip = True)\n",
    "            if not document == '':\n",
    "                document = document.replace('\\n', '')\n",
    "                if not len(document.split()) == 1:\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'markdown',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    index += 1\n",
    "                document = ''\n",
    "            document += text\n",
    "        elif element.name == 'p':\n",
    "            text = element.get_text(strip = True)\n",
    "            text = re.sub(code_block_pattern, '', text)\n",
    "            text = text.rstrip('\\n')\n",
    "            text = text.replace('\\nsh', '')\n",
    "            text = text.replace('\\nbash', '')\n",
    "            document += ' ' + text\n",
    "        elif element.name in ['ul', 'ol']:\n",
    "            text = ''\n",
    "            for li in element.find_all('li'):\n",
    "                item = li.get_text(strip=True)\n",
    "                if not '-' in item:\n",
    "                    text += '-' + item\n",
    "                    continue\n",
    "                text += item\n",
    "            document += ' ' + text\n",
    "            \n",
    "    documents.append({\n",
    "        'index': index,\n",
    "        'sub-index': 0,\n",
    "        'type': 'markdown',\n",
    "        'data': document\n",
    "    })\n",
    "    \n",
    "    formatted_documents = {\n",
    "        'markdown': documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d185d0f-0003-4958-a026-0b79c6c62333",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = repository_paths[7]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1c4d08e0-6f5e-41f1-a465-e9829d6cb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_documents = create_markdown_documents(\n",
    "    markdown_text = example_data\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f93ac-63d8-4b9f-8467-e202571ce0aa",
   "metadata": {},
   "source": [
    "## YAML documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b019e009-db94-47b4-9021-9ab915c437b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "def extract_yaml_values(\n",
    "    section: any,\n",
    "    path: str,\n",
    "    values: any\n",
    ") -> any:\n",
    "    for key, value in section.items():\n",
    "        if path == '':\n",
    "            current_path = key\n",
    "        else:\n",
    "            current_path = path + '/' + key\n",
    "        if isinstance(value, dict):\n",
    "            extract_yaml_values(\n",
    "                section = value,\n",
    "                path = current_path,\n",
    "                values = values\n",
    "            )\n",
    "        if isinstance(value, list):\n",
    "            number = 1\n",
    "            \n",
    "            for case in value:\n",
    "                base_path = current_path\n",
    "                if isinstance(case, dict):\n",
    "                   extract_yaml_values(\n",
    "                       section = case,\n",
    "                       path = current_path,\n",
    "                       values = values\n",
    "                   ) \n",
    "                   continue\n",
    "                base_path += '/' + str(number)\n",
    "                number += 1\n",
    "                values.append(base_path + '=' + str(case))\n",
    "        else:\n",
    "            if isinstance(value, dict):\n",
    "                continue\n",
    "            if isinstance(value, list):\n",
    "                continue\n",
    "            values.append(current_path + '=' + str(value))\n",
    "            \n",
    "    return values\n",
    "\n",
    "def create_yaml_documents(\n",
    "    yaml_text: any\n",
    ") -> any:\n",
    "    yaml_data = list(yaml.safe_load_all(yaml_text))\n",
    "\n",
    "    documents = []\n",
    "    index = 1\n",
    "    for data in yaml_data:\n",
    "        yaml_values = extract_yaml_values(\n",
    "            section = data,\n",
    "            path = '',\n",
    "            values = []\n",
    "        )\n",
    "\n",
    "        previous_root = ''\n",
    "        document = ''\n",
    "        sub_index = 1\n",
    "        for value in yaml_values:\n",
    "            equal_split = value.split('=')\n",
    "            path_split = equal_split[0].split('/')\n",
    "            root = path_split[0]\n",
    "            if not root == previous_root:\n",
    "                if 0 < len(document):\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': sub_index,\n",
    "                        'type': 'yaml',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    sub_index += 1\n",
    "                    \n",
    "                previous_root = root\n",
    "                document = value\n",
    "            else:\n",
    "                document += value\n",
    "                \n",
    "        documents.append({\n",
    "            'index': index,\n",
    "            'sub-index': sub_index,\n",
    "            'type': 'yaml',\n",
    "            'data': document\n",
    "        })\n",
    "        index += 1\n",
    "\n",
    "    formatted_documents = {\n",
    "        'yaml': documents\n",
    "    }\n",
    "            \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c8f8b39-2ec1-47c1-a799-25e4be8d3443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deployment/forwarder/forwarder-namespace.yaml'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_paths[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "239ffb67-18ec-4a3e-a8ca-57fa1364ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_yaml = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'deployment/forwarder/celery/celery-deployment.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704929f-53be-4852-ba22-f8b5efd6e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'deployment/kubeflow/manifests/in-cluster-setup/standalone-kfp/kustomization.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48880c03-8a81-46a5-b207-f0c583e5e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_documents = create_yaml_documents(\n",
    "    yaml_text = example_yaml\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46127d-3124-4243-a7fa-77dae3531c91",
   "metadata": {},
   "source": [
    "## Python documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42502b34-833a-41a5-8eb8-d6b52bb98330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_python_documents(\n",
    "    python_text: any\n",
    "): \n",
    "    joined_code = ''.join(python_text)\n",
    "    block_code_documents = tree_create_python_code_and_function_documents(\n",
    "        code_document = joined_code\n",
    "    )\n",
    "\n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    code_doc_index = 0\n",
    "    for code_doc in block_code_documents:\n",
    "        row_split = code_doc.split('\\n')\n",
    "        for row in row_split:\n",
    "            if 'function' in row and 'code' in row:\n",
    "                function_name = row.split(' ')[1]\n",
    "                if not function_name in seen_function_names:\n",
    "                    seen_function_names.append(function_name)\n",
    "                else:\n",
    "                    del block_code_documents[code_doc_index]\n",
    "        code_doc_index += 1\n",
    "\n",
    "    if 0 < len(block_code_documents):\n",
    "        index = 1\n",
    "        for code_doc in block_code_documents:\n",
    "            code_documents.append({\n",
    "                'index': index,\n",
    "                'sub-index': 0,\n",
    "                'type': 'python',\n",
    "                'data': code_doc\n",
    "            })\n",
    "            index += 1\n",
    "        \n",
    "    formatted_documents = {\n",
    "        'code': code_documents\n",
    "    }\n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7426485-07ce-46ea-8d2b-05b598f3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_python = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'applications/article/submitter/backend/functions/platforms/flower.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e688f33c-7429-458b-8983-994918e8537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_documents = create_python_documents(\n",
    "    python_text = example_python\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0259e6-052b-4e49-b73b-bd95fd6d3afe",
   "metadata": {},
   "source": [
    "## Notebook documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55ecc3b9-29af-42e9-acad-27f50bd8dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "def parse_jupyter_notebook_markdown_into_text(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    text = soup.get_text()\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    text = re.sub(code_block_pattern, '', text)\n",
    "    text = text.rstrip('\\n')\n",
    "    text = text.replace('\\nsh', '\\n')\n",
    "    text = text.replace('\\nbash', '\\n')\n",
    "    return text\n",
    "\n",
    "def extract_jupyter_notebook_markdown_and_code(\n",
    "    notebook_text: any\n",
    "): \n",
    "    notebook_documents = {\n",
    "        'markdown': [],\n",
    "        'code': []\n",
    "    }\n",
    "\n",
    "    notebook = nbformat.reads(notebook_text, as_version=2)\n",
    "    index = 1\n",
    "    for cell in notebook.worksheets[0].cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            notebook_documents['markdown'].append({\n",
    "                'id': index,\n",
    "                'data': cell.source\n",
    "            })\n",
    "            index += 1\n",
    "        if cell.cell_type == 'code':\n",
    "            notebook_documents['code'].append({\n",
    "                'id': index,\n",
    "                'data': cell.input\n",
    "            })\n",
    "            index += 1\n",
    "    \n",
    "    return notebook_documents\n",
    "\n",
    "def create_notebook_documents(\n",
    "    notebook_text: any\n",
    "):\n",
    "    notebook_documents = extract_jupyter_notebook_markdown_and_code(\n",
    "        notebook_text = notebook_text\n",
    "    )\n",
    "\n",
    "    markdown_documents = []\n",
    "    for block in notebook_documents['markdown']:\n",
    "        joined_text = ''.join(block['data'])\n",
    "        markdown_text = parse_jupyter_notebook_markdown_into_text(\n",
    "            markdown_text = joined_text\n",
    "        )\n",
    "        markdown_documents.append({\n",
    "            'index': block['id'],\n",
    "            'sub-index': 0,\n",
    "            'type': 'markdown',\n",
    "            'data': markdown_text\n",
    "        })\n",
    "        \n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    for block in notebook_documents['code']:\n",
    "        joined_code = ''.join(block['data'])\n",
    "        block_code_documents = tree_create_python_code_and_function_documents(\n",
    "            code_document = joined_code\n",
    "        )\n",
    "\n",
    "        code_doc_index = 0\n",
    "        for code_doc in block_code_documents:\n",
    "            row_split = code_doc.split('\\n')\n",
    "            for row in row_split:\n",
    "                if 'function' in row and 'code' in row:\n",
    "                    function_name = row.split(' ')[1]\n",
    "                    if not function_name in seen_function_names:\n",
    "                        seen_function_names.append(function_name)\n",
    "                    else:\n",
    "                        del block_code_documents[code_doc_index]\n",
    "            code_doc_index += 1\n",
    "        \n",
    "        if 0 < len(block_code_documents):\n",
    "            sub_indexes = False\n",
    "            if 1 < len(block_code_documents):\n",
    "                sub_indexes = True\n",
    "            index = 1\n",
    "            for code_doc in block_code_documents:\n",
    "                if sub_indexes:\n",
    "                    code_documents.append({\n",
    "                        'index': block['id'],\n",
    "                        'sub-index': index, \n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                else:\n",
    "                    code_documents.append({ \n",
    "                        'index': block['id'],\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                index += 1\n",
    "            \n",
    "    formatted_documents = {\n",
    "        'notebook-markdown': markdown_documents,\n",
    "        'notebook-code': code_documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a060a79-f17c-45c6-b81d-ad36d0c0965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_notebook = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'tutorials/cloud_hpc/Cloud-HPC-FMNIST.ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2fb19ea7-3ddc-4fce-99e9-6d37c21f60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_documents = create_notebook_documents(\n",
    "    notebook_text = example_notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe860a31-582b-4fa7-b8bf-73e2ca5919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_document(\n",
    "    mongo_client: any,\n",
    "    database_name: str,\n",
    "    collection_name: str\n",
    "):\n",
    "    document_exists = mongo_check_collection(\n",
    "        mongo_client = mongo_client, \n",
    "        database_name = database_name, \n",
    "        collection_name = collection_name\n",
    "    )\n",
    "\n",
    "    if not document_exists:\n",
    "        \n",
    "\n",
    "\n",
    "def store_github_repository_documents(\n",
    "    repository_paths: any\n",
    ") -> any:\n",
    "    for path in repository_paths:\n",
    "        path_split = path.split('/')\n",
    "        document_database_name = path_split[-1].split('.')[-1]\n",
    "        \n",
    "        document_collection_name = ''\n",
    "        for word in path_split[:-1]:\n",
    "            document_collection_name += word[:2] + '|'\n",
    "        document_collection_name += path_split[-1]\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "        #print(database_name)\n",
    "        #print(collection_name)\n",
    "        \n",
    "        \n",
    "        #print(storage_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a1e1c-3177-41b7-95c7-e0c10f11ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_github_repository_documents(\n",
    "    repository_paths = repository_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f592c78-bda2-4f51-a6b5-fb3a49985456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_check_collection(\n",
    "    mongo_client = mongo_client, \n",
    "    database_name = 'llm-rag-code', \n",
    "    collection_name = 'celery.py'\n",
    ")\n",
    "\n",
    "#mongo_get_document(\n",
    "#    mongo_client = mongo_client, \n",
    "#    database_name = 'llm-rag-code', \n",
    "#    collection_name = 'celery.py', \n",
    "#    filter_query: any\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8146f-a406-488d-bb79-77566dc3bb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
