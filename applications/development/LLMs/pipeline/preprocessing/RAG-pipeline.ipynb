{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76734520-9ec6-4cb9-bed5-477006377137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df5dcf8-2d82-40da-8914-9ce8aef3b84f",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7f7b3f-6c35-47f0-8ba4-f0853ab66d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config,RepositoryEnv\n",
    "env_path = '/home/sfniila/.ssh/.env'\n",
    "env_config = Config(RepositoryEnv(env_path))\n",
    "github_token = env_config.get('GITHUB_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4314a1-75b3-4a21-93ea-da45671295c9",
   "metadata": {},
   "source": [
    "## PyGitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07a4fb-3e77-4418-900a-00355b551a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "def pygithub_get_repo_paths(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    contents = repo.get_contents(\"\")\n",
    "    paths = []\n",
    "    while len(contents) > 0:\n",
    "      file_content = contents.pop(0)\n",
    "      if file_content.type == 'dir':\n",
    "        contents.extend(repo.get_contents(file_content.path))\n",
    "      else:\n",
    "        paths.append(file_content.path)\n",
    "    g.close()\n",
    "    return paths\n",
    "\n",
    "def pygithub_get_path_content(\n",
    "    token: str,\n",
    "    owner: str, \n",
    "    name: str, \n",
    "    path: str\n",
    ") -> any:\n",
    "    g = Github(token)\n",
    "    repo = g.get_repo(f\"{owner}/{name}\")\n",
    "    file_content = repo.get_contents(path)\n",
    "    content = file_content.decoded_content.decode('utf-8')\n",
    "    # fails on some yaml files\n",
    "    # deployment/kubeflow/manifests/contrib/ray/kuberay-operator/base/resources.yaml\n",
    "    # unsupported encoding: none\n",
    "    g.close()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d75007-8269-450f-a54b-c485a324949e",
   "metadata": {},
   "source": [
    "## Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2f0cd3-106c-4b5d-9926-40dd191ee231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_github_repo_documents(\n",
    "    github_token: str,\n",
    "    repo_owner: str,\n",
    "    repo_name: str,\n",
    "    relevant_files: any,\n",
    "    store: bool\n",
    ") -> any:\n",
    "    storage_path = os.getcwd() + '/' + repo_owner + '-' + repo_name + '.txt' \n",
    "\n",
    "    repo_paths = []\n",
    "    if not os.path.exists(storage_path):\n",
    "        print('Getting github paths')\n",
    "        repo_paths = pygithub_get_repo_paths(\n",
    "            token = github_token,\n",
    "            owner = repo_owner, \n",
    "            name = repo_name\n",
    "        )\n",
    "        \n",
    "        if store:\n",
    "            print('Storing paths')\n",
    "            path_amount = len(repo_paths)\n",
    "            i = 0\n",
    "            with open(storage_path, 'w') as file:\n",
    "                for line in repo_paths:\n",
    "                    row = line \n",
    "                    if i < path_amount:\n",
    "                        row += '\\n'\n",
    "                    file.write(row)\n",
    "                    i += 1\n",
    "            print('Paths stored')\n",
    "    else:\n",
    "        print('Getting stored paths')\n",
    "        with open(storage_path, 'r') as file:\n",
    "            repo_paths = file.readlines()\n",
    "    print('Paths fetched')\n",
    "                \n",
    "    print('Filtering paths')\n",
    "    relevant_paths = []\n",
    "    for path in repo_paths:\n",
    "        path_split = path.split('/')\n",
    "        file_end = path_split[-1].split('.')[-1].rstrip()\n",
    "        if file_end in relevant_files:\n",
    "            relevant_paths.append(path.rstrip())\n",
    "    print('Paths filtered')\n",
    "\n",
    "    formatted_paths = {\n",
    "        'paths': relevant_paths\n",
    "    }\n",
    "\n",
    "    # consider how to store this to allas\n",
    "    return formatted_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee717787-4d21-4082-ad61-5b1973926cc9",
   "metadata": {},
   "source": [
    "Files of intrest\n",
    "- md = important to usesr\n",
    "- txt = isn't important to users\n",
    "- sh = isn't important to users\n",
    "- yaml = important to developers\n",
    "- py = important to users and developers\n",
    "- ipynb = important to users and developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ccfa42-95dc-4c8a-9784-fa703937d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stored paths\n",
      "Paths fetched\n",
      "Filtering paths\n",
      "Paths filtered\n"
     ]
    }
   ],
   "source": [
    "repository_paths = get_github_repo_documents(\n",
    "    github_token = github_token,\n",
    "    repo_owner = 'K123AsJ0k1',\n",
    "    repo_name = 'cloud-hpc-oss-mlops-platform',\n",
    "    relevant_files = [\n",
    "        'md',\n",
    "        'yaml',\n",
    "        'py',\n",
    "        'ipynb'\n",
    "    ],\n",
    "    store = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70f6e8-ed91-45c9-afa5-cf598998ac17",
   "metadata": {},
   "source": [
    "# Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfc42e-02e2-4d94-b7f9-9782228cc44d",
   "metadata": {},
   "source": [
    "## Mongo Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e4c444-5608-4dde-bf09-c0364a1b8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient as mc\n",
    "\n",
    "def mongo_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, mc.Connection)\n",
    "\n",
    "def mongo_setup_client(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    address: str,\n",
    "    port: str\n",
    ") -> any:\n",
    "    connection_prefix = 'mongodb://(username):(password)@(address):(port)/'\n",
    "    connection_address = connection_prefix.replace('(username)', username)\n",
    "    connection_address = connection_address.replace('(password)', password)\n",
    "    connection_address = connection_address.replace('(address)', address)\n",
    "    connection_address = connection_address.replace('(port)', port)\n",
    "    mongo_client = mc(\n",
    "        host = connection_address\n",
    "    )\n",
    "    return mongo_client\n",
    "\n",
    "def mongo_get_database(\n",
    "    mongo_client: any,\n",
    "    database_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        return database\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_check_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database_exists = database_name in mongo_client.list_database_names()\n",
    "        return database_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_list_databases(\n",
    "    mongo_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        databases = mongo_client.list_database_names()\n",
    "        return databases\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_database(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        mongo_client.drop_database(database_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_get_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collection = database[collection_name]\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "def mongo_check_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_client[database_name]\n",
    "        collection_exists = collection_name in database.list_collection_names()\n",
    "        return collection_exists\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_update_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_many(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_list_collections(\n",
    "    mongo_client: any, \n",
    "    database_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        collections = database.list_collection_names()\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_remove_collection(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try: \n",
    "        database = mongo_get_database(\n",
    "            mongo_client = mongo_client,\n",
    "            database_name = database_name\n",
    "        )\n",
    "        database.drop_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def mongo_create_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    document: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.insert_one(document)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_get_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    "):\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        document = collection.find_one(filter_query)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None \n",
    "\n",
    "def mongo_list_documents(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any,\n",
    "    sorting_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        documents = list(collection.find(filter_query).sort(sorting_query))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def mongo_update_document(\n",
    "    mongo_client: any, \n",
    "    database_name: any, \n",
    "    collection_name: any, \n",
    "    filter_query: any, \n",
    "    update_query: any\n",
    ") -> any:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.update_one(filter_query, update_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def mongo_remove_document(\n",
    "    mongo_client: any, \n",
    "    database_name: str, \n",
    "    collection_name: str, \n",
    "    filter_query: any\n",
    ") -> bool:\n",
    "    try: \n",
    "        collection = mongo_get_collection(\n",
    "            mongo_client = mongo_client, \n",
    "            database_name = database_name, \n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        result = collection.delete_one(filter_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116c18c-53f1-4222-986f-6e3fa00e65b2",
   "metadata": {},
   "source": [
    "## Markdown documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec230be-1fbe-4b25-90da-078055b830af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def create_markdown_documents(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    \n",
    "    documents = []\n",
    "    document = ''\n",
    "    index = 1\n",
    "    for element in soup.descendants:\n",
    "        if element.name in ['h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            text = element.get_text(strip = True)\n",
    "            if not document == '':\n",
    "                document = document.replace('\\n', '')\n",
    "                if not len(document.split()) == 1:\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'markdown',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    index += 1\n",
    "                document = ''\n",
    "            document += text\n",
    "        elif element.name == 'p':\n",
    "            text = element.get_text(strip = True)\n",
    "            text = re.sub(code_block_pattern, '', text)\n",
    "            text = text.rstrip('\\n')\n",
    "            text = text.replace('\\nsh', '')\n",
    "            text = text.replace('\\nbash', '')\n",
    "            document += ' ' + text\n",
    "        elif element.name in ['ul', 'ol']:\n",
    "            text = ''\n",
    "            for li in element.find_all('li'):\n",
    "                item = li.get_text(strip=True)\n",
    "                if not '-' in item:\n",
    "                    text += '-' + item\n",
    "                    continue\n",
    "                text += item\n",
    "            document += ' ' + text\n",
    "            \n",
    "    documents.append({\n",
    "        'index': index,\n",
    "        'sub-index': 0,\n",
    "        'type': 'markdown',\n",
    "        'data': document\n",
    "    })\n",
    "    \n",
    "    formatted_documents = {\n",
    "        'text': documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d185d0f-0003-4958-a026-0b79c6c62333",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = repository_paths[7]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1c4d08e0-6f5e-41f1-a465-e9829d6cb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_documents = create_markdown_documents(\n",
    "    markdown_text = example_data\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f93ac-63d8-4b9f-8467-e202571ce0aa",
   "metadata": {},
   "source": [
    "## YAML documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b019e009-db94-47b4-9021-9ab915c437b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "def extract_yaml_values(\n",
    "    section: any,\n",
    "    path: str,\n",
    "    values: any\n",
    ") -> any:\n",
    "    for key, value in section.items():\n",
    "        if path == '':\n",
    "            current_path = key\n",
    "        else:\n",
    "            current_path = path + '/' + key\n",
    "        if isinstance(value, dict):\n",
    "            extract_yaml_values(\n",
    "                section = value,\n",
    "                path = current_path,\n",
    "                values = values\n",
    "            )\n",
    "        if isinstance(value, list):\n",
    "            number = 1\n",
    "            \n",
    "            for case in value:\n",
    "                base_path = current_path\n",
    "                if isinstance(case, dict):\n",
    "                   extract_yaml_values(\n",
    "                       section = case,\n",
    "                       path = current_path,\n",
    "                       values = values\n",
    "                   ) \n",
    "                   continue\n",
    "                base_path += '/' + str(number)\n",
    "                number += 1\n",
    "                values.append(base_path + '=' + str(case))\n",
    "        else:\n",
    "            if isinstance(value, dict):\n",
    "                continue\n",
    "            if isinstance(value, list):\n",
    "                continue\n",
    "            values.append(current_path + '=' + str(value))\n",
    "            \n",
    "    return values\n",
    "\n",
    "def create_yaml_documents(\n",
    "    yaml_text: any\n",
    ") -> any:\n",
    "    # has problems with some yaml files\n",
    "    # unsupported encoding: none\n",
    "    # deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-controller.yaml\n",
    "    # 'list' object has no attribute 'items'\n",
    "    # deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-release.yaml\n",
    "    # 'NoneType' object has no attribute 'items'\n",
    "    # deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/base/metadata/overlays/db/kustomization.yaml\n",
    "    #   could not determine a constructor for the tag 'tag:yaml.org,2002:value'\n",
    "    # in \"<unicode string>\", line 41, column 18:\n",
    "    #      delimiter: =\n",
    "    yaml_data = list(yaml.safe_load_all(yaml_text))\n",
    "\n",
    "    documents = []\n",
    "    index = 1\n",
    "    for data in yaml_data:\n",
    "        yaml_values = extract_yaml_values(\n",
    "            section = data,\n",
    "            path = '',\n",
    "            values = []\n",
    "        )\n",
    "\n",
    "        previous_root = ''\n",
    "        document = ''\n",
    "        sub_index = 1\n",
    "        for value in yaml_values:\n",
    "            equal_split = value.split('=')\n",
    "            path_split = equal_split[0].split('/')\n",
    "            root = path_split[0]\n",
    "            if not root == previous_root:\n",
    "                if 0 < len(document):\n",
    "                    documents.append({\n",
    "                        'index': index,\n",
    "                        'sub-index': sub_index,\n",
    "                        'type': 'yaml',\n",
    "                        'data': document\n",
    "                    })\n",
    "                    sub_index += 1\n",
    "                    \n",
    "                previous_root = root\n",
    "                document = value\n",
    "            else:\n",
    "                document += value\n",
    "                \n",
    "        documents.append({\n",
    "            'index': index,\n",
    "            'sub-index': sub_index,\n",
    "            'type': 'yaml',\n",
    "            'data': document\n",
    "        })\n",
    "        index += 1\n",
    "\n",
    "    formatted_documents = {\n",
    "        'text': documents\n",
    "    }\n",
    "            \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "239ffb67-18ec-4a3e-a8ca-57fa1364ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_yaml = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'deployment/forwarder/celery/celery-deployment.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48880c03-8a81-46a5-b207-f0c583e5e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_documents = create_yaml_documents(\n",
    "    yaml_text = example_yaml\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10990a57-ea53-4e0e-9c53-d620811f5b95",
   "metadata": {},
   "source": [
    "## TreeSitter Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c68780-ac71-4ede-84fb-713a7cf56da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "import re\n",
    "\n",
    "def tree_extract_imports(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    imports = []\n",
    "    if node.type == 'import_statement' or node.type == 'import_from_statement':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        imports.append(code_text[start_byte:end_byte].decode('utf8'))\n",
    "    for child in node.children:\n",
    "        imports.extend(tree_extract_imports(child, code_text))\n",
    "    return imports\n",
    "\n",
    "def tree_extract_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    dependencies = []\n",
    "    for child in node.children:\n",
    "        if child.type == 'call':\n",
    "            dependency_name = child.child_by_field_name('function').text.decode('utf8')\n",
    "            dependencies.append(dependency_name)\n",
    "        dependencies.extend(tree_extract_dependencies(child, code_text))\n",
    "    return dependencies\n",
    "\n",
    "def tree_extract_code_and_dependencies(\n",
    "    node: any,\n",
    "    code_text: str\n",
    ") -> any:\n",
    "    codes = []\n",
    "    if not node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name')\n",
    "        if name is None:\n",
    "            code = code_text[start_byte:end_byte].decode('utf8')\n",
    "            if not 'def' in code:\n",
    "                dependencies = tree_extract_dependencies(node, code_text)\n",
    "                codes.append({\n",
    "                    'name': 'global',\n",
    "                    'code': code,\n",
    "                    'dependencies': dependencies\n",
    "                })\n",
    "    return codes\n",
    "\n",
    "def tree_extract_functions_and_dependencies(\n",
    "    node: any, \n",
    "    code_text: str\n",
    ") -> any:\n",
    "    functions = []\n",
    "    if node.type == 'function_definition':\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        name = node.child_by_field_name('name').text.decode('utf8')\n",
    "        code = code_text[start_byte:end_byte].decode('utf8')\n",
    "        dependencies = tree_extract_dependencies(node, code_text)\n",
    "        functions.append({\n",
    "            'name': name,\n",
    "            'code': code,\n",
    "            'dependencies': dependencies\n",
    "        })\n",
    "    for child in node.children:\n",
    "        functions.extend(tree_extract_functions_and_dependencies(child, code_text))\n",
    "    return functions\n",
    "\n",
    "def tree_get_used_imports(\n",
    "    general_imports: any,\n",
    "    function_dependencies: any\n",
    ") -> any:\n",
    "    parsed_imports = {}\n",
    "    for code_import in general_imports:\n",
    "        import_factors = code_import.split('import')[-1].replace(' ', '')\n",
    "        import_factors = import_factors.split(',')\n",
    "    \n",
    "        for factor in import_factors:\n",
    "            if not factor in parsed_imports:\n",
    "                parsed_imports[factor] = code_import.split('import')[0] + 'import ' + factor\n",
    "            \n",
    "    relevant_imports = {}\n",
    "    for dependency in function_dependencies:\n",
    "        initial_term = dependency.split('.')[0]\n",
    "    \n",
    "        if not initial_term in relevant_imports:\n",
    "            if initial_term in parsed_imports:\n",
    "                relevant_imports[initial_term] = parsed_imports[initial_term]\n",
    "    \n",
    "    used_imports = []\n",
    "    for name, code in relevant_imports.items():\n",
    "        used_imports.append(code)\n",
    "\n",
    "    return used_imports\n",
    "\n",
    "def tree_get_used_functions(\n",
    "    general_functions: any,\n",
    "    function_dependencies: any\n",
    "): \n",
    "    used_functions = []\n",
    "    for related_function_name in function_dependencies:\n",
    "        for function in general_functions:\n",
    "            if function['name'] == related_function_name:\n",
    "                used_functions.append('from ice import ' + function['name'])\n",
    "    return used_functions\n",
    "\n",
    "def tree_create_code_document(\n",
    "    code_imports: any,\n",
    "    code_functions: any,\n",
    "    function_item: any\n",
    ") -> any:\n",
    "    used_imports = tree_get_used_imports(\n",
    "        general_imports = code_imports,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "\n",
    "    used_functions = tree_get_used_functions(\n",
    "        general_functions = code_functions,\n",
    "        function_dependencies = function_item['dependencies']\n",
    "    )\n",
    "    \n",
    "    document = {\n",
    "        'imports': used_imports,\n",
    "        'functions': used_functions,\n",
    "        'name': function_item['name'],\n",
    "        'dependencies': function_item['dependencies'],\n",
    "        'code': function_item['code']\n",
    "    }\n",
    "    \n",
    "    return document\n",
    "     \n",
    "def tree_format_code_document(\n",
    "    code_document: any\n",
    ") -> any:\n",
    "    formatted_document = ''\n",
    "    for doc_import in code_document['imports']:\n",
    "        formatted_document += doc_import + '\\n'\n",
    "\n",
    "    for doc_functions in code_document['functions']:\n",
    "        formatted_document += doc_functions + '\\n'\n",
    "\n",
    "    if 0 < len(code_document['dependencies']):\n",
    "        formatted_document += 'code dependencies\\n'\n",
    "\n",
    "        for doc_dependency in code_document['dependencies']:\n",
    "            formatted_document += doc_dependency + '\\n'\n",
    "\n",
    "    if code_document['name'] == 'global':\n",
    "        formatted_document += code_document['name'] + ' code\\n'\n",
    "    else:\n",
    "        formatted_document += 'function ' + code_document['name'] + ' code\\n'\n",
    "    \n",
    "    for line in code_document['code'].splitlines():\n",
    "        if not bool(line.strip()):\n",
    "            continue\n",
    "        doc_code = re.sub(r'#.*','', line)\n",
    "        if not bool(doc_code.strip()):\n",
    "            continue\n",
    "        formatted_document += doc_code + '\\n'    \n",
    "    return formatted_document\n",
    "\n",
    "def tree_create_python_code_and_function_documents(\n",
    "    code_document: any\n",
    "):\n",
    "    PY_LANGUAGE = Language(tspython.language())\n",
    "    parser = Parser(PY_LANGUAGE)\n",
    "   \n",
    "    tree = parser.parse(\n",
    "        bytes(\n",
    "            code_document,\n",
    "            \"utf8\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    root_node = tree.root_node\n",
    "    code_imports = tree_extract_imports(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_global = tree_extract_code_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    code_functions = tree_extract_functions_and_dependencies(\n",
    "        root_node, \n",
    "        bytes(\n",
    "            code_document, \n",
    "            'utf8'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    initial_documents = []\n",
    "    for item in code_global:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    for item in code_functions:\n",
    "        document = tree_create_code_document(\n",
    "            code_imports = code_imports,\n",
    "            code_functions = code_functions,\n",
    "            function_item = item\n",
    "        )  \n",
    "        initial_documents.append(document)\n",
    "\n",
    "    formatted_documents = []\n",
    "    seen_functions = []\n",
    "    for document in initial_documents:\n",
    "        if not document['name'] == 'global':\n",
    "            if document['name'] in seen_functions:\n",
    "                continue\n",
    "        \n",
    "        formatted_document = tree_format_code_document(\n",
    "            code_document = document\n",
    "        )\n",
    "\n",
    "        formatted_documents.append(formatted_document)\n",
    "        seen_functions.append(document['name'])\n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46127d-3124-4243-a7fa-77dae3531c91",
   "metadata": {},
   "source": [
    "## Python documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42502b34-833a-41a5-8eb8-d6b52bb98330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_python_documents(\n",
    "    python_text: any\n",
    "): \n",
    "    joined_code = ''.join(python_text)\n",
    "    block_code_documents = tree_create_python_code_and_function_documents(\n",
    "        code_document = joined_code\n",
    "    )\n",
    "\n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    code_doc_index = 0\n",
    "    for code_doc in block_code_documents:\n",
    "        row_split = code_doc.split('\\n')\n",
    "        for row in row_split:\n",
    "            if 'function' in row and 'code' in row:\n",
    "                # This causes problems with some documents\n",
    "                # list index out of range\n",
    "                function_name = row.split(' ')[1]\n",
    "                if not function_name in seen_function_names:\n",
    "                    seen_function_names.append(function_name)\n",
    "                else:\n",
    "                    del block_code_documents[code_doc_index]\n",
    "        code_doc_index += 1\n",
    "\n",
    "    if 0 < len(block_code_documents):\n",
    "        index = 1\n",
    "        for code_doc in block_code_documents:\n",
    "            code_documents.append({\n",
    "                'index': index,\n",
    "                'sub-index': 0,\n",
    "                'type': 'python',\n",
    "                'data': code_doc\n",
    "            })\n",
    "            index += 1\n",
    "        \n",
    "    formatted_documents = {\n",
    "        'code': code_documents\n",
    "    }\n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7426485-07ce-46ea-8d2b-05b598f3c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_python = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'applications/article/submitter/backend/functions/platforms/flower.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e688f33c-7429-458b-8983-994918e8537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_documents = create_python_documents(\n",
    "    python_text = example_python\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0259e6-052b-4e49-b73b-bd95fd6d3afe",
   "metadata": {},
   "source": [
    "## Notebook documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ecc3b9-29af-42e9-acad-27f50bd8dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from bs4 import BeautifulSoup\n",
    "import markdown\n",
    "\n",
    "def parse_jupyter_notebook_markdown_into_text(\n",
    "    markdown_text: any\n",
    ") -> any:\n",
    "    html = markdown.markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, features='html.parser')\n",
    "    text = soup.get_text()\n",
    "    code_block_pattern = re.compile(r\"```\")\n",
    "    text = re.sub(code_block_pattern, '', text)\n",
    "    text = text.rstrip('\\n')\n",
    "    text = text.replace('\\nsh', '\\n')\n",
    "    text = text.replace('\\nbash', '\\n')\n",
    "    return text\n",
    "\n",
    "def extract_jupyter_notebook_markdown_and_code(\n",
    "    notebook_text: any\n",
    "): \n",
    "    notebook_documents = {\n",
    "        'markdown': [],\n",
    "        'code': []\n",
    "    }\n",
    "\n",
    "    notebook = nbformat.reads(notebook_text, as_version=2)\n",
    "    index = 1\n",
    "    for cell in notebook.worksheets[0].cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            notebook_documents['markdown'].append({\n",
    "                'id': index,\n",
    "                'data': cell.source\n",
    "            })\n",
    "            index += 1\n",
    "        if cell.cell_type == 'code':\n",
    "            notebook_documents['code'].append({\n",
    "                'id': index,\n",
    "                'data': cell.input\n",
    "            })\n",
    "            index += 1\n",
    "    \n",
    "    return notebook_documents\n",
    "\n",
    "def create_notebook_documents(\n",
    "    notebook_text: any\n",
    "):\n",
    "    notebook_documents = extract_jupyter_notebook_markdown_and_code(\n",
    "        notebook_text = notebook_text\n",
    "    )\n",
    "\n",
    "    markdown_documents = []\n",
    "    for block in notebook_documents['markdown']:\n",
    "        joined_text = ''.join(block['data'])\n",
    "        markdown_text = parse_jupyter_notebook_markdown_into_text(\n",
    "            markdown_text = joined_text\n",
    "        )\n",
    "        markdown_documents.append({\n",
    "            'index': block['id'],\n",
    "            'sub-index': 0,\n",
    "            'type': 'markdown',\n",
    "            'data': markdown_text\n",
    "        })\n",
    "        \n",
    "    code_documents = []\n",
    "    seen_function_names = []\n",
    "    for block in notebook_documents['code']:\n",
    "        joined_code = ''.join(block['data'])\n",
    "        block_code_documents = tree_create_python_code_and_function_documents(\n",
    "            code_document = joined_code\n",
    "        )\n",
    "\n",
    "        code_doc_index = 0\n",
    "        for code_doc in block_code_documents:\n",
    "            row_split = code_doc.split('\\n')\n",
    "            for row in row_split:\n",
    "                if 'function' in row and 'code' in row:\n",
    "                    # This causes problems with some documents\n",
    "                    # list index out of range\n",
    "                    function_name = row.split(' ')[1]\n",
    "                    if not function_name in seen_function_names:\n",
    "                        seen_function_names.append(function_name)\n",
    "                    else:\n",
    "                        del block_code_documents[code_doc_index]\n",
    "            code_doc_index += 1\n",
    "        \n",
    "        if 0 < len(block_code_documents):\n",
    "            sub_indexes = False\n",
    "            if 1 < len(block_code_documents):\n",
    "                sub_indexes = True\n",
    "            index = 1\n",
    "            for code_doc in block_code_documents:\n",
    "                if sub_indexes:\n",
    "                    code_documents.append({\n",
    "                        'index': block['id'],\n",
    "                        'sub-index': index, \n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                else:\n",
    "                    code_documents.append({ \n",
    "                        'index': block['id'],\n",
    "                        'sub-index': 0,\n",
    "                        'type': 'python',\n",
    "                        'data': code_doc\n",
    "                    })\n",
    "                index += 1\n",
    "            \n",
    "    formatted_documents = {\n",
    "        'text': markdown_documents,\n",
    "        'code': code_documents\n",
    "    }\n",
    "    \n",
    "    return formatted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a060a79-f17c-45c6-b81d-ad36d0c0965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_notebook = pygithub_get_path_content(\n",
    "    token = github_token,\n",
    "    owner = 'K123AsJ0k1', \n",
    "    name = 'cloud-hpc-oss-mlops-platform', \n",
    "    path = 'tutorials/cloud_hpc/Cloud-HPC-FMNIST.ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2fb19ea7-3ddc-4fce-99e9-6d37c21f60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_documents = create_notebook_documents(\n",
    "    notebook_text = example_notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c944d67-e224-49b5-a01f-d348deb398ae",
   "metadata": {},
   "source": [
    "## Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb12557-3abf-4426-adfd-d42a4706067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = mongo_setup_client(\n",
    "    username = 'mongo123',\n",
    "    password = 'mongo456',\n",
    "    address = '127.0.0.1',\n",
    "    port = '27017'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe860a31-582b-4fa7-b8bf-73e2ca5919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_repository_path_documents(\n",
    "    mongo_client: any,\n",
    "    github_token: any,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    repository_path: str,\n",
    "    database_name: str,\n",
    "    collection_name: str\n",
    "):\n",
    "    collection_exists = mongo_check_collection(\n",
    "        mongo_client = mongo_client, \n",
    "        database_name = database_name, \n",
    "        collection_name = collection_name\n",
    "    )\n",
    "\n",
    "    if collection_exists:\n",
    "        return False\n",
    "\n",
    "    target_content = ''\n",
    "    try:\n",
    "        target_content = pygithub_get_path_content(\n",
    "            token = github_token,\n",
    "            owner = repository_owner, \n",
    "            name = repository_name, \n",
    "            path = repository_path\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(repository_path)\n",
    "        print(e)\n",
    "\n",
    "    if target_content == '':\n",
    "        return False\n",
    "\n",
    "    path_split = repository_path.split('/')\n",
    "    target_type = path_split[-1].split('.')[-1]\n",
    "    \n",
    "    target_documents = {}\n",
    "    if target_type == 'md':\n",
    "        try:\n",
    "            target_documents = create_markdown_documents(\n",
    "                markdown_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print(e)\n",
    "    if target_type == 'yaml':\n",
    "        try:\n",
    "            target_documents = create_yaml_documents(\n",
    "                yaml_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print(e)\n",
    "    if target_type == 'py':\n",
    "        try:\n",
    "            target_documents = create_python_documents(\n",
    "                python_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print(e)\n",
    "    if target_type == 'ipynb':\n",
    "        try:\n",
    "            target_documents = create_notebook_documents(\n",
    "                notebook_text = target_content\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(repository_path)\n",
    "            print(e)\n",
    "    if 0 < len(target_documents):\n",
    "        for doc_type, docs in target_documents.items():\n",
    "            for document in docs:\n",
    "                result = mongo_create_document(\n",
    "                    mongo_client = mongo_client,\n",
    "                    database_name = database_name,\n",
    "                    collection_name = collection_name,\n",
    "                    document = document\n",
    "                )\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_github_storage_prefix(\n",
    "    repository_owner: str,\n",
    "    repository_name: str\n",
    ") -> str:\n",
    "    return repository_owner + '|' + repository_name + '|'\n",
    "\n",
    "def store_github_repository_documents(\n",
    "    mongo_client: any,\n",
    "    github_token: str,\n",
    "    repository_owner: str,\n",
    "    repository_name: str,\n",
    "    repository_paths: any\n",
    ") -> any:\n",
    "    print('Storing paths')\n",
    "    paths = repository_paths['paths']\n",
    "    for path in paths:\n",
    "        path_split = path.split('/')\n",
    "        document_database_name = get_github_storage_prefix(repository_owner, repository_name) + path_split[-1].split('.')[-1]\n",
    "        \n",
    "        document_collection_name = ''\n",
    "        for word in path_split[:-1]:\n",
    "            document_collection_name += word[:2] + '|'\n",
    "        document_collection_name += path_split[-1].split('.')[0]\n",
    "\n",
    "        stored = store_repository_path_documents(\n",
    "            mongo_client = mongo_client,\n",
    "            github_token = github_token,\n",
    "            repository_owner = repository_owner,\n",
    "            repository_name = repository_name,\n",
    "            repository_path = path,\n",
    "            database_name = document_database_name,\n",
    "            collection_name = document_collection_name\n",
    "        )\n",
    "    print('Paths stored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e25a1e1c-3177-41b7-95c7-e0c10f11ca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing paths\n",
      "applications/development/LLMs/pipeline/preprocessing/RAG-Development.ipynb\n",
      "list index out of range\n",
      "applications/development/LLMs/pipeline/preprocessing/RAG-pipeline.ipynb\n",
      "list index out of range\n",
      "applications/development/LLMs/pipeline/preprocessing/RAG_Preprocessing.ipynb\n",
      "list index out of range\n",
      "applications/development/LLMs/pipeline/preprocessing/scripts/documents.py\n",
      "list index out of range\n",
      "applications/development/LLMs/pipeline/preprocessing/scripts/python_parsing.py\n",
      "list index out of range\n",
      "applications/development/LLMs/pipeline/preprocessing/scripts/platforms/tree.py\n",
      "list index out of range\n",
      "deployment/kubeflow/manifests/contrib/ray/kuberay-operator/base/resources.yaml\n",
      "unsupported encoding: none\n",
      "deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/eventing-core.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/in-memory-channel.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/common/knative/knative-eventing/base/upstream/mt-channel-broker.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/common/knative/knative-serving/base/upstream/net-istio.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/common/knative/knative-serving/base/upstream/serving-core.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-openshift/patches/service-serving-cert.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-openshift/patches/webhook-inject-cabundle.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-with-kubeflow/patches/enable-ui-authz-checks.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/katib/upstream/installs/katib-with-kubeflow/patches/ui-rbac.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/openshift-pipelines-custom-task/pipelineloop-controller-patch.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/openshift-pipelines-custom-task/pipelineloop-webhook-patch.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/contrib/kserve/models-web-app/overlays/kubeflow/patches/web-app-vsvc.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/base/metadata/overlays/db/kustomization.yaml\n",
      "could not determine a constructor for the tag 'tag:yaml.org,2002:value'\n",
      "  in \"<unicode string>\", line 41, column 18:\n",
      "          delimiter: =\n",
      "                     ^\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-dashboard/tekton-dashboard-release.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-controller.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-release.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/pipeline/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/pipeline/upstream/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/argo/upstream/manifests/namespace-install/overlays/argo-server-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/argo/upstream/manifests/namespace-install/overlays/workflow-controller-deployment.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-dashboard/tekton-dashboard-release.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-controller.yaml\n",
      "'list' object has no attribute 'items'\n",
      "deployment/kubeflow/manifests/apps/kfp-tekton/upstream/v1/third-party/tekton/upstream/manifests/base/tektoncd-install/tekton-release.yaml\n",
      "'NoneType' object has no attribute 'items'\n",
      "Paths stored\n"
     ]
    }
   ],
   "source": [
    "store_github_repository_documents(\n",
    "    mongo_client = mongo_client,\n",
    "    github_token = github_token,\n",
    "    repository_owner = 'K123AsJ0k1', \n",
    "    repository_name = 'cloud-hpc-oss-mlops-platform', \n",
    "    repository_paths = repository_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4bc4d1-9cd2-489c-8167-027e82ea42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, DESCENDING\n",
    "    \n",
    "def get_stored_documents(\n",
    "    mongo_client: any,\n",
    "    database_prefix: str\n",
    ") -> any:\n",
    "    storage_structure = {}\n",
    "    database_list = mongo_list_databases(\n",
    "        mongo_client = mongo_client\n",
    "    )\n",
    "    for database_name in database_list:\n",
    "        if database_prefix in database_name:\n",
    "            collection_list = mongo_list_collections(\n",
    "                mongo_client = mongo_client,\n",
    "                database_name = database_name\n",
    "            )\n",
    "            storage_structure[database_name] = collection_list\n",
    "    \n",
    "    storage_documents = {}\n",
    "    for database_name, collections in storage_structure.items():\n",
    "        if not database_name in storage_documents:\n",
    "            storage_documents[database_name] = {}\n",
    "        for collection_name in collections:\n",
    "            collection_documents = mongo_list_documents(\n",
    "                mongo_client = mongo_client,\n",
    "                database_name = database_name,\n",
    "                collection_name = collection_name,\n",
    "                filter_query = {},\n",
    "                sorting_query = [\n",
    "                    ('index', ASCENDING),\n",
    "                    ('sub-index', ASCENDING)\n",
    "                ]\n",
    "            )\n",
    "            storage_documents[database_name][collection_name] = collection_documents\n",
    "            \n",
    "    return storage_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed0eee5-bdd0-46b5-8a25-c06f0f5eb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_documents = get_stored_documents(\n",
    "    mongo_client = mongo_client,\n",
    "    database_prefix = get_github_storage_prefix('K123AsJ0k1', 'cloud-hpc-oss-mlops-platform')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea094ed-9324-48ce-b7c3-df51219b44b9",
   "metadata": {},
   "source": [
    "## MinIO Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13ee1a63-b54f-46f9-a7f8-fa1d4540e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pickle\n",
    "from minio import Minio\n",
    "\n",
    "def is_minio_client(\n",
    "    storage_client: any\n",
    ") -> bool:\n",
    "    return isinstance(storage_client, Minio)\n",
    "\n",
    "def setup_minio(\n",
    "    endpoint: str,\n",
    "    username: str,\n",
    "    password: str\n",
    ") -> any:\n",
    "    minio_client = Minio(\n",
    "        endpoint = endpoint, \n",
    "        access_key = username, \n",
    "        secret_key = password,\n",
    "        secure = False\n",
    "    )\n",
    "    return minio_client\n",
    "\n",
    "def pickle_data(\n",
    "    data: any\n",
    ") -> any:\n",
    "    pickled_data = pickle.dumps(data)\n",
    "    length = len(pickled_data)\n",
    "    buffer = io.BytesIO()\n",
    "    buffer.write(pickled_data)\n",
    "    buffer.seek(0)\n",
    "    return buffer, length\n",
    "\n",
    "def unpickle_data(\n",
    "    pickled: any\n",
    ") -> any:\n",
    "    return pickle.loads(pickled)\n",
    "\n",
    "def minio_create_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.make_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def minio_check_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        status = minio_client.bucket_exists(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket checking error')\n",
    "        print(e)\n",
    "        return False \n",
    "       \n",
    "def minio_delete_bucket(\n",
    "    minio_client: any,\n",
    "    bucket_name:str\n",
    ") -> bool:\n",
    "    try:\n",
    "        minio_client.remove_bucket(\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO bucket deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_create_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool: \n",
    "    # Be aware that MinIO objects have a size limit of 1GB, \n",
    "    # which might result to large header error    \n",
    "    #length = len(data)\n",
    "\n",
    "    try:\n",
    "        buffer, length = pickle_data(\n",
    "            data = data\n",
    "        )\n",
    "\n",
    "        minio_client.put_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path,\n",
    "            data = buffer,\n",
    "            length = length,\n",
    "            metadata = metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object creation error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_check_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_path\n",
    "        )      \n",
    "        return object_info\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "# Works\n",
    "def minio_delete_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        minio_client.remove_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('MinIO object deletion error')\n",
    "        print(e)\n",
    "        return False\n",
    "# Works\n",
    "def minio_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any,\n",
    "    metadata: dict\n",
    ") -> bool:  \n",
    "    remove = minio_delete_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    if remove:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data,\n",
    "            metadata = metadata\n",
    "        )\n",
    "    return False\n",
    "# works\n",
    "def minio_create_or_update_object(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    data: any, \n",
    "    metadata: dict\n",
    ") -> bool:\n",
    "    bucket_status = minio_check_bucket(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    if not bucket_status:\n",
    "        creation_status = minio_create_bucket(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    object_status = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not object_status:\n",
    "        return minio_create_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "    else:\n",
    "        return minio_update_object(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            data = data, \n",
    "            metadata = metadata\n",
    "        )\n",
    "# Works\n",
    "def minio_get_object_list(\n",
    "    minio_client: any,\n",
    "    bucket_name: str,\n",
    "    path_prefix: str\n",
    ") -> any:\n",
    "    try:\n",
    "        objects = minio_client.list_objects(\n",
    "            bucket_name = bucket_name, \n",
    "            prefix = path_prefix, \n",
    "            recursive = True\n",
    "        )\n",
    "        return objects\n",
    "    except Exception as e:\n",
    "        return None  \n",
    "    \n",
    "def minio_get_object_data_and_metadata(\n",
    "    minio_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any:\n",
    "    try:\n",
    "        given_object_data = minio_client.get_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        # There seems to be some kind of a limit\n",
    "        # with the amount of request a client \n",
    "        # can make, which is why this variable\n",
    "        # is set here to give more time got the client\n",
    "        # to complete the request\n",
    "\n",
    "        given_data = unpickle_data(\n",
    "            pickled = given_object_data.data\n",
    "        )\n",
    "        \n",
    "        #given_data = given_object_data.data\n",
    "\n",
    "        given_object_info = minio_client.stat_object(\n",
    "            bucket_name = bucket_name, \n",
    "            object_name = object_path\n",
    "        )\n",
    "        \n",
    "        given_metadata = given_object_info.metadata\n",
    "        \n",
    "        return {'data': given_data, 'metadata': given_metadata}\n",
    "    except Exception as e:\n",
    "        print('MinIO object fetching error')\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d75151-e190-4ce3-9e84-4bbdc38ae474",
   "metadata": {},
   "source": [
    "## Storing Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef29494-0db0-4796-921c-82d9d47376dd",
   "metadata": {},
   "source": [
    "## Langchain Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29be8d4a-44bd-418a-acee-c806074116c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def langchain_create_code_chunks(\n",
    "    language: any,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    document: any\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language = language,\n",
    "        chunk_size = chunk_size, \n",
    "        chunk_overlap = chunk_overlap\n",
    "    )\n",
    "\n",
    "    code_chunks = splitter.create_documents([document])\n",
    "    code_chunks = [doc.page_content for doc in code_chunks]\n",
    "    return code_chunks\n",
    "\n",
    "def lanchain_create_text_chunks(\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    document: any\n",
    ") -> any:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size, \n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False\n",
    "    )\n",
    "\n",
    "    text_chunks = splitter.create_documents([document])\n",
    "    text_chunks = [doc.page_content for doc in text_chunks]\n",
    "    return text_chunks\n",
    "\n",
    "def langchain_create_chunk_embeddings(\n",
    "    model_name: str,\n",
    "    chunks: any\n",
    ") -> any:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name = model_name\n",
    "    )\n",
    "    chunk_embeddings = embedding_model.embed_documents(\n",
    "        texts = chunks\n",
    "    )\n",
    "    return chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9aea4c-9ef7-401c-bf94-e8c94c88bbbe",
   "metadata": {},
   "source": [
    "## Qdrant Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3293c5e1-03be-4329-8322-9888680392d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient as qc\n",
    "from qdrant_client import models\n",
    "\n",
    "def qdrant_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, qc.Connection)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_setup_client(\n",
    "    api_key: str,\n",
    "    address: str, \n",
    "    port: str\n",
    ") -> any:\n",
    "    try:\n",
    "        qdrant_client = qc(\n",
    "            host = address,\n",
    "            port = int(port),\n",
    "            api_key = api_key,\n",
    "            https = False\n",
    "        ) \n",
    "        return qdrant_client\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_create_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str,\n",
    "    configuration: any\n",
    ") -> any:\n",
    "    try:\n",
    "        result = qdrant_client.create_collection(\n",
    "            collection_name = collection_name,\n",
    "            vectors_config = configuration\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_get_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        collection = qdrant_client.get_collection(\n",
    "            collection_name = collection_name\n",
    "        )\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def qdrant_list_collections(\n",
    "    qdrant_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        collections = qdrant_client.get_collections()\n",
    "        collection_list = []\n",
    "        for description in collections.collections:\n",
    "            collection_list.append(description.name)\n",
    "        return collection_list\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_remove_collection(\n",
    "    qdrant_client: any, \n",
    "    collection_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        qdrant_client.delete_collection(collection_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def qdrant_upsert_points(\n",
    "    qdrant_client: qc, \n",
    "    collection_name: str,\n",
    "    points: any\n",
    ") -> any:\n",
    "    try:\n",
    "        results = qdrant_client.upsert(\n",
    "            collection_name = collection_name, \n",
    "            points = points\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def qdrant_search_data(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    scroll_filter: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.scroll(\n",
    "            collection_name = collection_name,\n",
    "            scroll_filter = scroll_filter,\n",
    "            limit = limit\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def qdrant_search_vectors(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str,\n",
    "    query_vector: any,\n",
    "    limit: str\n",
    ") -> any:\n",
    "    try:\n",
    "        hits = qdrant_client.search(\n",
    "            collection_name = collection_name,\n",
    "            query_vector = query_vector,\n",
    "            limit = limit\n",
    "        )\n",
    "        return hits\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def qdrant_remove_vectors(\n",
    "    qdrant_client: qc,  \n",
    "    collection_name: str, \n",
    "    vectors: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        results = qdrant_client.delete_vectors(\n",
    "            collection_name = collection_name,\n",
    "            vectors = vectors\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing document: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4dc47b-c7cf-406c-9846-7c53c89f7a29",
   "metadata": {},
   "source": [
    "## Vector Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "126bd9db-f520-4bcc-8c06-de3af348e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import uuid\n",
    "import re\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "def create_document_packet(\n",
    "    document: any,\n",
    "    configuration: any,\n",
    ") -> any:\n",
    "    document_type = document['type']\n",
    "    used_configuration = configuration[document_type]\n",
    "    \n",
    "    document_chunks = []\n",
    "    if document_type == 'python':\n",
    "        document_chunks = langchain_create_code_chunks(\n",
    "            language = used_configuration['language'],\n",
    "            chunk_size = used_configuration['chunk-size'],\n",
    "            chunk_overlap = used_configuration['chunk-overlap'],\n",
    "            document = document['data']\n",
    "        )\n",
    "    if document_type == 'text' or document_type == 'yaml' or document_type == 'markdown':\n",
    "        document_chunks = lanchain_create_text_chunks(\n",
    "            chunk_size = used_configuration['chunk-size'],\n",
    "            chunk_overlap = used_configuration['chunk-overlap'],\n",
    "            document = document['data']\n",
    "        )\n",
    "    # This needs to remove empty chunks\n",
    "    filtered_chunks = []\n",
    "    for chunk in document_chunks:\n",
    "        if chunk.strip():\n",
    "            filtered_chunks.append(chunk)\n",
    "        \n",
    "    vector_embedding = langchain_create_chunk_embeddings(\n",
    "        model_name = used_configuration['model-name'],\n",
    "        chunks = filtered_chunks\n",
    "    )\n",
    "\n",
    "    packet = {\n",
    "        'chunks': filtered_chunks,\n",
    "        'embeddings': vector_embedding\n",
    "    }\n",
    "    \n",
    "    return packet\n",
    "\n",
    "def format_chunk(\n",
    "    document_chunk: any\n",
    ") -> any:\n",
    "    chunk = re.sub(r'[^\\w\\s]', '', document_chunk)\n",
    "    chunk = re.sub(r'\\s+', ' ', chunk) \n",
    "    chunk = chunk.strip()\n",
    "    chunk = chunk.lower()\n",
    "    # This helps to remove unique hashes for duplicates such as:\n",
    "    # task_id = task_id )\n",
    "    # task_id = task_id \n",
    "    # task_id = task_id )\n",
    "    return chunk\n",
    "\n",
    "def generate_chunk_hash(\n",
    "    document_chunk: any\n",
    ") -> any:\n",
    "    cleaned_chunk = format_chunk(\n",
    "        document_chunk = document_chunk\n",
    "    )\n",
    "    return hashlib.md5(cleaned_chunk.encode('utf-8')).hexdigest()\n",
    "\n",
    "def generate_document_vectors(\n",
    "    qdrant_client: any,\n",
    "    document_database: any,\n",
    "    document_collection: any,\n",
    "    document_type: any,\n",
    "    document_id: str, \n",
    "    document_chunks: any,\n",
    "    document_embeddings: any,\n",
    "    vector_collection: any\n",
    "):\n",
    "    vector_points = []\n",
    "    vector_index = 0\n",
    "    added_hashes = []\n",
    "    for chunk in document_chunks:\n",
    "        vector_id = document_id + '-' + str(vector_index + 1)\n",
    "        vector_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, vector_id))\n",
    "\n",
    "        chunk_hash = generate_chunk_hash(\n",
    "            document_chunk = chunk\n",
    "        )\n",
    "        \n",
    "        existing_chunks = qdrant_search_data(\n",
    "            qdrant_client = qdrant_client,\n",
    "            collection_name = vector_collection,\n",
    "            scroll_filter = models.Filter(\n",
    "                must = [\n",
    "                    models.FieldCondition(\n",
    "                        key = 'chunk_hash',\n",
    "                        match = models.MatchValue(\n",
    "                            value = chunk_hash\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit = 1\n",
    "        )\n",
    "        # Removes duplicates\n",
    "        if len(existing_chunks[0]) == 0:\n",
    "            if not chunk_hash in added_hashes:\n",
    "                given_vector = document_embeddings[vector_index]\n",
    "\n",
    "                chunk_point = PointStruct(\n",
    "                    id = vector_uuid, \n",
    "                    vector = given_vector,\n",
    "                    payload = {\n",
    "                        'database': document_database,\n",
    "                        'collection': document_collection,\n",
    "                        'document': document_id,\n",
    "                        'type': document_type,\n",
    "                        'chunk': chunk,\n",
    "                        'chunk_hash': chunk_hash\n",
    "                    }\n",
    "                )\n",
    "                added_hashes.append(chunk_hash)\n",
    "                vector_points.append(chunk_point)\n",
    "        vector_index += 1\n",
    "    return vector_points\n",
    "\n",
    "def create_document_vectors(\n",
    "    qdrant_client: any,\n",
    "    document_database,\n",
    "    document_collection,\n",
    "    document: any,\n",
    "    configuration: any,\n",
    "    vector_collection: str\n",
    ") -> bool:\n",
    "    document_id = str(document['_id'])\n",
    "    document_type = document['type']\n",
    "\n",
    "    document_packet = {}\n",
    "    try:\n",
    "        document_packet = create_document_packet(\n",
    "            document = document,\n",
    "            configuration = configuration\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(document_database,document_collection,document_id)\n",
    "        print(e)\n",
    "\n",
    "    if 0 == len(document_packet):\n",
    "        return []\n",
    "        \n",
    "    document_chunks = document_packet['chunks']\n",
    "    document_embeddings = document_packet['embeddings']\n",
    "    \n",
    "    if 0 == len(document_embeddings):\n",
    "        return []\n",
    "    \n",
    "    vector_collections = qdrant_list_collections(\n",
    "        qdrant_client = qdrant_client\n",
    "    )\n",
    "    \n",
    "    collection_created = None\n",
    "    if not vector_collection in vector_collections:\n",
    "        collection_configuration = VectorParams(\n",
    "            size = len(document_embeddings[0]), \n",
    "            distance = Distance.COSINE\n",
    "        )\n",
    "        collection_created = qdrant_create_collection(\n",
    "            qdrant_client = qdrant_client,\n",
    "            collection_name = vector_collection,\n",
    "            configuration = collection_configuration\n",
    "        )\n",
    "\n",
    "    vector_points = generate_document_vectors(\n",
    "        qdrant_client = qdrant_client,\n",
    "        document_database = document_database,\n",
    "        document_collection = document_collection,\n",
    "        document_type = document_type,\n",
    "        document_id = document_id,\n",
    "        document_chunks = document_chunks,\n",
    "        document_embeddings = document_embeddings,\n",
    "        vector_collection = vector_collection\n",
    "    )\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def store_vectors(\n",
    "    qdrant_client: any,\n",
    "    configuration: any,\n",
    "    storage_documents: any\n",
    "):\n",
    "    print('Storing vectors')\n",
    "    # create progress logs\n",
    "\n",
    "    used_object_bucket = 'llm-rag'\n",
    "    used_object_path = 'vector-documents'\n",
    "    \n",
    "    identities_exists = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path\n",
    "    )\n",
    "\n",
    "    document_identities = []\n",
    "    if not len(identities_exists) == 0:\n",
    "        document_identities = minio_get_object_data_and_metadata(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = used_object_bucket, \n",
    "            object_path = used_object_path\n",
    "        )['data']\n",
    "    \n",
    "    amount_of_databases = len(storage_documents)\n",
    "    database_index = 1\n",
    "    for document_database, document_collections in storage_documents.items():\n",
    "        vector_collection = document_database.replace('|','-') + '-embeddings'\n",
    "        amount_of_collections = len(document_collections)\n",
    "        collection_index = 1\n",
    "        database_vectors = []\n",
    "        for document_collection, documents in document_collections.items():\n",
    "            amount_of_documents = len(documents)\n",
    "            for document in documents:\n",
    "                document_identity = document_database + '-' + document_collection + '-' + str(document['_id'])\n",
    "\n",
    "                if document_identity in document_identities:\n",
    "                    continue\n",
    "                    \n",
    "                document_vectors = create_document_vectors(\n",
    "                    qdrant_client = qdrant_client,\n",
    "                    document_database = document_database,\n",
    "                    document_collection = document_collection,\n",
    "                    document = document,\n",
    "                    configuration = configuration,\n",
    "                    vector_collection = vector_collection\n",
    "                )\n",
    "\n",
    "                if 0 < len(document_vectors):\n",
    "                    database_vectors.extend(document_vectors)\n",
    "                    document_identities.append(document_identity)\n",
    "            print('Collections: ' + str(collection_index) + '|' + str(amount_of_collections))\n",
    "            collection_index += 1\n",
    "        points_stored = qdrant_upsert_points(\n",
    "            qdrant_client = qdrant_client, \n",
    "            collection_name = vector_collection,\n",
    "            points = database_vectors\n",
    "        )\n",
    "        print('Databases: ' + str(database_index) + '|' + str(amount_of_databases))\n",
    "        database_index += 1\n",
    "\n",
    "    minio_create_or_update_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path\n",
    "        data = document_identities, \n",
    "        metadata = {}\n",
    "    )\n",
    "    \n",
    "    print('Vectors stored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb0c0f3a-0b85-4ead-b075-f5a2dd61bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client = setup_minio(\n",
    "    endpoint = '127.0.0.1:9000',\n",
    "    username = 'minio123',\n",
    "    password = 'minio456'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0c446d6-dca4-4d47-9498-1a9c2441f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfniila/Project/cloud-hpc-oss-mlops-platform/applications/development/LLMs/pipeline/llm_venv/lib/python3.10/site-packages/qdrant_client/qdrant_remote.py:130: UserWarning: Api key is used with an insecure connection.\n",
      "  warnings.warn(\"Api key is used with an insecure connection.\")\n"
     ]
    }
   ],
   "source": [
    "qdrant_client = qdrant_setup_client(\n",
    "    api_key = 'qdrant_key',\n",
    "    address = '127.0.0.1', \n",
    "    port = '6333'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6ab5ac0-2963-42f7-a67f-d62380bdbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_configuration = {\n",
    "    'python': {\n",
    "        'language': Language.PYTHON,\n",
    "        'chunk-size': 50,\n",
    "        'chunk-overlap': 0,\n",
    "        'model-name': 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    },\n",
    "    'markdown': {\n",
    "        'chunk-size': 50,\n",
    "        'chunk-overlap': 0,\n",
    "        'model-name': 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    },\n",
    "    'yaml': {\n",
    "        'chunk-size': 50,\n",
    "        'chunk-overlap': 0,\n",
    "        'model-name': 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624bf65-0fa4-4a7f-80a8-070567bd2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_vectors(\n",
    "    qdrant_client = qdrant_client,\n",
    "    configuration = vector_configuration,\n",
    "    storage_documents = stored_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07548d-e73d-49f4-afce-cb74d798974e",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a989b4b-c898-433d-809a-ebf091e24516",
   "metadata": {},
   "source": [
    "## SpaCy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "664663d3-39ac-4acb-bc1b-e741daebf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_document_keywords(\n",
    "    document: str\n",
    "):\n",
    "    doc = nlp(document.lower())\n",
    "    \n",
    "    keywords = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop               \n",
    "        and not token.is_punct              \n",
    "        and not token.is_space              \n",
    "        and len(token) > 1                  \n",
    "    ]\n",
    "    \n",
    "    keywords = list(set(keywords))\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8d0c9-7e6a-477e-bd1e-f5a3a5925a6c",
   "metadata": {},
   "source": [
    "## Meili Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b06b314-ccbc-41cf-8160-2bb92286e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meilisearch as ms\n",
    "\n",
    "def meili_is_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        return isinstance(storage_client, ms.Connection)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def meili_setup_client(\n",
    "    host: str, \n",
    "    api_key: str\n",
    ") -> any:\n",
    "    try:\n",
    "        meili_client = ms.Client(\n",
    "            url = host, \n",
    "            api_key = api_key\n",
    "        )\n",
    "        return meili_client \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_get_index( \n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_check_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        meili_client.get_index(\n",
    "            uid = index_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "def meili_remove_index(\n",
    "    meili_client: any, \n",
    "    index_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        response = meili_client.index(\n",
    "            index_name = index_name\n",
    "        ).delete()\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_list_indexes(\n",
    "    meili_client: any\n",
    ") -> bool:\n",
    "    try:\n",
    "        indexes = meili_client.get_indexes()\n",
    "        return indexes\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_add_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    documents: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.add_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_set_filterable(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    attributes: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_filterable_attributes(attributes)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_search_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    query: any, \n",
    "    options: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_get_index(\n",
    "            meili_client = meili_client,\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.search(\n",
    "            query,\n",
    "            options\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def meili_update_documents(\n",
    "    meili_client, \n",
    "    index_name, \n",
    "    documents\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.update_documents(\n",
    "            documents = documents\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def meili_delete_documents(\n",
    "    meili_client: any, \n",
    "    index_name: str, \n",
    "    ids: any\n",
    ") -> any:\n",
    "    try:\n",
    "        index = meili_client.index(\n",
    "            index_name = index_name\n",
    "        )\n",
    "        response = index.delete_documents(\n",
    "            document_ids = ids\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b71ef-af43-4e45-a4d2-84e41acccb87",
   "metadata": {},
   "source": [
    "## Keyword Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72b4bef1-d26c-44a3-a6b6-c1249a4caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def generate_keyword_uuid(\n",
    "    document_id: str,\n",
    "    document_index: int\n",
    ") -> str:\n",
    "    keyword_id = document_id + '-' + str(document_index + 1)\n",
    "    keyword_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, keyword_id))\n",
    "    return keyword_uuid\n",
    "\n",
    "def create_document_keywords(\n",
    "    document_database: str,\n",
    "    document_collection: str,\n",
    "    document: any,\n",
    "    document_index: int\n",
    ") -> any:\n",
    "    document_id = str(document['_id'])\n",
    "    document_data = document['data']\n",
    "    document_type = document['type']\n",
    "\n",
    "    document_keywords = []\n",
    "    try:\n",
    "        document_keywords = get_document_keywords(\n",
    "            document = document_data\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if 0 == len(document_keywords):\n",
    "        return {}\n",
    "    \n",
    "    keyword_uuid = generate_keyword_uuid(\n",
    "        document_id = document_id,\n",
    "        document_index = document_index\n",
    "    ) \n",
    "\n",
    "    payload = {\n",
    "        'id': keyword_uuid,\n",
    "        'database': document_database,\n",
    "        'collection': document_collection,\n",
    "        'document': document_id,\n",
    "        'type': document_type,\n",
    "        'keywords': document_keywords\n",
    "    }\n",
    "\n",
    "    return payload\n",
    "    \n",
    "def store_keywords(\n",
    "    minio_client: any,\n",
    "    meili_client: any,\n",
    "    storage_documents: any\n",
    "):\n",
    "\n",
    "    used_object_bucket = 'llm-rag'\n",
    "    used_object_path = 'search-documents'\n",
    "    \n",
    "    identities_exists = minio_check_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path\n",
    "    )\n",
    "\n",
    "    document_identities = []\n",
    "    if not len(identities_exists) == 0:\n",
    "        document_identities = minio_get_object_data_and_metadata(\n",
    "            minio_client = minio_client,\n",
    "            bucket_name = used_object_bucket, \n",
    "            object_path = used_object_path\n",
    "        )['data']\n",
    "\n",
    "    amount_of_databases = len(storage_documents)\n",
    "    database_index = 1\n",
    "    for document_database, collections in storage_documents.items():\n",
    "        keyword_collection = document_database.replace('|','-') + '-keywords'\n",
    "        database_keywords = []\n",
    "        collection_index = 1\n",
    "        amount_of_collections = len(collections)\n",
    "        for document_collection, documents in collections.items():\n",
    "            document_index = 1\n",
    "            for document in documents:\n",
    "                document_identity = document_database + '-' + document_collection + '-' + str(document['_id'])\n",
    "\n",
    "                if document_identity in document_identities:\n",
    "                    continue\n",
    "\n",
    "                document_keywords = create_document_keywords(\n",
    "                    document_database = document_database,\n",
    "                    document_collection = document_collection,\n",
    "                    document = document,\n",
    "                    document_index = document_index\n",
    "                )\n",
    "\n",
    "                if 0 < len(document_keywords):\n",
    "                    database_keywords.append(document_keywords)\n",
    "                    document_identities.append(document_identity)\n",
    "            print('Collections: ' + str(collection_index) + '|' + str(amount_of_collections))\n",
    "            collection_index += 1\n",
    "        #print(database_keywords)\n",
    "        stored = meili_add_documents(\n",
    "            meili_client = meili_client,\n",
    "            index_name = keyword_collection,\n",
    "            documents = database_keywords\n",
    "        )\n",
    "        print('Databases: ' + str(database_index) + '|' + str(amount_of_databases))\n",
    "        database_index += 1\n",
    "        \n",
    "    minio_create_or_update_object(\n",
    "        minio_client = minio_client,\n",
    "        bucket_name = used_object_bucket, \n",
    "        object_path = used_object_path,\n",
    "        data = document_identities, \n",
    "        metadata = {}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5fbc769-527e-48a4-b952-b767ab4c10a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskInfo(task_uid=42, index_uid='K123AsJ0k1-cloud-hpc-oss-mlops-platform-py-keywords', status='enqueued', type='indexDeletion', enqueued_at=datetime.datetime(2024, 11, 1, 14, 3, 58, 519677))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meili_client.index('K123AsJ0k1-cloud-hpc-oss-mlops-platform-py-keywords').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61da8311-8864-46fe-b533-61908700ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "meili_client = meili_setup_client(\n",
    "    host = 'http://127.0.0.1:7700', \n",
    "    api_key = 'meili_key'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a6d8d0f-d008-4013-b352-4960815777f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections: 1|16\n",
      "Collections: 2|16\n",
      "Collections: 3|16\n",
      "Collections: 4|16\n",
      "Collections: 5|16\n",
      "Collections: 6|16\n",
      "Collections: 7|16\n",
      "Collections: 8|16\n",
      "Collections: 9|16\n",
      "Collections: 10|16\n",
      "Collections: 11|16\n",
      "Collections: 12|16\n",
      "Collections: 13|16\n",
      "Collections: 14|16\n",
      "Collections: 15|16\n",
      "Collections: 16|16\n",
      "Databases: 1|4\n",
      "Collections: 1|84\n",
      "Collections: 2|84\n",
      "Collections: 3|84\n",
      "Collections: 4|84\n",
      "Collections: 5|84\n",
      "Collections: 6|84\n",
      "Collections: 7|84\n",
      "Collections: 8|84\n",
      "Collections: 9|84\n",
      "Collections: 10|84\n",
      "Collections: 11|84\n",
      "Collections: 12|84\n",
      "Collections: 13|84\n",
      "Collections: 14|84\n",
      "Collections: 15|84\n",
      "Collections: 16|84\n",
      "Collections: 17|84\n",
      "Collections: 18|84\n",
      "Collections: 19|84\n",
      "Collections: 20|84\n",
      "Collections: 21|84\n",
      "Collections: 22|84\n",
      "Collections: 23|84\n",
      "Collections: 24|84\n",
      "Collections: 25|84\n",
      "Collections: 26|84\n",
      "Collections: 27|84\n",
      "Collections: 28|84\n",
      "Collections: 29|84\n",
      "Collections: 30|84\n",
      "Collections: 31|84\n",
      "Collections: 32|84\n",
      "Collections: 33|84\n",
      "Collections: 34|84\n",
      "Collections: 35|84\n",
      "Collections: 36|84\n",
      "Collections: 37|84\n",
      "Collections: 38|84\n",
      "Collections: 39|84\n",
      "Collections: 40|84\n",
      "Collections: 41|84\n",
      "Collections: 42|84\n",
      "Collections: 43|84\n",
      "Collections: 44|84\n",
      "Collections: 45|84\n",
      "Collections: 46|84\n",
      "Collections: 47|84\n",
      "Collections: 48|84\n",
      "Collections: 49|84\n",
      "Collections: 50|84\n",
      "Collections: 51|84\n",
      "Collections: 52|84\n",
      "Collections: 53|84\n",
      "Collections: 54|84\n",
      "Collections: 55|84\n",
      "Collections: 56|84\n",
      "Collections: 57|84\n",
      "Collections: 58|84\n",
      "Collections: 59|84\n",
      "Collections: 60|84\n",
      "Collections: 61|84\n",
      "Collections: 62|84\n",
      "Collections: 63|84\n",
      "Collections: 64|84\n",
      "Collections: 65|84\n",
      "Collections: 66|84\n",
      "Collections: 67|84\n",
      "Collections: 68|84\n",
      "Collections: 69|84\n",
      "Collections: 70|84\n",
      "Collections: 71|84\n",
      "Collections: 72|84\n",
      "Collections: 73|84\n",
      "Collections: 74|84\n",
      "Collections: 75|84\n",
      "Collections: 76|84\n",
      "Collections: 77|84\n",
      "Collections: 78|84\n",
      "Collections: 79|84\n",
      "Collections: 80|84\n",
      "Collections: 81|84\n",
      "Collections: 82|84\n",
      "Collections: 83|84\n",
      "Collections: 84|84\n",
      "Databases: 2|4\n",
      "Collections: 1|336\n",
      "Collections: 2|336\n",
      "Collections: 3|336\n",
      "Collections: 4|336\n",
      "Collections: 5|336\n",
      "Collections: 6|336\n",
      "Collections: 7|336\n",
      "Collections: 8|336\n",
      "Collections: 9|336\n",
      "Collections: 10|336\n",
      "Collections: 11|336\n",
      "Collections: 12|336\n",
      "Collections: 13|336\n",
      "Collections: 14|336\n",
      "Collections: 15|336\n",
      "Collections: 16|336\n",
      "Collections: 17|336\n",
      "Collections: 18|336\n",
      "Collections: 19|336\n",
      "Collections: 20|336\n",
      "Collections: 21|336\n",
      "Collections: 22|336\n",
      "Collections: 23|336\n",
      "Collections: 24|336\n",
      "Collections: 25|336\n",
      "Collections: 26|336\n",
      "Collections: 27|336\n",
      "Collections: 28|336\n",
      "Collections: 29|336\n",
      "Collections: 30|336\n",
      "Collections: 31|336\n",
      "Collections: 32|336\n",
      "Collections: 33|336\n",
      "Collections: 34|336\n",
      "Collections: 35|336\n",
      "Collections: 36|336\n",
      "Collections: 37|336\n",
      "Collections: 38|336\n",
      "Collections: 39|336\n",
      "Collections: 40|336\n",
      "Collections: 41|336\n",
      "Collections: 42|336\n",
      "Collections: 43|336\n",
      "Collections: 44|336\n",
      "Collections: 45|336\n",
      "Collections: 46|336\n",
      "Collections: 47|336\n",
      "Collections: 48|336\n",
      "Collections: 49|336\n",
      "Collections: 50|336\n",
      "Collections: 51|336\n",
      "Collections: 52|336\n",
      "Collections: 53|336\n",
      "Collections: 54|336\n",
      "Collections: 55|336\n",
      "Collections: 56|336\n",
      "Collections: 57|336\n",
      "Collections: 58|336\n",
      "Collections: 59|336\n",
      "Collections: 60|336\n",
      "Collections: 61|336\n",
      "Collections: 62|336\n",
      "Collections: 63|336\n",
      "Collections: 64|336\n",
      "Collections: 65|336\n",
      "Collections: 66|336\n",
      "Collections: 67|336\n",
      "Collections: 68|336\n",
      "Collections: 69|336\n",
      "Collections: 70|336\n",
      "Collections: 71|336\n",
      "Collections: 72|336\n",
      "Collections: 73|336\n",
      "Collections: 74|336\n",
      "Collections: 75|336\n",
      "Collections: 76|336\n",
      "Collections: 77|336\n",
      "Collections: 78|336\n",
      "Collections: 79|336\n",
      "Collections: 80|336\n",
      "Collections: 81|336\n",
      "Collections: 82|336\n",
      "Collections: 83|336\n",
      "Collections: 84|336\n",
      "Collections: 85|336\n",
      "Collections: 86|336\n",
      "Collections: 87|336\n",
      "Collections: 88|336\n",
      "Collections: 89|336\n",
      "Collections: 90|336\n",
      "Collections: 91|336\n",
      "Collections: 92|336\n",
      "Collections: 93|336\n",
      "Collections: 94|336\n",
      "Collections: 95|336\n",
      "Collections: 96|336\n",
      "Collections: 97|336\n",
      "Collections: 98|336\n",
      "Collections: 99|336\n",
      "Collections: 100|336\n",
      "Collections: 101|336\n",
      "Collections: 102|336\n",
      "Collections: 103|336\n",
      "Collections: 104|336\n",
      "Collections: 105|336\n",
      "Collections: 106|336\n",
      "Collections: 107|336\n",
      "Collections: 108|336\n",
      "Collections: 109|336\n",
      "Collections: 110|336\n",
      "Collections: 111|336\n",
      "Collections: 112|336\n",
      "Collections: 113|336\n",
      "Collections: 114|336\n",
      "Collections: 115|336\n",
      "Collections: 116|336\n",
      "Collections: 117|336\n",
      "Collections: 118|336\n",
      "Collections: 119|336\n",
      "Collections: 120|336\n",
      "Collections: 121|336\n",
      "Collections: 122|336\n",
      "Collections: 123|336\n",
      "Collections: 124|336\n",
      "Collections: 125|336\n",
      "Collections: 126|336\n",
      "Collections: 127|336\n",
      "Collections: 128|336\n",
      "Collections: 129|336\n",
      "Collections: 130|336\n",
      "Collections: 131|336\n",
      "Collections: 132|336\n",
      "Collections: 133|336\n",
      "Collections: 134|336\n",
      "Collections: 135|336\n",
      "Collections: 136|336\n",
      "Collections: 137|336\n",
      "Collections: 138|336\n",
      "Collections: 139|336\n",
      "Collections: 140|336\n",
      "Collections: 141|336\n",
      "Collections: 142|336\n",
      "Collections: 143|336\n",
      "Collections: 144|336\n",
      "Collections: 145|336\n",
      "Collections: 146|336\n",
      "Collections: 147|336\n",
      "Collections: 148|336\n",
      "Collections: 149|336\n",
      "Collections: 150|336\n",
      "Collections: 151|336\n",
      "Collections: 152|336\n",
      "Collections: 153|336\n",
      "Collections: 154|336\n",
      "Collections: 155|336\n",
      "Collections: 156|336\n",
      "Collections: 157|336\n",
      "Collections: 158|336\n",
      "Collections: 159|336\n",
      "Collections: 160|336\n",
      "Collections: 161|336\n",
      "Collections: 162|336\n",
      "Collections: 163|336\n",
      "Collections: 164|336\n",
      "Collections: 165|336\n",
      "Collections: 166|336\n",
      "Collections: 167|336\n",
      "Collections: 168|336\n",
      "Collections: 169|336\n",
      "Collections: 170|336\n",
      "Collections: 171|336\n",
      "Collections: 172|336\n",
      "Collections: 173|336\n",
      "Collections: 174|336\n",
      "Collections: 175|336\n",
      "Collections: 176|336\n",
      "Collections: 177|336\n",
      "Collections: 178|336\n",
      "Collections: 179|336\n",
      "Collections: 180|336\n",
      "Collections: 181|336\n",
      "Collections: 182|336\n",
      "Collections: 183|336\n",
      "Collections: 184|336\n",
      "Collections: 185|336\n",
      "Collections: 186|336\n",
      "Collections: 187|336\n",
      "Collections: 188|336\n",
      "Collections: 189|336\n",
      "Collections: 190|336\n",
      "Collections: 191|336\n",
      "Collections: 192|336\n",
      "Collections: 193|336\n",
      "Collections: 194|336\n",
      "Collections: 195|336\n",
      "Collections: 196|336\n",
      "Collections: 197|336\n",
      "Collections: 198|336\n",
      "Collections: 199|336\n",
      "Collections: 200|336\n",
      "Collections: 201|336\n",
      "Collections: 202|336\n",
      "Collections: 203|336\n",
      "Collections: 204|336\n",
      "Collections: 205|336\n",
      "Collections: 206|336\n",
      "Collections: 207|336\n",
      "Collections: 208|336\n",
      "Collections: 209|336\n",
      "Collections: 210|336\n",
      "Collections: 211|336\n",
      "Collections: 212|336\n",
      "Collections: 213|336\n",
      "Collections: 214|336\n",
      "Collections: 215|336\n",
      "Collections: 216|336\n",
      "Collections: 217|336\n",
      "Collections: 218|336\n",
      "Collections: 219|336\n",
      "Collections: 220|336\n",
      "Collections: 221|336\n",
      "Collections: 222|336\n",
      "Collections: 223|336\n",
      "Collections: 224|336\n",
      "Collections: 225|336\n",
      "Collections: 226|336\n",
      "Collections: 227|336\n",
      "Collections: 228|336\n",
      "Collections: 229|336\n",
      "Collections: 230|336\n",
      "Collections: 231|336\n",
      "Collections: 232|336\n",
      "Collections: 233|336\n",
      "Collections: 234|336\n",
      "Collections: 235|336\n",
      "Collections: 236|336\n",
      "Collections: 237|336\n",
      "Collections: 238|336\n",
      "Collections: 239|336\n",
      "Collections: 240|336\n",
      "Collections: 241|336\n",
      "Collections: 242|336\n",
      "Collections: 243|336\n",
      "Collections: 244|336\n",
      "Collections: 245|336\n",
      "Collections: 246|336\n",
      "Collections: 247|336\n",
      "Collections: 248|336\n",
      "Collections: 249|336\n",
      "Collections: 250|336\n",
      "Collections: 251|336\n",
      "Collections: 252|336\n",
      "Collections: 253|336\n",
      "Collections: 254|336\n",
      "Collections: 255|336\n",
      "Collections: 256|336\n",
      "Collections: 257|336\n",
      "Collections: 258|336\n",
      "Collections: 259|336\n",
      "Collections: 260|336\n",
      "Collections: 261|336\n",
      "Collections: 262|336\n",
      "Collections: 263|336\n",
      "Collections: 264|336\n",
      "Collections: 265|336\n",
      "Collections: 266|336\n",
      "Collections: 267|336\n",
      "Collections: 268|336\n",
      "Collections: 269|336\n",
      "Collections: 270|336\n",
      "Collections: 271|336\n",
      "Collections: 272|336\n",
      "Collections: 273|336\n",
      "Collections: 274|336\n",
      "Collections: 275|336\n",
      "Collections: 276|336\n",
      "Collections: 277|336\n",
      "Collections: 278|336\n",
      "Collections: 279|336\n",
      "Collections: 280|336\n",
      "Collections: 281|336\n",
      "Collections: 282|336\n",
      "Collections: 283|336\n",
      "Collections: 284|336\n",
      "Collections: 285|336\n",
      "Collections: 286|336\n",
      "Collections: 287|336\n",
      "Collections: 288|336\n",
      "Collections: 289|336\n",
      "Collections: 290|336\n",
      "Collections: 291|336\n",
      "Collections: 292|336\n",
      "Collections: 293|336\n",
      "Collections: 294|336\n",
      "Collections: 295|336\n",
      "Collections: 296|336\n",
      "Collections: 297|336\n",
      "Collections: 298|336\n",
      "Collections: 299|336\n",
      "Collections: 300|336\n",
      "Collections: 301|336\n",
      "Collections: 302|336\n",
      "Collections: 303|336\n",
      "Collections: 304|336\n",
      "Collections: 305|336\n",
      "Collections: 306|336\n",
      "Collections: 307|336\n",
      "Collections: 308|336\n",
      "Collections: 309|336\n",
      "Collections: 310|336\n",
      "Collections: 311|336\n",
      "Collections: 312|336\n",
      "Collections: 313|336\n",
      "Collections: 314|336\n",
      "Collections: 315|336\n",
      "Collections: 316|336\n",
      "Collections: 317|336\n",
      "Collections: 318|336\n",
      "Collections: 319|336\n",
      "Collections: 320|336\n",
      "Collections: 321|336\n",
      "Collections: 322|336\n",
      "Collections: 323|336\n",
      "Collections: 324|336\n",
      "Collections: 325|336\n",
      "Collections: 326|336\n",
      "Collections: 327|336\n",
      "Collections: 328|336\n",
      "Collections: 329|336\n",
      "Collections: 330|336\n",
      "Collections: 331|336\n",
      "Collections: 332|336\n",
      "Collections: 333|336\n",
      "Collections: 334|336\n",
      "Collections: 335|336\n",
      "Collections: 336|336\n",
      "Databases: 3|4\n",
      "Collections: 1|1534\n",
      "Collections: 2|1534\n",
      "Collections: 3|1534\n",
      "Collections: 4|1534\n",
      "Collections: 5|1534\n",
      "Collections: 6|1534\n",
      "Collections: 7|1534\n",
      "Collections: 8|1534\n",
      "Collections: 9|1534\n",
      "Collections: 10|1534\n",
      "Collections: 11|1534\n",
      "Collections: 12|1534\n",
      "Collections: 13|1534\n",
      "Collections: 14|1534\n",
      "Collections: 15|1534\n",
      "Collections: 16|1534\n",
      "Collections: 17|1534\n",
      "Collections: 18|1534\n",
      "Collections: 19|1534\n",
      "Collections: 20|1534\n",
      "Collections: 21|1534\n",
      "Collections: 22|1534\n",
      "Collections: 23|1534\n",
      "Collections: 24|1534\n",
      "Collections: 25|1534\n",
      "Collections: 26|1534\n",
      "Collections: 27|1534\n",
      "Collections: 28|1534\n",
      "Collections: 29|1534\n",
      "Collections: 30|1534\n",
      "Collections: 31|1534\n",
      "Collections: 32|1534\n",
      "Collections: 33|1534\n",
      "Collections: 34|1534\n",
      "Collections: 35|1534\n",
      "Collections: 36|1534\n",
      "Collections: 37|1534\n",
      "Collections: 38|1534\n",
      "Collections: 39|1534\n",
      "Collections: 40|1534\n",
      "Collections: 41|1534\n",
      "Collections: 42|1534\n",
      "Collections: 43|1534\n",
      "Collections: 44|1534\n",
      "Collections: 45|1534\n",
      "Collections: 46|1534\n",
      "Collections: 47|1534\n",
      "Collections: 48|1534\n",
      "Collections: 49|1534\n",
      "Collections: 50|1534\n",
      "Collections: 51|1534\n",
      "Collections: 52|1534\n",
      "Collections: 53|1534\n",
      "Collections: 54|1534\n",
      "Collections: 55|1534\n",
      "Collections: 56|1534\n",
      "Collections: 57|1534\n",
      "Collections: 58|1534\n",
      "Collections: 59|1534\n",
      "Collections: 60|1534\n",
      "Collections: 61|1534\n",
      "Collections: 62|1534\n",
      "Collections: 63|1534\n",
      "Collections: 64|1534\n",
      "Collections: 65|1534\n",
      "Collections: 66|1534\n",
      "Collections: 67|1534\n",
      "Collections: 68|1534\n",
      "Collections: 69|1534\n",
      "Collections: 70|1534\n",
      "Collections: 71|1534\n",
      "Collections: 72|1534\n",
      "Collections: 73|1534\n",
      "Collections: 74|1534\n",
      "Collections: 75|1534\n",
      "Collections: 76|1534\n",
      "Collections: 77|1534\n",
      "Collections: 78|1534\n",
      "Collections: 79|1534\n",
      "Collections: 80|1534\n",
      "Collections: 81|1534\n",
      "Collections: 82|1534\n",
      "Collections: 83|1534\n",
      "Collections: 84|1534\n",
      "Collections: 85|1534\n",
      "Collections: 86|1534\n",
      "Collections: 87|1534\n",
      "Collections: 88|1534\n",
      "Collections: 89|1534\n",
      "Collections: 90|1534\n",
      "Collections: 91|1534\n",
      "Collections: 92|1534\n",
      "Collections: 93|1534\n",
      "Collections: 94|1534\n",
      "Collections: 95|1534\n",
      "Collections: 96|1534\n",
      "Collections: 97|1534\n",
      "Collections: 98|1534\n",
      "Collections: 99|1534\n",
      "Collections: 100|1534\n",
      "Collections: 101|1534\n",
      "Collections: 102|1534\n",
      "Collections: 103|1534\n",
      "Collections: 104|1534\n",
      "Collections: 105|1534\n",
      "Collections: 106|1534\n",
      "Collections: 107|1534\n",
      "Collections: 108|1534\n",
      "Collections: 109|1534\n",
      "Collections: 110|1534\n",
      "Collections: 111|1534\n",
      "Collections: 112|1534\n",
      "Collections: 113|1534\n",
      "Collections: 114|1534\n",
      "Collections: 115|1534\n",
      "Collections: 116|1534\n",
      "Collections: 117|1534\n",
      "Collections: 118|1534\n",
      "Collections: 119|1534\n",
      "Collections: 120|1534\n",
      "Collections: 121|1534\n",
      "Collections: 122|1534\n",
      "Collections: 123|1534\n",
      "Collections: 124|1534\n",
      "Collections: 125|1534\n",
      "Collections: 126|1534\n",
      "Collections: 127|1534\n",
      "Collections: 128|1534\n",
      "Collections: 129|1534\n",
      "Collections: 130|1534\n",
      "Collections: 131|1534\n",
      "Collections: 132|1534\n",
      "Collections: 133|1534\n",
      "Collections: 134|1534\n",
      "Collections: 135|1534\n",
      "Collections: 136|1534\n",
      "Collections: 137|1534\n",
      "Collections: 138|1534\n",
      "Collections: 139|1534\n",
      "Collections: 140|1534\n",
      "Collections: 141|1534\n",
      "Collections: 142|1534\n",
      "Collections: 143|1534\n",
      "Collections: 144|1534\n",
      "Collections: 145|1534\n",
      "Collections: 146|1534\n",
      "Collections: 147|1534\n",
      "Collections: 148|1534\n",
      "Collections: 149|1534\n",
      "Collections: 150|1534\n",
      "Collections: 151|1534\n",
      "Collections: 152|1534\n",
      "Collections: 153|1534\n",
      "Collections: 154|1534\n",
      "Collections: 155|1534\n",
      "Collections: 156|1534\n",
      "Collections: 157|1534\n",
      "Collections: 158|1534\n",
      "Collections: 159|1534\n",
      "Collections: 160|1534\n",
      "Collections: 161|1534\n",
      "Collections: 162|1534\n",
      "Collections: 163|1534\n",
      "Collections: 164|1534\n",
      "Collections: 165|1534\n",
      "Collections: 166|1534\n",
      "Collections: 167|1534\n",
      "Collections: 168|1534\n",
      "Collections: 169|1534\n",
      "Collections: 170|1534\n",
      "Collections: 171|1534\n",
      "Collections: 172|1534\n",
      "Collections: 173|1534\n",
      "Collections: 174|1534\n",
      "Collections: 175|1534\n",
      "Collections: 176|1534\n",
      "Collections: 177|1534\n",
      "Collections: 178|1534\n",
      "Collections: 179|1534\n",
      "Collections: 180|1534\n",
      "Collections: 181|1534\n",
      "Collections: 182|1534\n",
      "Collections: 183|1534\n",
      "Collections: 184|1534\n",
      "Collections: 185|1534\n",
      "Collections: 186|1534\n",
      "Collections: 187|1534\n",
      "Collections: 188|1534\n",
      "Collections: 189|1534\n",
      "Collections: 190|1534\n",
      "Collections: 191|1534\n",
      "Collections: 192|1534\n",
      "Collections: 193|1534\n",
      "Collections: 194|1534\n",
      "Collections: 195|1534\n",
      "Collections: 196|1534\n",
      "Collections: 197|1534\n",
      "Collections: 198|1534\n",
      "Collections: 199|1534\n",
      "Collections: 200|1534\n",
      "Collections: 201|1534\n",
      "Collections: 202|1534\n",
      "Collections: 203|1534\n",
      "Collections: 204|1534\n",
      "Collections: 205|1534\n",
      "Collections: 206|1534\n",
      "Collections: 207|1534\n",
      "Collections: 208|1534\n",
      "Collections: 209|1534\n",
      "Collections: 210|1534\n",
      "Collections: 211|1534\n",
      "Collections: 212|1534\n",
      "Collections: 213|1534\n",
      "Collections: 214|1534\n",
      "Collections: 215|1534\n",
      "Collections: 216|1534\n",
      "Collections: 217|1534\n",
      "Collections: 218|1534\n",
      "Collections: 219|1534\n",
      "Collections: 220|1534\n",
      "Collections: 221|1534\n",
      "Collections: 222|1534\n",
      "Collections: 223|1534\n",
      "Collections: 224|1534\n",
      "Collections: 225|1534\n",
      "Collections: 226|1534\n",
      "Collections: 227|1534\n",
      "Collections: 228|1534\n",
      "Collections: 229|1534\n",
      "Collections: 230|1534\n",
      "Collections: 231|1534\n",
      "Collections: 232|1534\n",
      "Collections: 233|1534\n",
      "Collections: 234|1534\n",
      "Collections: 235|1534\n",
      "Collections: 236|1534\n",
      "Collections: 237|1534\n",
      "Collections: 238|1534\n",
      "Collections: 239|1534\n",
      "Collections: 240|1534\n",
      "Collections: 241|1534\n",
      "Collections: 242|1534\n",
      "Collections: 243|1534\n",
      "Collections: 244|1534\n",
      "Collections: 245|1534\n",
      "Collections: 246|1534\n",
      "Collections: 247|1534\n",
      "Collections: 248|1534\n",
      "Collections: 249|1534\n",
      "Collections: 250|1534\n",
      "Collections: 251|1534\n",
      "Collections: 252|1534\n",
      "Collections: 253|1534\n",
      "Collections: 254|1534\n",
      "Collections: 255|1534\n",
      "Collections: 256|1534\n",
      "Collections: 257|1534\n",
      "Collections: 258|1534\n",
      "Collections: 259|1534\n",
      "Collections: 260|1534\n",
      "Collections: 261|1534\n",
      "Collections: 262|1534\n",
      "Collections: 263|1534\n",
      "Collections: 264|1534\n",
      "Collections: 265|1534\n",
      "Collections: 266|1534\n",
      "Collections: 267|1534\n",
      "Collections: 268|1534\n",
      "Collections: 269|1534\n",
      "Collections: 270|1534\n",
      "Collections: 271|1534\n",
      "Collections: 272|1534\n",
      "Collections: 273|1534\n",
      "Collections: 274|1534\n",
      "Collections: 275|1534\n",
      "Collections: 276|1534\n",
      "Collections: 277|1534\n",
      "Collections: 278|1534\n",
      "Collections: 279|1534\n",
      "Collections: 280|1534\n",
      "Collections: 281|1534\n",
      "Collections: 282|1534\n",
      "Collections: 283|1534\n",
      "Collections: 284|1534\n",
      "Collections: 285|1534\n",
      "Collections: 286|1534\n",
      "Collections: 287|1534\n",
      "Collections: 288|1534\n",
      "Collections: 289|1534\n",
      "Collections: 290|1534\n",
      "Collections: 291|1534\n",
      "Collections: 292|1534\n",
      "Collections: 293|1534\n",
      "Collections: 294|1534\n",
      "Collections: 295|1534\n",
      "Collections: 296|1534\n",
      "Collections: 297|1534\n",
      "Collections: 298|1534\n",
      "Collections: 299|1534\n",
      "Collections: 300|1534\n",
      "Collections: 301|1534\n",
      "Collections: 302|1534\n",
      "Collections: 303|1534\n",
      "Collections: 304|1534\n",
      "Collections: 305|1534\n",
      "Collections: 306|1534\n",
      "Collections: 307|1534\n",
      "Collections: 308|1534\n",
      "Collections: 309|1534\n",
      "Collections: 310|1534\n",
      "Collections: 311|1534\n",
      "Collections: 312|1534\n",
      "Collections: 313|1534\n",
      "Collections: 314|1534\n",
      "Collections: 315|1534\n",
      "Collections: 316|1534\n",
      "Collections: 317|1534\n",
      "Collections: 318|1534\n",
      "Collections: 319|1534\n",
      "Collections: 320|1534\n",
      "Collections: 321|1534\n",
      "Collections: 322|1534\n",
      "Collections: 323|1534\n",
      "Collections: 324|1534\n",
      "Collections: 325|1534\n",
      "Collections: 326|1534\n",
      "Collections: 327|1534\n",
      "Collections: 328|1534\n",
      "Collections: 329|1534\n",
      "Collections: 330|1534\n",
      "Collections: 331|1534\n",
      "Collections: 332|1534\n",
      "Collections: 333|1534\n",
      "Collections: 334|1534\n",
      "Collections: 335|1534\n",
      "Collections: 336|1534\n",
      "Collections: 337|1534\n",
      "Collections: 338|1534\n",
      "Collections: 339|1534\n",
      "Collections: 340|1534\n",
      "Collections: 341|1534\n",
      "Collections: 342|1534\n",
      "Collections: 343|1534\n",
      "Collections: 344|1534\n",
      "Collections: 345|1534\n",
      "Collections: 346|1534\n",
      "Collections: 347|1534\n",
      "Collections: 348|1534\n",
      "Collections: 349|1534\n",
      "Collections: 350|1534\n",
      "Collections: 351|1534\n",
      "Collections: 352|1534\n",
      "Collections: 353|1534\n",
      "Collections: 354|1534\n",
      "Collections: 355|1534\n",
      "Collections: 356|1534\n",
      "Collections: 357|1534\n",
      "Collections: 358|1534\n",
      "Collections: 359|1534\n",
      "Collections: 360|1534\n",
      "Collections: 361|1534\n",
      "Collections: 362|1534\n",
      "Collections: 363|1534\n",
      "Collections: 364|1534\n",
      "Collections: 365|1534\n",
      "Collections: 366|1534\n",
      "Collections: 367|1534\n",
      "Collections: 368|1534\n",
      "Collections: 369|1534\n",
      "Collections: 370|1534\n",
      "Collections: 371|1534\n",
      "Collections: 372|1534\n",
      "Collections: 373|1534\n",
      "Collections: 374|1534\n",
      "Collections: 375|1534\n",
      "Collections: 376|1534\n",
      "Collections: 377|1534\n",
      "Collections: 378|1534\n",
      "Collections: 379|1534\n",
      "Collections: 380|1534\n",
      "Collections: 381|1534\n",
      "Collections: 382|1534\n",
      "Collections: 383|1534\n",
      "Collections: 384|1534\n",
      "Collections: 385|1534\n",
      "Collections: 386|1534\n",
      "Collections: 387|1534\n",
      "Collections: 388|1534\n",
      "Collections: 389|1534\n",
      "Collections: 390|1534\n",
      "Collections: 391|1534\n",
      "Collections: 392|1534\n",
      "Collections: 393|1534\n",
      "Collections: 394|1534\n",
      "Collections: 395|1534\n",
      "Collections: 396|1534\n",
      "Collections: 397|1534\n",
      "Collections: 398|1534\n",
      "Collections: 399|1534\n",
      "Collections: 400|1534\n",
      "Collections: 401|1534\n",
      "Collections: 402|1534\n",
      "Collections: 403|1534\n",
      "Collections: 404|1534\n",
      "Collections: 405|1534\n",
      "Collections: 406|1534\n",
      "Collections: 407|1534\n",
      "Collections: 408|1534\n",
      "Collections: 409|1534\n",
      "Collections: 410|1534\n",
      "Collections: 411|1534\n",
      "Collections: 412|1534\n",
      "Collections: 413|1534\n",
      "Collections: 414|1534\n",
      "Collections: 415|1534\n",
      "Collections: 416|1534\n",
      "Collections: 417|1534\n",
      "Collections: 418|1534\n",
      "Collections: 419|1534\n",
      "Collections: 420|1534\n",
      "Collections: 421|1534\n",
      "Collections: 422|1534\n",
      "Collections: 423|1534\n",
      "Collections: 424|1534\n",
      "Collections: 425|1534\n",
      "Collections: 426|1534\n",
      "Collections: 427|1534\n",
      "Collections: 428|1534\n",
      "Collections: 429|1534\n",
      "Collections: 430|1534\n",
      "Collections: 431|1534\n",
      "Collections: 432|1534\n",
      "Collections: 433|1534\n",
      "Collections: 434|1534\n",
      "Collections: 435|1534\n",
      "Collections: 436|1534\n",
      "Collections: 437|1534\n",
      "Collections: 438|1534\n",
      "[E088] Text of length 1409376 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
      "Collections: 439|1534\n",
      "Collections: 440|1534\n",
      "Collections: 441|1534\n",
      "Collections: 442|1534\n",
      "Collections: 443|1534\n",
      "Collections: 444|1534\n",
      "Collections: 445|1534\n",
      "Collections: 446|1534\n",
      "Collections: 447|1534\n",
      "Collections: 448|1534\n",
      "Collections: 449|1534\n",
      "Collections: 450|1534\n",
      "Collections: 451|1534\n",
      "Collections: 452|1534\n",
      "Collections: 453|1534\n",
      "Collections: 454|1534\n",
      "Collections: 455|1534\n",
      "Collections: 456|1534\n",
      "Collections: 457|1534\n",
      "Collections: 458|1534\n",
      "Collections: 459|1534\n",
      "Collections: 460|1534\n",
      "Collections: 461|1534\n",
      "Collections: 462|1534\n",
      "Collections: 463|1534\n",
      "Collections: 464|1534\n",
      "Collections: 465|1534\n",
      "Collections: 466|1534\n",
      "Collections: 467|1534\n",
      "Collections: 468|1534\n",
      "Collections: 469|1534\n",
      "Collections: 470|1534\n",
      "Collections: 471|1534\n",
      "Collections: 472|1534\n",
      "Collections: 473|1534\n",
      "Collections: 474|1534\n",
      "Collections: 475|1534\n",
      "Collections: 476|1534\n",
      "Collections: 477|1534\n",
      "Collections: 478|1534\n",
      "Collections: 479|1534\n",
      "Collections: 480|1534\n",
      "Collections: 481|1534\n",
      "Collections: 482|1534\n",
      "Collections: 483|1534\n",
      "Collections: 484|1534\n",
      "Collections: 485|1534\n",
      "Collections: 486|1534\n",
      "Collections: 487|1534\n",
      "Collections: 488|1534\n",
      "Collections: 489|1534\n",
      "Collections: 490|1534\n",
      "Collections: 491|1534\n",
      "[E088] Text of length 1337143 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
      "Collections: 492|1534\n",
      "Collections: 493|1534\n",
      "Collections: 494|1534\n",
      "Collections: 495|1534\n",
      "Collections: 496|1534\n",
      "Collections: 497|1534\n",
      "Collections: 498|1534\n",
      "Collections: 499|1534\n",
      "Collections: 500|1534\n",
      "Collections: 501|1534\n",
      "Collections: 502|1534\n",
      "Collections: 503|1534\n",
      "Collections: 504|1534\n",
      "Collections: 505|1534\n",
      "Collections: 506|1534\n",
      "Collections: 507|1534\n",
      "Collections: 508|1534\n",
      "Collections: 509|1534\n",
      "Collections: 510|1534\n",
      "Collections: 511|1534\n",
      "Collections: 512|1534\n",
      "Collections: 513|1534\n",
      "Collections: 514|1534\n",
      "Collections: 515|1534\n",
      "Collections: 516|1534\n",
      "Collections: 517|1534\n",
      "Collections: 518|1534\n",
      "Collections: 519|1534\n",
      "Collections: 520|1534\n",
      "Collections: 521|1534\n",
      "Collections: 522|1534\n",
      "Collections: 523|1534\n",
      "Collections: 524|1534\n",
      "Collections: 525|1534\n",
      "Collections: 526|1534\n",
      "Collections: 527|1534\n",
      "Collections: 528|1534\n",
      "Collections: 529|1534\n",
      "Collections: 530|1534\n",
      "Collections: 531|1534\n",
      "Collections: 532|1534\n",
      "Collections: 533|1534\n",
      "Collections: 534|1534\n",
      "Collections: 535|1534\n",
      "Collections: 536|1534\n",
      "Collections: 537|1534\n",
      "Collections: 538|1534\n",
      "Collections: 539|1534\n",
      "Collections: 540|1534\n",
      "Collections: 541|1534\n",
      "Collections: 542|1534\n",
      "Collections: 543|1534\n",
      "Collections: 544|1534\n",
      "Collections: 545|1534\n",
      "Collections: 546|1534\n",
      "Collections: 547|1534\n",
      "Collections: 548|1534\n",
      "Collections: 549|1534\n",
      "Collections: 550|1534\n",
      "Collections: 551|1534\n",
      "Collections: 552|1534\n",
      "Collections: 553|1534\n",
      "Collections: 554|1534\n",
      "Collections: 555|1534\n",
      "Collections: 556|1534\n",
      "Collections: 557|1534\n",
      "Collections: 558|1534\n",
      "Collections: 559|1534\n",
      "Collections: 560|1534\n",
      "Collections: 561|1534\n",
      "Collections: 562|1534\n",
      "Collections: 563|1534\n",
      "Collections: 564|1534\n",
      "Collections: 565|1534\n",
      "Collections: 566|1534\n",
      "Collections: 567|1534\n",
      "Collections: 568|1534\n",
      "Collections: 569|1534\n",
      "Collections: 570|1534\n",
      "Collections: 571|1534\n",
      "Collections: 572|1534\n",
      "Collections: 573|1534\n",
      "Collections: 574|1534\n",
      "Collections: 575|1534\n",
      "Collections: 576|1534\n",
      "Collections: 577|1534\n",
      "Collections: 578|1534\n",
      "Collections: 579|1534\n",
      "Collections: 580|1534\n",
      "Collections: 581|1534\n",
      "Collections: 582|1534\n",
      "Collections: 583|1534\n",
      "Collections: 584|1534\n",
      "Collections: 585|1534\n",
      "Collections: 586|1534\n",
      "Collections: 587|1534\n",
      "Collections: 588|1534\n",
      "Collections: 589|1534\n",
      "Collections: 590|1534\n",
      "Collections: 591|1534\n",
      "Collections: 592|1534\n",
      "Collections: 593|1534\n",
      "Collections: 594|1534\n",
      "Collections: 595|1534\n",
      "Collections: 596|1534\n",
      "Collections: 597|1534\n",
      "Collections: 598|1534\n",
      "Collections: 599|1534\n",
      "Collections: 600|1534\n",
      "Collections: 601|1534\n",
      "Collections: 602|1534\n",
      "Collections: 603|1534\n",
      "Collections: 604|1534\n",
      "Collections: 605|1534\n",
      "Collections: 606|1534\n",
      "Collections: 607|1534\n",
      "Collections: 608|1534\n",
      "Collections: 609|1534\n",
      "Collections: 610|1534\n",
      "[E088] Text of length 1337141 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
      "Collections: 611|1534\n",
      "Collections: 612|1534\n",
      "Collections: 613|1534\n",
      "Collections: 614|1534\n",
      "Collections: 615|1534\n",
      "Collections: 616|1534\n",
      "Collections: 617|1534\n",
      "Collections: 618|1534\n",
      "Collections: 619|1534\n",
      "Collections: 620|1534\n",
      "Collections: 621|1534\n",
      "Collections: 622|1534\n",
      "Collections: 623|1534\n",
      "Collections: 624|1534\n",
      "Collections: 625|1534\n",
      "Collections: 626|1534\n",
      "Collections: 627|1534\n",
      "Collections: 628|1534\n",
      "Collections: 629|1534\n",
      "Collections: 630|1534\n",
      "Collections: 631|1534\n",
      "Collections: 632|1534\n",
      "Collections: 633|1534\n",
      "Collections: 634|1534\n",
      "Collections: 635|1534\n",
      "Collections: 636|1534\n",
      "Collections: 637|1534\n",
      "Collections: 638|1534\n",
      "Collections: 639|1534\n",
      "Collections: 640|1534\n",
      "Collections: 641|1534\n",
      "Collections: 642|1534\n",
      "Collections: 643|1534\n",
      "Collections: 644|1534\n",
      "Collections: 645|1534\n",
      "Collections: 646|1534\n",
      "Collections: 647|1534\n",
      "Collections: 648|1534\n",
      "Collections: 649|1534\n",
      "Collections: 650|1534\n",
      "Collections: 651|1534\n",
      "Collections: 652|1534\n",
      "Collections: 653|1534\n",
      "Collections: 654|1534\n",
      "Collections: 655|1534\n",
      "Collections: 656|1534\n",
      "Collections: 657|1534\n",
      "Collections: 658|1534\n",
      "Collections: 659|1534\n",
      "Collections: 660|1534\n",
      "Collections: 661|1534\n",
      "Collections: 662|1534\n",
      "Collections: 663|1534\n",
      "Collections: 664|1534\n",
      "Collections: 665|1534\n",
      "Collections: 666|1534\n",
      "Collections: 667|1534\n",
      "Collections: 668|1534\n",
      "Collections: 669|1534\n",
      "Collections: 670|1534\n",
      "Collections: 671|1534\n",
      "Collections: 672|1534\n",
      "Collections: 673|1534\n",
      "Collections: 674|1534\n",
      "Collections: 675|1534\n",
      "Collections: 676|1534\n",
      "Collections: 677|1534\n",
      "Collections: 678|1534\n",
      "Collections: 679|1534\n",
      "Collections: 680|1534\n",
      "Collections: 681|1534\n",
      "Collections: 682|1534\n",
      "Collections: 683|1534\n",
      "Collections: 684|1534\n",
      "Collections: 685|1534\n",
      "Collections: 686|1534\n",
      "Collections: 687|1534\n",
      "Collections: 688|1534\n",
      "Collections: 689|1534\n",
      "Collections: 690|1534\n",
      "Collections: 691|1534\n",
      "Collections: 692|1534\n",
      "Collections: 693|1534\n",
      "Collections: 694|1534\n",
      "Collections: 695|1534\n",
      "Collections: 696|1534\n",
      "Collections: 697|1534\n",
      "Collections: 698|1534\n",
      "Collections: 699|1534\n",
      "Collections: 700|1534\n",
      "Collections: 701|1534\n",
      "Collections: 702|1534\n",
      "Collections: 703|1534\n",
      "Collections: 704|1534\n",
      "Collections: 705|1534\n",
      "Collections: 706|1534\n",
      "Collections: 707|1534\n",
      "Collections: 708|1534\n",
      "Collections: 709|1534\n",
      "Collections: 710|1534\n",
      "Collections: 711|1534\n",
      "Collections: 712|1534\n",
      "Collections: 713|1534\n",
      "Collections: 714|1534\n",
      "Collections: 715|1534\n",
      "Collections: 716|1534\n",
      "Collections: 717|1534\n",
      "Collections: 718|1534\n",
      "Collections: 719|1534\n",
      "Collections: 720|1534\n",
      "Collections: 721|1534\n",
      "Collections: 722|1534\n",
      "Collections: 723|1534\n",
      "Collections: 724|1534\n",
      "Collections: 725|1534\n",
      "Collections: 726|1534\n",
      "Collections: 727|1534\n",
      "Collections: 728|1534\n",
      "Collections: 729|1534\n",
      "Collections: 730|1534\n",
      "Collections: 731|1534\n",
      "Collections: 732|1534\n",
      "Collections: 733|1534\n",
      "Collections: 734|1534\n",
      "Collections: 735|1534\n",
      "Collections: 736|1534\n",
      "Collections: 737|1534\n",
      "Collections: 738|1534\n",
      "Collections: 739|1534\n",
      "Collections: 740|1534\n",
      "Collections: 741|1534\n",
      "Collections: 742|1534\n",
      "Collections: 743|1534\n",
      "Collections: 744|1534\n",
      "Collections: 745|1534\n",
      "Collections: 746|1534\n",
      "Collections: 747|1534\n",
      "Collections: 748|1534\n",
      "Collections: 749|1534\n",
      "Collections: 750|1534\n",
      "Collections: 751|1534\n",
      "Collections: 752|1534\n",
      "Collections: 753|1534\n",
      "Collections: 754|1534\n",
      "Collections: 755|1534\n",
      "Collections: 756|1534\n",
      "Collections: 757|1534\n",
      "Collections: 758|1534\n",
      "Collections: 759|1534\n",
      "Collections: 760|1534\n",
      "Collections: 761|1534\n",
      "Collections: 762|1534\n",
      "Collections: 763|1534\n",
      "Collections: 764|1534\n",
      "Collections: 765|1534\n",
      "Collections: 766|1534\n",
      "Collections: 767|1534\n",
      "Collections: 768|1534\n",
      "Collections: 769|1534\n",
      "Collections: 770|1534\n",
      "Collections: 771|1534\n",
      "Collections: 772|1534\n",
      "Collections: 773|1534\n",
      "Collections: 774|1534\n",
      "Collections: 775|1534\n",
      "Collections: 776|1534\n",
      "Collections: 777|1534\n",
      "Collections: 778|1534\n",
      "Collections: 779|1534\n",
      "Collections: 780|1534\n",
      "Collections: 781|1534\n",
      "Collections: 782|1534\n",
      "Collections: 783|1534\n",
      "Collections: 784|1534\n",
      "Collections: 785|1534\n",
      "Collections: 786|1534\n",
      "Collections: 787|1534\n",
      "Collections: 788|1534\n",
      "Collections: 789|1534\n",
      "Collections: 790|1534\n",
      "Collections: 791|1534\n",
      "Collections: 792|1534\n",
      "Collections: 793|1534\n",
      "Collections: 794|1534\n",
      "Collections: 795|1534\n",
      "Collections: 796|1534\n",
      "Collections: 797|1534\n",
      "Collections: 798|1534\n",
      "Collections: 799|1534\n",
      "Collections: 800|1534\n",
      "Collections: 801|1534\n",
      "Collections: 802|1534\n",
      "Collections: 803|1534\n",
      "Collections: 804|1534\n",
      "Collections: 805|1534\n",
      "Collections: 806|1534\n",
      "Collections: 807|1534\n",
      "Collections: 808|1534\n",
      "Collections: 809|1534\n",
      "Collections: 810|1534\n",
      "Collections: 811|1534\n",
      "Collections: 812|1534\n",
      "Collections: 813|1534\n",
      "Collections: 814|1534\n",
      "Collections: 815|1534\n",
      "Collections: 816|1534\n",
      "Collections: 817|1534\n",
      "Collections: 818|1534\n",
      "Collections: 819|1534\n",
      "Collections: 820|1534\n",
      "Collections: 821|1534\n",
      "Collections: 822|1534\n",
      "Collections: 823|1534\n",
      "Collections: 824|1534\n",
      "Collections: 825|1534\n",
      "Collections: 826|1534\n",
      "Collections: 827|1534\n",
      "Collections: 828|1534\n",
      "Collections: 829|1534\n",
      "Collections: 830|1534\n",
      "Collections: 831|1534\n",
      "Collections: 832|1534\n",
      "Collections: 833|1534\n",
      "Collections: 834|1534\n",
      "Collections: 835|1534\n",
      "Collections: 836|1534\n",
      "Collections: 837|1534\n",
      "Collections: 838|1534\n",
      "Collections: 839|1534\n",
      "Collections: 840|1534\n",
      "Collections: 841|1534\n",
      "Collections: 842|1534\n",
      "Collections: 843|1534\n",
      "Collections: 844|1534\n",
      "Collections: 845|1534\n",
      "Collections: 846|1534\n",
      "Collections: 847|1534\n",
      "Collections: 848|1534\n",
      "Collections: 849|1534\n",
      "Collections: 850|1534\n",
      "Collections: 851|1534\n",
      "Collections: 852|1534\n",
      "Collections: 853|1534\n",
      "Collections: 854|1534\n",
      "Collections: 855|1534\n",
      "Collections: 856|1534\n",
      "Collections: 857|1534\n",
      "Collections: 858|1534\n",
      "Collections: 859|1534\n",
      "Collections: 860|1534\n",
      "Collections: 861|1534\n",
      "Collections: 862|1534\n",
      "Collections: 863|1534\n",
      "Collections: 864|1534\n",
      "Collections: 865|1534\n",
      "Collections: 866|1534\n",
      "Collections: 867|1534\n",
      "Collections: 868|1534\n",
      "Collections: 869|1534\n",
      "Collections: 870|1534\n",
      "Collections: 871|1534\n",
      "Collections: 872|1534\n",
      "Collections: 873|1534\n",
      "Collections: 874|1534\n",
      "Collections: 875|1534\n",
      "Collections: 876|1534\n",
      "Collections: 877|1534\n",
      "Collections: 878|1534\n",
      "Collections: 879|1534\n",
      "Collections: 880|1534\n",
      "Collections: 881|1534\n",
      "Collections: 882|1534\n",
      "Collections: 883|1534\n",
      "Collections: 884|1534\n",
      "Collections: 885|1534\n",
      "Collections: 886|1534\n",
      "Collections: 887|1534\n",
      "Collections: 888|1534\n",
      "Collections: 889|1534\n",
      "Collections: 890|1534\n",
      "Collections: 891|1534\n",
      "Collections: 892|1534\n",
      "Collections: 893|1534\n",
      "Collections: 894|1534\n",
      "Collections: 895|1534\n",
      "Collections: 896|1534\n",
      "Collections: 897|1534\n",
      "Collections: 898|1534\n",
      "Collections: 899|1534\n",
      "Collections: 900|1534\n",
      "Collections: 901|1534\n",
      "Collections: 902|1534\n",
      "Collections: 903|1534\n",
      "Collections: 904|1534\n",
      "Collections: 905|1534\n",
      "Collections: 906|1534\n",
      "Collections: 907|1534\n",
      "Collections: 908|1534\n",
      "Collections: 909|1534\n",
      "Collections: 910|1534\n",
      "Collections: 911|1534\n",
      "Collections: 912|1534\n",
      "Collections: 913|1534\n",
      "Collections: 914|1534\n",
      "Collections: 915|1534\n",
      "Collections: 916|1534\n",
      "Collections: 917|1534\n",
      "Collections: 918|1534\n",
      "Collections: 919|1534\n",
      "Collections: 920|1534\n",
      "Collections: 921|1534\n",
      "Collections: 922|1534\n",
      "Collections: 923|1534\n",
      "Collections: 924|1534\n",
      "Collections: 925|1534\n",
      "Collections: 926|1534\n",
      "Collections: 927|1534\n",
      "Collections: 928|1534\n",
      "Collections: 929|1534\n",
      "Collections: 930|1534\n",
      "Collections: 931|1534\n",
      "Collections: 932|1534\n",
      "Collections: 933|1534\n",
      "Collections: 934|1534\n",
      "Collections: 935|1534\n",
      "Collections: 936|1534\n",
      "Collections: 937|1534\n",
      "Collections: 938|1534\n",
      "Collections: 939|1534\n",
      "Collections: 940|1534\n",
      "Collections: 941|1534\n",
      "Collections: 942|1534\n",
      "Collections: 943|1534\n",
      "Collections: 944|1534\n",
      "Collections: 945|1534\n",
      "Collections: 946|1534\n",
      "Collections: 947|1534\n",
      "Collections: 948|1534\n",
      "Collections: 949|1534\n",
      "Collections: 950|1534\n",
      "Collections: 951|1534\n",
      "Collections: 952|1534\n",
      "Collections: 953|1534\n",
      "Collections: 954|1534\n",
      "Collections: 955|1534\n",
      "Collections: 956|1534\n",
      "Collections: 957|1534\n",
      "Collections: 958|1534\n",
      "Collections: 959|1534\n",
      "Collections: 960|1534\n",
      "Collections: 961|1534\n",
      "Collections: 962|1534\n",
      "Collections: 963|1534\n",
      "Collections: 964|1534\n",
      "Collections: 965|1534\n",
      "Collections: 966|1534\n",
      "Collections: 967|1534\n",
      "Collections: 968|1534\n",
      "Collections: 969|1534\n",
      "Collections: 970|1534\n",
      "Collections: 971|1534\n",
      "Collections: 972|1534\n",
      "Collections: 973|1534\n",
      "Collections: 974|1534\n",
      "Collections: 975|1534\n",
      "Collections: 976|1534\n",
      "Collections: 977|1534\n",
      "Collections: 978|1534\n",
      "Collections: 979|1534\n",
      "Collections: 980|1534\n",
      "Collections: 981|1534\n",
      "Collections: 982|1534\n",
      "Collections: 983|1534\n",
      "Collections: 984|1534\n",
      "Collections: 985|1534\n",
      "Collections: 986|1534\n",
      "Collections: 987|1534\n",
      "Collections: 988|1534\n",
      "Collections: 989|1534\n",
      "Collections: 990|1534\n",
      "Collections: 991|1534\n",
      "Collections: 992|1534\n",
      "Collections: 993|1534\n",
      "Collections: 994|1534\n",
      "Collections: 995|1534\n",
      "Collections: 996|1534\n",
      "Collections: 997|1534\n",
      "Collections: 998|1534\n",
      "Collections: 999|1534\n",
      "Collections: 1000|1534\n",
      "Collections: 1001|1534\n",
      "Collections: 1002|1534\n",
      "Collections: 1003|1534\n",
      "Collections: 1004|1534\n",
      "Collections: 1005|1534\n",
      "Collections: 1006|1534\n",
      "Collections: 1007|1534\n",
      "Collections: 1008|1534\n",
      "Collections: 1009|1534\n",
      "Collections: 1010|1534\n",
      "Collections: 1011|1534\n",
      "Collections: 1012|1534\n",
      "Collections: 1013|1534\n",
      "Collections: 1014|1534\n",
      "Collections: 1015|1534\n",
      "Collections: 1016|1534\n",
      "Collections: 1017|1534\n",
      "Collections: 1018|1534\n",
      "Collections: 1019|1534\n",
      "Collections: 1020|1534\n",
      "Collections: 1021|1534\n",
      "Collections: 1022|1534\n",
      "Collections: 1023|1534\n",
      "Collections: 1024|1534\n",
      "Collections: 1025|1534\n",
      "Collections: 1026|1534\n",
      "Collections: 1027|1534\n",
      "Collections: 1028|1534\n",
      "Collections: 1029|1534\n",
      "Collections: 1030|1534\n",
      "Collections: 1031|1534\n",
      "Collections: 1032|1534\n",
      "Collections: 1033|1534\n",
      "Collections: 1034|1534\n",
      "Collections: 1035|1534\n",
      "Collections: 1036|1534\n",
      "Collections: 1037|1534\n",
      "Collections: 1038|1534\n",
      "Collections: 1039|1534\n",
      "Collections: 1040|1534\n",
      "Collections: 1041|1534\n",
      "Collections: 1042|1534\n",
      "Collections: 1043|1534\n",
      "Collections: 1044|1534\n",
      "Collections: 1045|1534\n",
      "Collections: 1046|1534\n",
      "Collections: 1047|1534\n",
      "Collections: 1048|1534\n",
      "Collections: 1049|1534\n",
      "Collections: 1050|1534\n",
      "Collections: 1051|1534\n",
      "Collections: 1052|1534\n",
      "Collections: 1053|1534\n",
      "Collections: 1054|1534\n",
      "Collections: 1055|1534\n",
      "Collections: 1056|1534\n",
      "Collections: 1057|1534\n",
      "Collections: 1058|1534\n",
      "Collections: 1059|1534\n",
      "Collections: 1060|1534\n",
      "Collections: 1061|1534\n",
      "Collections: 1062|1534\n",
      "Collections: 1063|1534\n",
      "Collections: 1064|1534\n",
      "Collections: 1065|1534\n",
      "Collections: 1066|1534\n",
      "Collections: 1067|1534\n",
      "Collections: 1068|1534\n",
      "Collections: 1069|1534\n",
      "Collections: 1070|1534\n",
      "Collections: 1071|1534\n",
      "Collections: 1072|1534\n",
      "Collections: 1073|1534\n",
      "Collections: 1074|1534\n",
      "Collections: 1075|1534\n",
      "Collections: 1076|1534\n",
      "Collections: 1077|1534\n",
      "Collections: 1078|1534\n",
      "Collections: 1079|1534\n",
      "Collections: 1080|1534\n",
      "Collections: 1081|1534\n",
      "Collections: 1082|1534\n",
      "Collections: 1083|1534\n",
      "Collections: 1084|1534\n",
      "Collections: 1085|1534\n",
      "Collections: 1086|1534\n",
      "Collections: 1087|1534\n",
      "Collections: 1088|1534\n",
      "Collections: 1089|1534\n",
      "Collections: 1090|1534\n",
      "Collections: 1091|1534\n",
      "Collections: 1092|1534\n",
      "Collections: 1093|1534\n",
      "Collections: 1094|1534\n",
      "Collections: 1095|1534\n",
      "Collections: 1096|1534\n",
      "Collections: 1097|1534\n",
      "Collections: 1098|1534\n",
      "Collections: 1099|1534\n",
      "Collections: 1100|1534\n",
      "Collections: 1101|1534\n",
      "Collections: 1102|1534\n",
      "Collections: 1103|1534\n",
      "Collections: 1104|1534\n",
      "Collections: 1105|1534\n",
      "Collections: 1106|1534\n",
      "Collections: 1107|1534\n",
      "Collections: 1108|1534\n",
      "Collections: 1109|1534\n",
      "Collections: 1110|1534\n",
      "Collections: 1111|1534\n",
      "Collections: 1112|1534\n",
      "Collections: 1113|1534\n",
      "Collections: 1114|1534\n",
      "Collections: 1115|1534\n",
      "Collections: 1116|1534\n",
      "Collections: 1117|1534\n",
      "Collections: 1118|1534\n",
      "Collections: 1119|1534\n",
      "Collections: 1120|1534\n",
      "Collections: 1121|1534\n",
      "Collections: 1122|1534\n",
      "Collections: 1123|1534\n",
      "Collections: 1124|1534\n",
      "Collections: 1125|1534\n",
      "Collections: 1126|1534\n",
      "Collections: 1127|1534\n",
      "Collections: 1128|1534\n",
      "Collections: 1129|1534\n",
      "Collections: 1130|1534\n",
      "Collections: 1131|1534\n",
      "Collections: 1132|1534\n",
      "Collections: 1133|1534\n",
      "Collections: 1134|1534\n",
      "Collections: 1135|1534\n",
      "Collections: 1136|1534\n",
      "Collections: 1137|1534\n",
      "Collections: 1138|1534\n",
      "Collections: 1139|1534\n",
      "Collections: 1140|1534\n",
      "Collections: 1141|1534\n",
      "Collections: 1142|1534\n",
      "Collections: 1143|1534\n",
      "Collections: 1144|1534\n",
      "Collections: 1145|1534\n",
      "Collections: 1146|1534\n",
      "Collections: 1147|1534\n",
      "Collections: 1148|1534\n",
      "Collections: 1149|1534\n",
      "Collections: 1150|1534\n",
      "Collections: 1151|1534\n",
      "Collections: 1152|1534\n",
      "Collections: 1153|1534\n",
      "Collections: 1154|1534\n",
      "Collections: 1155|1534\n",
      "Collections: 1156|1534\n",
      "Collections: 1157|1534\n",
      "Collections: 1158|1534\n",
      "Collections: 1159|1534\n",
      "Collections: 1160|1534\n",
      "Collections: 1161|1534\n",
      "Collections: 1162|1534\n",
      "Collections: 1163|1534\n",
      "Collections: 1164|1534\n",
      "Collections: 1165|1534\n",
      "Collections: 1166|1534\n",
      "Collections: 1167|1534\n",
      "Collections: 1168|1534\n",
      "Collections: 1169|1534\n",
      "Collections: 1170|1534\n",
      "Collections: 1171|1534\n",
      "Collections: 1172|1534\n",
      "Collections: 1173|1534\n",
      "Collections: 1174|1534\n",
      "Collections: 1175|1534\n",
      "Collections: 1176|1534\n",
      "Collections: 1177|1534\n",
      "Collections: 1178|1534\n",
      "Collections: 1179|1534\n",
      "Collections: 1180|1534\n",
      "Collections: 1181|1534\n",
      "Collections: 1182|1534\n",
      "Collections: 1183|1534\n",
      "Collections: 1184|1534\n",
      "Collections: 1185|1534\n",
      "Collections: 1186|1534\n",
      "Collections: 1187|1534\n",
      "Collections: 1188|1534\n",
      "Collections: 1189|1534\n",
      "Collections: 1190|1534\n",
      "Collections: 1191|1534\n",
      "Collections: 1192|1534\n",
      "Collections: 1193|1534\n",
      "Collections: 1194|1534\n",
      "Collections: 1195|1534\n",
      "Collections: 1196|1534\n",
      "Collections: 1197|1534\n",
      "Collections: 1198|1534\n",
      "Collections: 1199|1534\n",
      "Collections: 1200|1534\n",
      "Collections: 1201|1534\n",
      "[E088] Text of length 1409376 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
      "Collections: 1202|1534\n",
      "Collections: 1203|1534\n",
      "Collections: 1204|1534\n",
      "Collections: 1205|1534\n",
      "Collections: 1206|1534\n",
      "Collections: 1207|1534\n",
      "Collections: 1208|1534\n",
      "Collections: 1209|1534\n",
      "Collections: 1210|1534\n",
      "Collections: 1211|1534\n",
      "Collections: 1212|1534\n",
      "Collections: 1213|1534\n",
      "Collections: 1214|1534\n",
      "Collections: 1215|1534\n",
      "Collections: 1216|1534\n",
      "Collections: 1217|1534\n",
      "Collections: 1218|1534\n",
      "Collections: 1219|1534\n",
      "Collections: 1220|1534\n",
      "Collections: 1221|1534\n",
      "Collections: 1222|1534\n",
      "Collections: 1223|1534\n",
      "Collections: 1224|1534\n",
      "Collections: 1225|1534\n",
      "Collections: 1226|1534\n",
      "Collections: 1227|1534\n",
      "Collections: 1228|1534\n",
      "Collections: 1229|1534\n",
      "Collections: 1230|1534\n",
      "Collections: 1231|1534\n",
      "Collections: 1232|1534\n",
      "Collections: 1233|1534\n",
      "Collections: 1234|1534\n",
      "Collections: 1235|1534\n",
      "Collections: 1236|1534\n",
      "Collections: 1237|1534\n",
      "Collections: 1238|1534\n",
      "Collections: 1239|1534\n",
      "Collections: 1240|1534\n",
      "Collections: 1241|1534\n",
      "Collections: 1242|1534\n",
      "Collections: 1243|1534\n",
      "Collections: 1244|1534\n",
      "Collections: 1245|1534\n",
      "Collections: 1246|1534\n",
      "Collections: 1247|1534\n",
      "Collections: 1248|1534\n",
      "Collections: 1249|1534\n",
      "Collections: 1250|1534\n",
      "Collections: 1251|1534\n",
      "Collections: 1252|1534\n",
      "Collections: 1253|1534\n",
      "Collections: 1254|1534\n",
      "Collections: 1255|1534\n",
      "Collections: 1256|1534\n",
      "Collections: 1257|1534\n",
      "Collections: 1258|1534\n",
      "Collections: 1259|1534\n",
      "Collections: 1260|1534\n",
      "Collections: 1261|1534\n",
      "Collections: 1262|1534\n",
      "Collections: 1263|1534\n",
      "Collections: 1264|1534\n",
      "Collections: 1265|1534\n",
      "Collections: 1266|1534\n",
      "Collections: 1267|1534\n",
      "Collections: 1268|1534\n",
      "Collections: 1269|1534\n",
      "Collections: 1270|1534\n",
      "Collections: 1271|1534\n",
      "Collections: 1272|1534\n",
      "Collections: 1273|1534\n",
      "Collections: 1274|1534\n",
      "Collections: 1275|1534\n",
      "Collections: 1276|1534\n",
      "Collections: 1277|1534\n",
      "Collections: 1278|1534\n",
      "Collections: 1279|1534\n",
      "Collections: 1280|1534\n",
      "Collections: 1281|1534\n",
      "Collections: 1282|1534\n",
      "Collections: 1283|1534\n",
      "Collections: 1284|1534\n",
      "Collections: 1285|1534\n",
      "Collections: 1286|1534\n",
      "Collections: 1287|1534\n",
      "Collections: 1288|1534\n",
      "Collections: 1289|1534\n",
      "Collections: 1290|1534\n",
      "Collections: 1291|1534\n",
      "Collections: 1292|1534\n",
      "Collections: 1293|1534\n",
      "Collections: 1294|1534\n",
      "Collections: 1295|1534\n",
      "Collections: 1296|1534\n",
      "Collections: 1297|1534\n",
      "Collections: 1298|1534\n",
      "Collections: 1299|1534\n",
      "Collections: 1300|1534\n",
      "Collections: 1301|1534\n",
      "Collections: 1302|1534\n",
      "Collections: 1303|1534\n",
      "Collections: 1304|1534\n",
      "Collections: 1305|1534\n",
      "Collections: 1306|1534\n",
      "Collections: 1307|1534\n",
      "Collections: 1308|1534\n",
      "Collections: 1309|1534\n",
      "Collections: 1310|1534\n",
      "Collections: 1311|1534\n",
      "Collections: 1312|1534\n",
      "Collections: 1313|1534\n",
      "Collections: 1314|1534\n",
      "Collections: 1315|1534\n",
      "Collections: 1316|1534\n",
      "Collections: 1317|1534\n",
      "Collections: 1318|1534\n",
      "Collections: 1319|1534\n",
      "Collections: 1320|1534\n",
      "Collections: 1321|1534\n",
      "Collections: 1322|1534\n",
      "Collections: 1323|1534\n",
      "Collections: 1324|1534\n",
      "Collections: 1325|1534\n",
      "Collections: 1326|1534\n",
      "Collections: 1327|1534\n",
      "Collections: 1328|1534\n",
      "Collections: 1329|1534\n",
      "Collections: 1330|1534\n",
      "Collections: 1331|1534\n",
      "Collections: 1332|1534\n",
      "Collections: 1333|1534\n",
      "Collections: 1334|1534\n",
      "Collections: 1335|1534\n",
      "Collections: 1336|1534\n",
      "Collections: 1337|1534\n",
      "Collections: 1338|1534\n",
      "Collections: 1339|1534\n",
      "Collections: 1340|1534\n",
      "Collections: 1341|1534\n",
      "Collections: 1342|1534\n",
      "Collections: 1343|1534\n",
      "Collections: 1344|1534\n",
      "Collections: 1345|1534\n",
      "Collections: 1346|1534\n",
      "Collections: 1347|1534\n",
      "Collections: 1348|1534\n",
      "Collections: 1349|1534\n",
      "Collections: 1350|1534\n",
      "Collections: 1351|1534\n",
      "Collections: 1352|1534\n",
      "Collections: 1353|1534\n",
      "Collections: 1354|1534\n",
      "Collections: 1355|1534\n",
      "Collections: 1356|1534\n",
      "Collections: 1357|1534\n",
      "Collections: 1358|1534\n",
      "Collections: 1359|1534\n",
      "Collections: 1360|1534\n",
      "Collections: 1361|1534\n",
      "Collections: 1362|1534\n",
      "Collections: 1363|1534\n",
      "Collections: 1364|1534\n",
      "Collections: 1365|1534\n",
      "Collections: 1366|1534\n",
      "Collections: 1367|1534\n",
      "Collections: 1368|1534\n",
      "Collections: 1369|1534\n",
      "Collections: 1370|1534\n",
      "Collections: 1371|1534\n",
      "Collections: 1372|1534\n",
      "Collections: 1373|1534\n",
      "Collections: 1374|1534\n",
      "Collections: 1375|1534\n",
      "Collections: 1376|1534\n",
      "Collections: 1377|1534\n",
      "Collections: 1378|1534\n",
      "Collections: 1379|1534\n",
      "Collections: 1380|1534\n",
      "Collections: 1381|1534\n",
      "Collections: 1382|1534\n",
      "Collections: 1383|1534\n",
      "Collections: 1384|1534\n",
      "Collections: 1385|1534\n",
      "Collections: 1386|1534\n",
      "Collections: 1387|1534\n",
      "Collections: 1388|1534\n",
      "Collections: 1389|1534\n",
      "Collections: 1390|1534\n",
      "Collections: 1391|1534\n",
      "Collections: 1392|1534\n",
      "Collections: 1393|1534\n",
      "Collections: 1394|1534\n",
      "Collections: 1395|1534\n",
      "Collections: 1396|1534\n",
      "Collections: 1397|1534\n",
      "Collections: 1398|1534\n",
      "Collections: 1399|1534\n",
      "Collections: 1400|1534\n",
      "Collections: 1401|1534\n",
      "Collections: 1402|1534\n",
      "Collections: 1403|1534\n",
      "Collections: 1404|1534\n",
      "Collections: 1405|1534\n",
      "Collections: 1406|1534\n",
      "Collections: 1407|1534\n",
      "Collections: 1408|1534\n",
      "Collections: 1409|1534\n",
      "Collections: 1410|1534\n",
      "Collections: 1411|1534\n",
      "Collections: 1412|1534\n",
      "Collections: 1413|1534\n",
      "Collections: 1414|1534\n",
      "Collections: 1415|1534\n",
      "Collections: 1416|1534\n",
      "Collections: 1417|1534\n",
      "Collections: 1418|1534\n",
      "Collections: 1419|1534\n",
      "Collections: 1420|1534\n",
      "Collections: 1421|1534\n",
      "Collections: 1422|1534\n",
      "Collections: 1423|1534\n",
      "Collections: 1424|1534\n",
      "Collections: 1425|1534\n",
      "Collections: 1426|1534\n",
      "Collections: 1427|1534\n",
      "Collections: 1428|1534\n",
      "Collections: 1429|1534\n",
      "Collections: 1430|1534\n",
      "Collections: 1431|1534\n",
      "Collections: 1432|1534\n",
      "Collections: 1433|1534\n",
      "Collections: 1434|1534\n",
      "Collections: 1435|1534\n",
      "Collections: 1436|1534\n",
      "Collections: 1437|1534\n",
      "Collections: 1438|1534\n",
      "Collections: 1439|1534\n",
      "Collections: 1440|1534\n",
      "Collections: 1441|1534\n",
      "Collections: 1442|1534\n",
      "Collections: 1443|1534\n",
      "Collections: 1444|1534\n",
      "Collections: 1445|1534\n",
      "Collections: 1446|1534\n",
      "Collections: 1447|1534\n",
      "Collections: 1448|1534\n",
      "Collections: 1449|1534\n",
      "Collections: 1450|1534\n",
      "Collections: 1451|1534\n",
      "Collections: 1452|1534\n",
      "Collections: 1453|1534\n",
      "Collections: 1454|1534\n",
      "Collections: 1455|1534\n",
      "Collections: 1456|1534\n",
      "Collections: 1457|1534\n",
      "Collections: 1458|1534\n",
      "Collections: 1459|1534\n",
      "Collections: 1460|1534\n",
      "Collections: 1461|1534\n",
      "Collections: 1462|1534\n",
      "Collections: 1463|1534\n",
      "Collections: 1464|1534\n",
      "Collections: 1465|1534\n",
      "Collections: 1466|1534\n",
      "Collections: 1467|1534\n",
      "Collections: 1468|1534\n",
      "Collections: 1469|1534\n",
      "Collections: 1470|1534\n",
      "[E088] Text of length 1409376 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
      "Collections: 1471|1534\n",
      "Collections: 1472|1534\n",
      "Collections: 1473|1534\n",
      "Collections: 1474|1534\n",
      "Collections: 1475|1534\n",
      "Collections: 1476|1534\n",
      "Collections: 1477|1534\n",
      "Collections: 1478|1534\n",
      "Collections: 1479|1534\n",
      "Collections: 1480|1534\n",
      "Collections: 1481|1534\n",
      "Collections: 1482|1534\n",
      "Collections: 1483|1534\n",
      "Collections: 1484|1534\n",
      "Collections: 1485|1534\n",
      "Collections: 1486|1534\n",
      "Collections: 1487|1534\n",
      "Collections: 1488|1534\n",
      "Collections: 1489|1534\n",
      "Collections: 1490|1534\n",
      "Collections: 1491|1534\n",
      "Collections: 1492|1534\n",
      "Collections: 1493|1534\n",
      "Collections: 1494|1534\n",
      "Collections: 1495|1534\n",
      "Collections: 1496|1534\n",
      "Collections: 1497|1534\n",
      "Collections: 1498|1534\n",
      "Collections: 1499|1534\n",
      "Collections: 1500|1534\n",
      "Collections: 1501|1534\n",
      "Collections: 1502|1534\n",
      "Collections: 1503|1534\n",
      "Collections: 1504|1534\n",
      "Collections: 1505|1534\n",
      "Collections: 1506|1534\n",
      "Collections: 1507|1534\n",
      "Collections: 1508|1534\n",
      "Collections: 1509|1534\n",
      "Collections: 1510|1534\n",
      "Collections: 1511|1534\n",
      "Collections: 1512|1534\n",
      "Collections: 1513|1534\n",
      "Collections: 1514|1534\n",
      "Collections: 1515|1534\n",
      "Collections: 1516|1534\n",
      "Collections: 1517|1534\n",
      "Collections: 1518|1534\n",
      "Collections: 1519|1534\n",
      "Collections: 1520|1534\n",
      "Collections: 1521|1534\n",
      "Collections: 1522|1534\n",
      "Collections: 1523|1534\n",
      "Collections: 1524|1534\n",
      "Collections: 1525|1534\n",
      "Collections: 1526|1534\n",
      "Collections: 1527|1534\n",
      "Collections: 1528|1534\n",
      "Collections: 1529|1534\n",
      "Collections: 1530|1534\n",
      "Collections: 1531|1534\n",
      "Collections: 1532|1534\n",
      "Collections: 1533|1534\n",
      "Collections: 1534|1534\n",
      "Databases: 4|4\n"
     ]
    }
   ],
   "source": [
    "store_keywords(\n",
    "    minio_client = minio_client,\n",
    "    meili_client = meili_client,\n",
    "    storage_documents = stored_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a484c6-7032-4878-8f8a-b5d466089bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88b4c8f0-1390-4c4a-a6c9-21411d839c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskInfo(task_uid=32, index_uid='llm-rag-code-keywords', status='enqueued', type='indexDeletion', enqueued_at=datetime.datetime(2024, 11, 1, 13, 29, 58, 264698))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meili_client.index('llm-rag-code-keywords').delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340932c-f57d-464c-9d0e-0baa4c20077f",
   "metadata": {},
   "source": [
    "## Hybrid Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd2a9e-4a99-45b2-83cb-da2f9895c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prompt(\n",
    "    prompt: str\n",
    ") -> any:\n",
    "    prompt = prompt.lower()\n",
    "    prompt = re.sub(r'\\s+', ' ', prompt)\n",
    "    prompt = re.sub(r'[^\\w\\s]', '', prompt)\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_prompt_embedding_query(\n",
    "    model_name: str,\n",
    "    prompt: any\n",
    ") -> any:\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name = model_name\n",
    "    )\n",
    "    embedding = embedding_model.embed_documents(\n",
    "        texts = [prompt]\n",
    "    )\n",
    "    return embedding[0]\n",
    "\n",
    "def spacy_find_keywords(\n",
    "    text: str\n",
    "):\n",
    "    formatted = nlp(text.lower())\n",
    "    \n",
    "    keywords = [\n",
    "        token.lemma_ for token in formatted\n",
    "        if not token.is_stop               \n",
    "        and not token.is_punct              \n",
    "        and not token.is_space              \n",
    "        and len(token) > 1                  \n",
    "    ]\n",
    "    \n",
    "    keywords = list(set(keywords))\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def generate_prompt_keyword_query(\n",
    "    prompt: any\n",
    ") -> any:\n",
    "    keywords = spacy_find_keywords(\n",
    "        text = prompt\n",
    "    )\n",
    "    keyword_query = ' OR '.join([f'keywords = \"{keyword}\"' for keyword in keywords])\n",
    "    return keyword_query\n",
    "\n",
    "def calculate_keyword_score(\n",
    "    keyword_query: str,\n",
    "    keyword_list: any\n",
    ") -> any:\n",
    "    match = 0\n",
    "    asked_keywords = keyword_query.split('OR')\n",
    "    for asked_keyword in asked_keywords:\n",
    "        formatted = asked_keyword.replace('keywords =', '')\n",
    "        formatted = formatted.replace('\"', '')\n",
    "        formatted = formatted.replace(' ', '')\n",
    "        \n",
    "        if formatted in keyword_list:\n",
    "            match += 1\n",
    "            \n",
    "    query_length = len(asked_keywords)\n",
    "    keyword_length = len(keyword_list)\n",
    "\n",
    "    if match == 0:\n",
    "        return 0.0\n",
    "\n",
    "    normalized = match / ((query_length * keyword_length) ** 0.5)\n",
    "    return normalized\n",
    "    \n",
    "def vector_search_collection(\n",
    "    vector_client: any,\n",
    "    search_client: any,\n",
    "    prompt: str,\n",
    "    top_k: int\n",
    "):\n",
    "\n",
    "    cleaned_prompt = clean_prompt(\n",
    "        prompt = prompt\n",
    "    )\n",
    "\n",
    "    prompt_embedding_query = generate_prompt_embedding_query(\n",
    "        model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "        prompt = cleaned_prompt\n",
    "    )\n",
    "\n",
    "    prompt_keyword_query = generate_prompt_keyword_query(\n",
    "        prompt = cleaned_prompt\n",
    "    )\n",
    "\n",
    "    qdrant_collections = [\n",
    "        'llm-rag-code-embeddings',\n",
    "        'llm-rag-workflows-embeddings'\n",
    "    ]\n",
    "    \n",
    "    recommeded_cases = []\n",
    "    for collection in qdrant_collections:\n",
    "        results = qdrant_search_vectors(\n",
    "            qdrant_client = vector_client,  \n",
    "            collection_name = collection,\n",
    "            query_vector = prompt_embedding_query,\n",
    "            limit = top_k\n",
    "        ) \n",
    "        \n",
    "        for result in results:\n",
    "            res_database = result.payload['database']\n",
    "            res_collection = result.payload['collection']\n",
    "            res_document = result.payload['document']\n",
    "            res_type = result.payload['type']\n",
    "            res_score = result.score\n",
    "            \n",
    "            res_case = {\n",
    "                'source': 'vector',\n",
    "                'database': res_database,\n",
    "                'collection': res_collection,\n",
    "                'document': res_document,\n",
    "                'type': res_type,\n",
    "                'score': res_score\n",
    "            }\n",
    "            \n",
    "            recommeded_cases.append(res_case)\n",
    "            \n",
    "    meili_collections = [\n",
    "        'llm-rag-code-keywords',\n",
    "        'llm-rag-workflows-keywords'\n",
    "    ]\n",
    "\n",
    "    recommeded_keyword_cases = []\n",
    "    for index in meili_collections:\n",
    "        results = meili_search_documents(\n",
    "            meili_client = search_client, \n",
    "            index_name = index, \n",
    "            query = \"\", \n",
    "            options = {\n",
    "                'filter': prompt_keyword_query,\n",
    "                'attributesToRetrieve': ['database','collection','document', 'keywords'],\n",
    "                'limit': top_k\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for result in results['hits']:\n",
    "            res_database = result['database']\n",
    "            res_collection = result['collection']\n",
    "            res_document = result['document']\n",
    "            res_keywords = result['keywords']\n",
    "            \n",
    "            res_score = calculate_keyword_score(\n",
    "                keyword_query = prompt_keyword_query,\n",
    "                keyword_list = res_keywords\n",
    "            )\n",
    "\n",
    "            res_case = {\n",
    "                'source': 'search',\n",
    "                'database': res_database,\n",
    "                'collection': res_collection,\n",
    "                'document': res_document,\n",
    "                'type': res_type,\n",
    "                'score': res_score\n",
    "            }\n",
    "\n",
    "            recommeded_cases.append(res_case)\n",
    "\n",
    "    return recommeded_cases\n",
    "\n",
    "def get_top_document_metadata(\n",
    "    collection: str,\n",
    "    alpha: float\n",
    ") -> any:\n",
    "    df = pd.DataFrame(collection)\n",
    "    ids_with_both = df.groupby('document')['source'].nunique()\n",
    "    ids_with_both = ids_with_both[ids_with_both > 1].index\n",
    "    filtered_df = df[df['document'].isin(ids_with_both)]\n",
    "\n",
    "    matched_documents = []\n",
    "    for index_i, row_i in filtered_df[filtered_df['source'] == 'vector'].iterrows():\n",
    "        vector_source = row_i['source']\n",
    "        vector_database = row_i['database']\n",
    "        vector_collection = row_i['collection']\n",
    "        vector_id = row_i['document']\n",
    "        vector_type = row_i['type']\n",
    "        vector_score = row_i['score']\n",
    "        \n",
    "        for index_j, row_j in filtered_df[filtered_df['source'] == 'search'].iterrows():\n",
    "            search_source = row_j['source']\n",
    "            search_database = row_j['database']\n",
    "            search_collection = row_j['collection']\n",
    "            search_id = row_j['document']\n",
    "            search_type = row_j['type']\n",
    "            search_score = row_j['score']\n",
    "            \n",
    "            if vector_database == search_database:\n",
    "                if vector_collection == search_collection:\n",
    "                    if vector_type == search_type:\n",
    "                        if vector_id == search_id:\n",
    "                            hybrid_score = vector_score * alpha + search_score * (1-alpha)\n",
    "    \n",
    "                            matched_documents.append({\n",
    "                                'source': 'hybrid',\n",
    "                                'database': search_database,\n",
    "                                'collection': search_collection,\n",
    "                                'document': search_id,\n",
    "                                'score': hybrid_score\n",
    "                            })\n",
    "    \n",
    "    match_df = pd.DataFrame(matched_documents)\n",
    "    print(match_df)\n",
    "    return match_df.nlargest(1, 'score').values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9dd18-5f6a-4869-a606-b8ed73cbdde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
